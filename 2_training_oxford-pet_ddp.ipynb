{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2_training_oxford-pet_ddp(Distributed Data Parallel)\n",
    "---\n",
    "\n",
    "본 모듈에서는 Amzaon SageMaker API을 효과적으로 이용하기 위해 multigpu-distributed 학습을 위한 PyTorch 프레임워크 기반 모델 훈련을 수행해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "install_needed = True\n",
    "# install_needed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "installing deps and restarting kernel\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import IPython\n",
    "\n",
    "if install_needed:\n",
    "    print(\"installing deps and restarting kernel\")\n",
    "    !{sys.executable} -m pip install --upgrade pip --quiet\n",
    "    !{sys.executable} -m pip install -U wget split-folders --quiet\n",
    "    IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Sagemaker notebook 설명\n",
    "<p>Sagemaker notebook은 완전 관리형 서비스로 컨테이너 기반으로 구성되어 있습니다. 사용자가 직접 컨테이너를 볼 수 없지만, 내부적으로는 아래와 같은 원리로 동작합니다. </p>\n",
    "<p><img src=\"./imgs/fig00.png\" width=\"800\", height=\"80\"></p>\n",
    "\n",
    "- **S3 (Simple Storage Serivce)** : Object Storage로서 학습할 데이터 파일과 학습 결과인 model, checkpoint, tensorboard를 위한 event 파일, 로그 정보 등을 저장하는데 사용합니다.\n",
    "- **SageMaker Notebook** : 학습을 위한 스크립트 작성과 디버깅, 그리고 실제 학습을 수행하기 위한 Python을 개발하기 위한 환경을 제공합니다.\n",
    "- **Amazon Elastic Container Registry(ECR)** :  Docker 컨테이너 이미지를 손쉽게 저장, 관리 및 배포할 수 있게 해주는 완전관리형 Docker 컨테이너 레지스트리입니다. Sagemaker는 기본적인 컨테이너를 제공하기 때문에 별도 ECR에 컨테이너 이미지를 등록할 필요는 없습니다. 하지만, 별도의 학습 및 배포 환경이 필요한 경우 custom 컨테이너 이미지를 만들어서 ECR에 등록한 후 이 환경을 활용할 수 있습니다.\n",
    "\n",
    "<p>학습과 추론을 하는 hosting 서비스는 각각 다른 컨테이너 환경에서 수행할 수 있으며, 쉽게 다량으로 컨테이너 환경을 확장할 수 있으므로 다량의 학습과 hosting이 동시에 가능합니다.   \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Sagemaker 학습에 필요한 기본적인 package를 import 합니다. </p>\n",
    "<p>boto3는 HTTP API 호출을 숨기는 편한 추상화 모델을 가지고 있고, Amazon EC2 인스턴스 및 S3 버켓과 같은 AWS 리소스와 동작하는 파이선 클래스를 제공합니다. </p>\n",
    "<p>sagemaker python sdk는 Amazon SageMaker에서 기계 학습 모델을 교육 및 배포하기 위한 오픈 소스 라이브러리입니다.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from pathlib import Path\n",
    "from time import strftime\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.169.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 소개 및 split 후 S3 upload하기\n",
    "<p>이번 학습에 사용할 이미지 데이터는 <strong><a href=\"https://www.robots.ox.ac.uk/~vgg/data/pets/\" target=\"_blank\" class ='btn-default'>Oxford-IIIT Pet Dataset</a></strong> 입니다. Oxford-IIIT Pet Dataset은 <strong>37</strong>개 다른 종의 개와 고양이 이미지를 각각 200장 씩 제공하고 있으며, Ground Truth 또한 Classification, Object Detection, Segmentation와 관련된 모든 정보가 있으나, 이번 학습에서는 37개 class에 대해 일부 이미지로 Classification 문제를 해결하기 위해 학습을 진행할 예정입니다.</p>\n",
    "<p><img src=\"./imgs/pet_annotations.jpg\" width=\"700\", height=\"70\"></p>    \n",
    "<p>이미지 파일을 학습하기 위해 SageMaker Notebook 환경으로 upload를 합니다. 폴더 구조는 아래와 같은 형태로 구성되어야 합니다. </p>\n",
    "<pre>\n",
    "<div style='line-height:80%'>\n",
    "    image_path/class1/Aimage_1<br>\n",
    "                      Aimage_2<br>\n",
    "                       ...<br>\n",
    "                      Aimage_N<br>\n",
    "    image_path/class2/Bimage_1<br>\n",
    "                      Bimage_2<br>\n",
    "                       ...<br>\n",
    "                      Bimage_M<br>\n",
    "</div>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>SageMaker 학습을 위해 train/val로 분리한 폴더를 S3내 이전에 지정한 bucket 내 prefix 하위 폴더로 upload합니다. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading the data to S3\n",
    "We are going to use the `sagemaker.Session.upload_data` function to upload our datasets to an S3 location. The return value inputs identifies the location -- we will use later when we start the training job.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_dir(img_path, delete=True):\n",
    "    import shutil, os\n",
    "    try:\n",
    "        if not os.path.exists(img_path):\n",
    "            os.makedirs(img_path)\n",
    "        else:\n",
    "            if delete:\n",
    "                shutil.rmtree(img_path)\n",
    "    except OSError:\n",
    "        print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf dataset/oxford_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rawimg_path = 'dataset/oxford_dataset/raw'\n",
    "dataset_path = 'dataset/oxford_dataset/dataset'\n",
    "output_dir = 'dataset/oxford_dataset/output'\n",
    "\n",
    "make_dir(rawimg_path)\n",
    "make_dir(dataset_path)\n",
    "make_dir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not (os.path.isfile(\"images.tar.gz\") and tarfile.is_tarfile(\"images.tar.gz\")):\n",
    "    wget.download('https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz')\n",
    "tar = tarfile.open(\"images.tar.gz\")\n",
    "tar.extractall(path=rawimg_path)\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import wget\n",
    "import tarfile\n",
    "import splitfolders\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "def checkImage(path):\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            data = f.read()\n",
    "            f.seek(-2,2)\n",
    "            value = f.read()\n",
    "\n",
    "        encoded_img = np.frombuffer(data, dtype = np.uint8)\n",
    "        img_cv = cv2.imdecode(encoded_img, cv2.IMREAD_COLOR)\n",
    "        if img_cv.shape[0]>0 and value == b'\\xff\\xd9':\n",
    "            return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corrupt_img = ['Egyptian_Mau_14.jpg','Egyptian_Mau_139.jpg','Egyptian_Mau_145.jpg','Egyptian_Mau_156.jpg',\n",
    "               'Egyptian_Mau_167.jpg','Egyptian_Mau_177.jpg','Egyptian_Mau_186.jpg','Egyptian_Mau_191.jpg',\n",
    "               'Abyssinian_5.jpg','Abyssinian_34.jpg','chihuahua_121.jpg','beagle_116.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/oxford_dataset/raw/images/Egyptian_Mau_191.jpg\n",
      "dataset/oxford_dataset/raw/images/Abyssinian_100.mat\n",
      "dataset/oxford_dataset/raw/images/Abyssinian_102.mat\n",
      "dataset/oxford_dataset/raw/images/Egyptian_Mau_14.jpg\n",
      "dataset/oxford_dataset/raw/images/Egyptian_Mau_156.jpg\n",
      "dataset/oxford_dataset/raw/images/Egyptian_Mau_139.jpg\n",
      "dataset/oxford_dataset/raw/images/Egyptian_Mau_167.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: premature end of data segment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/oxford_dataset/raw/images/beagle_116.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/oxford_dataset/raw/images/chihuahua_121.jpg\n",
      "dataset/oxford_dataset/raw/images/Egyptian_Mau_138.jpg\n",
      "dataset/oxford_dataset/raw/images/Abyssinian_34.jpg\n",
      "dataset/oxford_dataset/raw/images/Abyssinian_101.mat\n",
      "dataset/oxford_dataset/raw/images/Egyptian_Mau_177.jpg\n",
      "dataset/oxford_dataset/raw/images/Egyptian_Mau_145.jpg\n",
      "dataset/oxford_dataset/raw/images/Egyptian_Mau_186.jpg\n",
      "dataset/oxford_dataset/raw/images/Abyssinian_5.jpg\n"
     ]
    }
   ],
   "source": [
    "file_dir = os.path.join(rawimg_path, 'images')\n",
    "\n",
    "for file_path in glob.glob(file_dir + \"/*\"):\n",
    "    filename = file_path.split(\"/\")[4]\n",
    "    if checkImage(file_path) and filename not in corrupt_img:\n",
    "        dir_name = filename.split(\"_\")\n",
    "        dir_name.pop()\n",
    "        dir_name = \"_\".join(dir_name)\n",
    "        dir_path = os.path.join(output_dir, dir_name)\n",
    "        make_dir(dir_path, False)\n",
    "        target_name = os.path.join(dir_path, filename)\n",
    "        shutil.copyfile(file_path, target_name)\n",
    "    else:\n",
    "        print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 7377 files [00:01, 4977.55 files/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: AWS CLI version 2, the latest major version of the AWS CLI, is now stable and recommended for general use. For more information, see the AWS CLI version 2 installation instructions at: https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html\n",
      "\n",
      "usage: aws [options] <command> <subcommand> [<subcommand> ...] [parameters]\n",
      "To see help text, you can run:\n",
      "\n",
      "  aws help\n",
      "  aws <command> help\n",
      "  aws <command> <subcommand> help\n",
      "aws: error: the following arguments are required: paths\n",
      "Note: AWS CLI version 2, the latest major version of the AWS CLI, is now stable and recommended for general use. For more information, see the AWS CLI version 2 installation instructions at: https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html\n",
      "\n",
      "usage: aws [options] <command> <subcommand> [<subcommand> ...] [parameters]\n",
      "To see help text, you can run:\n",
      "\n",
      "  aws help\n",
      "  aws <command> help\n",
      "  aws <command> <subcommand> help\n",
      "aws: error: the following arguments are required: paths\n"
     ]
    }
   ],
   "source": [
    "splitfolders.ratio(output_dir, output=dataset_path, seed=1337, ratio=(.8, .1, .1)) # default values\n",
    "inputs = 's3://{}/{}'.format(bucket, 'oxford_pet_dataset')\n",
    "!aws s3 rm $s3_data_path --quiet --recursive\n",
    "!aws s3 cp $dataset_path $s3_data_path --quiet --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Training\n",
    "\n",
    "AWS에서 Multigpu distributed training은 `data_parallel`와 `model_parallel` 를 모두 사용할 수 있으며, 아래 예제는 data_parallel 중심으로 학습을 하게 됩니다. \n",
    "\n",
    "<!-- \n",
    "이번에는 Pytorch에서 활용할 수 있는 [APEX](https://github.com/NVIDIA/apex) (A Pytorch EXtension) 패키지를 이용하여 Multigpu distributed training을 수행합니다. APEX 패키지에는 distributed training 기능과 함께 mixed precision training도 할 수 있도록 지원하고 있습니다. \n",
    "\n",
    "<!-- \n",
    "<p><img src=\"./imgs/apex.png\" width=\"1100\", height=\"150\"></p>  -->\n",
    "<!-- - mixed precision training (apex.amp) : FP16과 FP32연산을 mixed하여 처리 속도와 정확도를 동시에 잡기 위해 학습을 하는 방법입니다. Tensor Cores에서 FP16를 이용하면 compute 처리량은 8배, 메모리 처리량은 2배 증가하는 반면 메모리 저장은 50% 절감됩니다. (FP : Floating Point, AMP: Automatic Mixed Precision) -->\n",
    "\n",
    "- **[SageMaker Distributed Data Parallel](https://docs.aws.amazon.com/sagemaker/latest/dg/data-parallel.html)** : AWS의 네트워크 인프라와 Balanced Fusion Buffers 를 이용하여 AWS SageMaker에 최적화된 data parallel 분산학습 알고리즘을 제공합니다.\n",
    "\n",
    "- **DataParallel (DP)** : 데이터 샘플의 미니 배치를 여러 개의 더 작은 미니 배치로 나누고 병렬로 작은 미니 배치를 각각 계산하는 방식이며, 단일 host에서 multi-gpu인 경우와 cpu 연산일 경우에 사용합니다. DP의 단점은 GPU가 즐어나면서 communication 비용이 높아지게 되면서 성능저하가 발생하게 되는데 일반적으로 4 gpu 이상일 경우 발생한다고 합니다. 또한, 타 GPU 메모리 대비 0번 GPU 메모리 사용량이 증가하는 현상도 발생합니다.  \n",
    "\n",
    "- **Distributed Data Parallel (DDP)** : 모듈 수준에서 데이터 병렬 처리를 구현하는 것으로 torch.distributed 패키지의 communication collectives를 사용하여 gradient, parameters, buffers를 동기화합니다. 프로세스 내와 프로세스 간을 사용하는 multi-host의 multi-gpu 와 같은 경우에 사용하게 되는데, 프로세스 내에서는 DDP는 input 모듈을 device_id에 특정한 device로 복제하고, 그에 따라 배치 크기로 input을 분산시키며, outputs는 DataParallel과 유사하게 output_device로 모으게 됩니다.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training with Distributed Data Parallel\n",
    "\n",
    "\n",
    "The training script provides the code you need for distributed data parallel (DDP) training. The training script is very similar to a PyTorch training script you might run outside of SageMaker.\n",
    "\n",
    "In the following code block, you can update the estimator function to use a different instance type, instance count, and distrubtion strategy. You're also passing in the training script you reviewed in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metric_definitions=[\n",
    "     {'Name': 'train:Time', 'Regex': 'Train_Time=(.*?):'},\n",
    "     {'Name': 'train:Loss', 'Regex': 'Train_Loss=(.*?):'},\n",
    "     {'Name': 'train:Prec@1', 'Regex': 'Train_Prec@1=(.*?):'},\n",
    "     {'Name': 'train:Prec@5', 'Regex': 'Train_Prec@5=(.*?):'},\n",
    "     {'Name': 'test:Time', 'Regex': 'Test_Time=(.*?):'},\n",
    "     {'Name': 'test:Loss', 'Regex': 'Test_Loss=(.*?):'},\n",
    "     {'Name': 'test:Prec@1', 'Regex': 'Test_Prec@1=(.*?):'},\n",
    "     {'Name': 'test:Prec@5', 'Regex': 'Test_Prec@5=(.*?):'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "        # 'model_name' : 'resnext101_32x8d',\n",
    "        'model_name' : 'swin_b',\n",
    "        'num-classes' : 37,\n",
    "        'height' : 128,\n",
    "        'width' : 128,\n",
    "        'num-epochs': 15,\n",
    "        'batch-size' : 80, # 80 128 136\n",
    "        'test-batch-size' : 200, \n",
    "        'lr': 0.0001,\n",
    "        # 'backend': 'nccl',  \n",
    "        'backend': 'smddp', \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "distribution = {}\n",
    "\n",
    "if hyperparameters['backend'] == 'nccl':\n",
    "    # ### MPIRUN 수행\n",
    "    distribution[\"mpi\"]={\"enabled\": True}\n",
    "elif hyperparameters['backend'] == 'smddp':\n",
    "    ### SageMaker DDP\n",
    "    distribution[\"smdistributed\"] = {\"dataparallel\": {\"enabled\": True}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instance_type = 'ml.p3.16xlarge'  # 'ml.p3.16xlarge', 'ml.p3dn.24xlarge', 'ml.p4d.24xlarge', 'local_gpu'\n",
    "# instance_type = 'local_gpu'\n",
    "instance_count = 2\n",
    "max_run = 1*60*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-west-2-322537213286/oxford_pet_dataset'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if instance_type =='local_gpu':\n",
    "    from sagemaker.local import LocalSession\n",
    "\n",
    "    sagemaker_session = LocalSession()\n",
    "    sagemaker_session.config = {'local': {'local_code': True}}\n",
    "    s3_data_path = f'file://{Path.cwd()}/dataset/oxford_dataset/dataset'\n",
    "else:\n",
    "    sagemaker_session = sagemaker.Session()\n",
    "    s3_data_path = inputs\n",
    "s3_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(entry_point='pytorch_oxford_ddp.py',\n",
    "                    source_dir=f'{Path.cwd()}/2_training_oxford-pet_ddp',\n",
    "                    role=role,\n",
    "                    framework_version='1.13.1',\n",
    "                    py_version='py39',\n",
    "                    instance_count=instance_count,\n",
    "                    instance_type=instance_type,\n",
    "                    distribution=distribution,\n",
    "                    metric_definitions=metric_definitions,\n",
    "                    disable_profiler=True,\n",
    "                    debugger_hook_config=False,\n",
    "                    max_run=max_run,\n",
    "                    hyperparameters=hyperparameters,\n",
    "                    sagemaker_session=sagemaker_session\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we've constructed our `PyTorch` object, we can fit it using the data we uploaded to S3. SageMaker makes sure our data is available in the local filesystem, so our training script can simply read the data from disk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: oxford-ml-p3-16xlarge-0702-08581688288298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    }
   ],
   "source": [
    "current_time = strftime(\"%m%d-%H%M%s\")\n",
    "i_type = instance_type.replace('.','-')\n",
    "job_name = f'oxford-{i_type}-{current_time}'\n",
    "\n",
    "estimator.fit(\n",
    "    inputs={'training': s3_data_path}, \n",
    "    job_name=job_name,\n",
    "    wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-02 08:58:19 Starting - Starting the training job......\n",
      "2023-07-02 08:59:15 Starting - Preparing the instances for training.........\n",
      "2023-07-02 09:00:26 Downloading - Downloading input data......\n",
      "2023-07-02 09:01:21 Training - Downloading the training image..................\n",
      "2023-07-02 09:04:28 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-07-02 09:04:55,777 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-07-02 09:04:55,842 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-07-02 09:04:55,855 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-07-02 09:04:55,858 sagemaker_pytorch_container.training INFO     Invoking SMDataParallel\u001b[0m\n",
      "\u001b[34m2023-07-02 09:04:55,858 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-07-02 09:04:56,110 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.9 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting albumentations (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading albumentations-1.3.1-py3-none-any.whl (125 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 125.7/125.7 kB 6.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.11.1 in /opt/conda/lib/python3.9/site-packages (from albumentations->-r requirements.txt (line 1)) (1.23.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from albumentations->-r requirements.txt (line 1)) (1.10.1)\u001b[0m\n",
      "\u001b[34mCollecting scikit-image>=0.16.1 (from albumentations->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading scikit_image-0.21.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.8/13.8 MB 78.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: PyYAML in /opt/conda/lib/python3.9/site-packages (from albumentations->-r requirements.txt (line 1)) (5.4.1)\u001b[0m\n",
      "\u001b[34mCollecting qudida>=0.0.4 (from albumentations->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting opencv-python-headless>=4.1.1 (from albumentations->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 49.1/49.1 MB 37.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/lib/python3.9/site-packages (from qudida>=0.0.4->albumentations->-r requirements.txt (line 1)) (1.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from qudida>=0.0.4->albumentations->-r requirements.txt (line 1)) (4.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations->-r requirements.txt (line 1)) (3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>=9.0.1 in /opt/conda/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations->-r requirements.txt (line 1)) (9.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: imageio>=2.27 in /opt/conda/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations->-r requirements.txt (line 1)) (2.28.0)\u001b[0m\n",
      "\u001b[34mCollecting tifffile>=2022.8.12 (from scikit-image>=0.16.1->albumentations->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading tifffile-2023.4.12-py3-none-any.whl (219 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 219.4/219.4 kB 42.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting PyWavelets>=1.1.1 (from scikit-image>=0.16.1->albumentations->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading PyWavelets-1.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.9/6.9 MB 89.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=21 in /opt/conda/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations->-r requirements.txt (line 1)) (23.1)\u001b[0m\n",
      "\u001b[34mCollecting lazy_loader>=0.2 (from scikit-image>=0.16.1->albumentations->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading lazy_loader-0.3-py3-none-any.whl (9.1 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations->-r requirements.txt (line 1)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations->-r requirements.txt (line 1)) (3.1.0)\u001b[0m\n",
      "\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-07-02 09:04:55,342 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-07-02 09:04:55,407 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-07-02 09:04:55,419 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-07-02 09:04:55,422 sagemaker_pytorch_container.training INFO     Invoking SMDataParallel\u001b[0m\n",
      "\u001b[34m2023-07-02 09:04:55,422 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-07-02 09:04:55,673 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.9 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting albumentations (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading albumentations-1.3.1-py3-none-any.whl (125 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 125.7/125.7 kB 6.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.11.1 in /opt/conda/lib/python3.9/site-packages (from albumentations->-r requirements.txt (line 1)) (1.23.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from albumentations->-r requirements.txt (line 1)) (1.10.1)\u001b[0m\n",
      "\u001b[34mCollecting scikit-image>=0.16.1 (from albumentations->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading scikit_image-0.21.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.8/13.8 MB 78.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: PyYAML in /opt/conda/lib/python3.9/site-packages (from albumentations->-r requirements.txt (line 1)) (5.4.1)\u001b[0m\n",
      "\u001b[34mCollecting qudida>=0.0.4 (from albumentations->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting opencv-python-headless>=4.1.1 (from albumentations->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 49.1/49.1 MB 35.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/lib/python3.9/site-packages (from qudida>=0.0.4->albumentations->-r requirements.txt (line 1)) (1.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from qudida>=0.0.4->albumentations->-r requirements.txt (line 1)) (4.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations->-r requirements.txt (line 1)) (3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>=9.0.1 in /opt/conda/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations->-r requirements.txt (line 1)) (9.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: imageio>=2.27 in /opt/conda/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations->-r requirements.txt (line 1)) (2.28.0)\u001b[0m\n",
      "\u001b[34mCollecting tifffile>=2022.8.12 (from scikit-image>=0.16.1->albumentations->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading tifffile-2023.4.12-py3-none-any.whl (219 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 219.4/219.4 kB 36.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting PyWavelets>=1.1.1 (from scikit-image>=0.16.1->albumentations->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading PyWavelets-1.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.9/6.9 MB 86.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=21 in /opt/conda/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations->-r requirements.txt (line 1)) (23.1)\u001b[0m\n",
      "\u001b[34mCollecting lazy_loader>=0.2 (from scikit-image>=0.16.1->albumentations->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading lazy_loader-0.3-py3-none-any.whl (9.1 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations->-r requirements.txt (line 1)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations->-r requirements.txt (line 1)) (3.1.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: tifffile, PyWavelets, opencv-python-headless, lazy_loader, scikit-image, qudida, albumentations\u001b[0m\n",
      "\u001b[35mInstalling collected packages: tifffile, PyWavelets, opencv-python-headless, lazy_loader, scikit-image, qudida, albumentations\u001b[0m\n",
      "\u001b[34mSuccessfully installed PyWavelets-1.4.1 albumentations-1.3.1 lazy_loader-0.3 opencv-python-headless-4.8.0.74 qudida-0.0.4 scikit-image-0.21.0 tifffile-2023.4.12\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[35mSuccessfully installed PyWavelets-1.4.1 albumentations-1.3.1 lazy_loader-0.3 opencv-python-headless-4.8.0.74 qudida-0.0.4 scikit-image-0.21.0 tifffile-2023.4.12\u001b[0m\n",
      "\u001b[35mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[35m[notice] A new release of pip is available: 23.1.1 -> 23.1.2\u001b[0m\n",
      "\u001b[35m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.1.1 -> 23.1.2\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2023-07-02 09:05:02,535 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-07-02 09:05:02,535 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-07-02 09:05:02,615 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-07-02 09:05:02,704 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-07-02 09:05:02,716 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\u001b[0m\n",
      "\u001b[34m2023-07-02 09:05:02,717 sagemaker-training-toolkit INFO     Creating SSH daemon.\u001b[0m\n",
      "\u001b[34m2023-07-02 09:05:02,719 sagemaker-training-toolkit INFO     Waiting for MPI workers to establish their SSH connections\u001b[0m\n",
      "\u001b[34m2023-07-02 09:05:02,720 sagemaker-training-toolkit INFO     Cannot connect to host algo-2 at port 22. Retrying...\u001b[0m\n",
      "\u001b[34m2023-07-02 09:05:02,720 sagemaker-training-toolkit INFO     Connection closed\u001b[0m\n",
      "\u001b[35m2023-07-02 09:05:02,802 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[35m2023-07-02 09:05:02,803 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[35m2023-07-02 09:05:02,875 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[35m2023-07-02 09:05:02,959 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[35m2023-07-02 09:05:02,972 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\u001b[0m\n",
      "\u001b[35m2023-07-02 09:05:02,972 sagemaker-training-toolkit INFO     Waiting for MPI Master to create SSH daemon.\u001b[0m\n",
      "\u001b[35m2023-07-02 09:05:02,985 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_8.2p1)\u001b[0m\n",
      "\u001b[35m2023-07-02 09:05:03,156 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[35m2023-07-02 09:05:03,156 sagemaker-training-toolkit INFO     Can connect to host algo-1\u001b[0m\n",
      "\u001b[35m2023-07-02 09:05:03,156 sagemaker-training-toolkit INFO     MPI Master online, creating SSH daemon.\u001b[0m\n",
      "\u001b[35m2023-07-02 09:05:03,156 sagemaker-training-toolkit INFO     Writing environment variables to /etc/environment for the MPI process.\u001b[0m\n",
      "\u001b[35m2023-07-02 09:05:03,161 sagemaker-training-toolkit INFO     Waiting for MPI process to finish.\u001b[0m\n",
      "\u001b[34m2023-07-02 09:05:03,734 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_8.2p1)\u001b[0m\n",
      "\u001b[34m2023-07-02 09:05:03,906 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[34m2023-07-02 09:05:03,906 sagemaker-training-toolkit INFO     Can connect to host algo-2 at port 22\u001b[0m\n",
      "\u001b[34m2023-07-02 09:05:03,907 sagemaker-training-toolkit INFO     Connection closed\u001b[0m\n",
      "\u001b[34m2023-07-02 09:05:03,907 sagemaker-training-toolkit INFO     Worker algo-2 available for communication\u001b[0m\n",
      "\u001b[34m2023-07-02 09:05:03,907 sagemaker-training-toolkit INFO     Network interface name: eth0\u001b[0m\n",
      "\u001b[34m2023-07-02 09:05:03,907 sagemaker-training-toolkit INFO     Host: ['algo-1', 'algo-2']\u001b[0m\n",
      "\u001b[34m2023-07-02 09:05:03,908 sagemaker-training-toolkit INFO     instance type: ml.p3.16xlarge\u001b[0m\n",
      "\u001b[34m2023-07-02 09:05:03,908 sagemaker-training-toolkit INFO     Env Hosts: ['algo-1', 'algo-2'] Hosts: ['algo-1:8', 'algo-2:8'] process_per_hosts: 8 num_processes: 16\u001b[0m\n",
      "\u001b[34m2023-07-02 09:05:03,978 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-07-02 09:05:03,992 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_distributed_dataparallel_custom_mpi_options\": \"\",\n",
      "        \"sagemaker_distributed_dataparallel_enabled\": true,\n",
      "        \"sagemaker_instance_type\": \"ml.p3.16xlarge\"\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.p3.16xlarge\",\n",
      "    \"distribution_hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"distribution_instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"backend\": \"smddp\",\n",
      "        \"batch-size\": 80,\n",
      "        \"height\": 128,\n",
      "        \"lr\": 0.0001,\n",
      "        \"model_name\": \"swin_b\",\n",
      "        \"num-classes\": 37,\n",
      "        \"num-epochs\": 15,\n",
      "        \"test-batch-size\": 200,\n",
      "        \"width\": 128\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.p3.16xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\",\n",
      "                \"algo-2\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"oxford-ml-p3-16xlarge-0702-08581688288298\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-322537213286/oxford-ml-p3-16xlarge-0702-08581688288298/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"pytorch_oxford_ddp\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 64,\n",
      "    \"num_gpus\": 8,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.16xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.16xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"pytorch_oxford_ddp.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"backend\":\"smddp\",\"batch-size\":80,\"height\":128,\"lr\":0.0001,\"model_name\":\"swin_b\",\"num-classes\":37,\"num-epochs\":15,\"test-batch-size\":200,\"width\":128}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=pytorch_oxford_ddp.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_distributed_dataparallel_custom_mpi_options\":\"\",\"sagemaker_distributed_dataparallel_enabled\":true,\"sagemaker_instance_type\":\"ml.p3.16xlarge\"}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.16xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.p3.16xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=pytorch_oxford_ddp\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=64\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-322537213286/oxford-ml-p3-16xlarge-0702-08581688288298/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_distributed_dataparallel_custom_mpi_options\":\"\",\"sagemaker_distributed_dataparallel_enabled\":true,\"sagemaker_instance_type\":\"ml.p3.16xlarge\"},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.p3.16xlarge\",\"distribution_hosts\":[\"algo-1\",\"algo-2\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"backend\":\"smddp\",\"batch-size\":80,\"height\":128,\"lr\":0.0001,\"model_name\":\"swin_b\",\"num-classes\":37,\"num-epochs\":15,\"test-batch-size\":200,\"width\":128},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"oxford-ml-p3-16xlarge-0702-08581688288298\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-322537213286/oxford-ml-p3-16xlarge-0702-08581688288298/source/sourcedir.tar.gz\",\"module_name\":\"pytorch_oxford_ddp\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.16xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"pytorch_oxford_ddp.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--backend\",\"smddp\",\"--batch-size\",\"80\",\"--height\",\"128\",\"--lr\",\"0.0001\",\"--model_name\",\"swin_b\",\"--num-classes\",\"37\",\"--num-epochs\",\"15\",\"--test-batch-size\",\"200\",\"--width\",\"128\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BACKEND=smddp\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=80\u001b[0m\n",
      "\u001b[34mSM_HP_HEIGHT=128\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.0001\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME=swin_b\u001b[0m\n",
      "\u001b[34mSM_HP_NUM-CLASSES=37\u001b[0m\n",
      "\u001b[34mSM_HP_NUM-EPOCHS=15\u001b[0m\n",
      "\u001b[34mSM_HP_TEST-BATCH-SIZE=200\u001b[0m\n",
      "\u001b[34mSM_HP_WIDTH=128\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34mmpirun --host algo-1:8,algo-2:8 -np 16 --allow-run-as-root --tag-output --oversubscribe -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -mca btl_vader_single_copy_mechanism none -mca plm_rsh_num_concurrent 2 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x SMDATAPARALLEL_USE_HOMOGENEOUS=1 -x FI_PROVIDER=efa -x RDMAV_FORK_SAFE=1 -x LD_PRELOAD=/opt/conda/lib/python3.9/site-packages/gethostname.cpython-39-x86_64-linux-gnu.so -x SMDATAPARALLEL_SERVER_ADDR=algo-1 -x SMDATAPARALLEL_SERVER_PORT=7592 -x SAGEMAKER_INSTANCE_TYPE=ml.p3.16xlarge smddprun /opt/conda/bin/python3.9 -m mpi4py pytorch_oxford_ddp.py --backend smddp --batch-size 80 --height 128 --lr 0.0001 --model_name swin_b --num-classes 37 --num-epochs 15 --test-batch-size 200 --width 128\u001b[0m\n",
      "\u001b[34mWarning: Permanently added 'algo-2,10.0.134.115' (ECDSA) to the list of known hosts.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\u001b[0m\n",
      "\u001b[35m2023-07-02 09:05:06,172 sagemaker-training-toolkit INFO     Process[es]: [psutil.Process(pid=68, name='orted', status='sleeping', started='09:05:04')]\u001b[0m\n",
      "\u001b[35m2023-07-02 09:05:06,173 sagemaker-training-toolkit INFO     Orted process found [psutil.Process(pid=68, name='orted', status='sleeping', started='09:05:04')]\u001b[0m\n",
      "\u001b[35m2023-07-02 09:05:06,173 sagemaker-training-toolkit INFO     Waiting for orted process [psutil.Process(pid=68, name='orted', status='sleeping', started='09:05:04')]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:start main function\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:start main function\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:start main function\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:start main function\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:start main function\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:start main function\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:start main function\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:start main function\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:start main function\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:start main function\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:start main function\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:start main function\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:start main function\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:start main function\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:start main function\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:start main function\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:DDP Mode\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:DDP Mode\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:DDP Mode\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:DDP Mode\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:DDP Mode\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:DDP Mode\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:DDP Mode\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:DDP Mode\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:DDP Mode\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:DDP Mode\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:DDP Mode\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:DDP Mode\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:DDP Mode\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:DDP Mode\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:DDP Mode\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:DDP Mode\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Bootstrap : Using eth0:10.0.137.57<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO cudaDriverVersion 12000\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:NCCL version 2.14.3+cuda11.7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO cudaDriverVersion 12000\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO cudaDriverVersion 12000\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO cudaDriverVersion 12000\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO cudaDriverVersion 12000\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO cudaDriverVersion 12000\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO cudaDriverVersion 12000\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO cudaDriverVersion 12000\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO cudaDriverVersion 12000\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO cudaDriverVersion 12000\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO cudaDriverVersion 12000\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO cudaDriverVersion 12000\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO cudaDriverVersion 12000\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO cudaDriverVersion 12000\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO cudaDriverVersion 12000\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO cudaDriverVersion 12000\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.137.57<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Bootstrap : Using eth0:10.0.137.57<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Bootstrap : Using eth0:10.0.137.57<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO NET/Socket : Using [0]eth0:10.0.137.57<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO NET/Socket : Using [0]eth0:10.0.137.57<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Bootstrap : Using eth0:10.0.137.57<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Bootstrap : Using eth0:10.0.137.57<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Bootstrap : Using eth0:10.0.137.57<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Bootstrap : Using eth0:10.0.134.115<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Bootstrap : Using eth0:10.0.134.115<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Bootstrap : Using eth0:10.0.134.115<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Bootstrap : Using eth0:10.0.137.57<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Bootstrap : Using eth0:10.0.134.115<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Bootstrap : Using eth0:10.0.134.115<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Bootstrap : Using eth0:10.0.134.115<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Bootstrap : Using eth0:10.0.134.115<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO NET/Socket : Using [0]eth0:10.0.137.57<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Bootstrap : Using eth0:10.0.137.57<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Bootstrap : Using eth0:10.0.134.115<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v6 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin symbol (v4 or v5).\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO NET/Socket : Using [0]eth0:10.0.137.57<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO NET/Socket : Using [0]eth0:10.0.137.57<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO NET/Socket : Using [0]eth0:10.0.137.57<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO NET/OFI Using aws-ofi-nccl 1.4.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO NET/Socket : Using [0]eth0:10.0.137.57<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO NET/Socket : Using [0]eth0:10.0.134.115<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO NET/Socket : Using [0]eth0:10.0.134.115<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO NET/Socket : Using [0]eth0:10.0.134.115<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO NET/Socket : Using [0]eth0:10.0.134.115<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO NET/Socket : Using [0]eth0:10.0.134.115<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO NET/Socket : Using [0]eth0:10.0.134.115<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO NET/Socket : Using [0]eth0:10.0.134.115<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO NET/Socket : Using [0]eth0:10.0.134.115<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Trees [0] 4/-1/-1->7->6 [1] 4/-1/-1->7->6\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Trees [0] -1/-1/-1->4->7 [1] -1/-1/-1->4->7\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Trees [0] 2/-1/-1->3->0 [1] 2/-1/-1->3->0\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Trees [0] 1/-1/-1->2->3 [1] 1/-1/-1->2->3\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Trees [0] 6/-1/-1->5->1 [1] 6/-1/-1->5->1\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Trees [0] 5/-1/-1->1->2 [1] 5/-1/-1->1->2\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 00/02 :    0   3   2   1   5   6   7   4   8  11  10   9  13  14  15  12\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 01/02 :    0   3   2   1   5   6   7   4   8  11  10   9  13  14  15  12\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Trees [0] 3/8/-1->0->-1 [1] 3/-1/-1->0->8\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Trees [0] 9/-1/-1->10->11 [1] 9/-1/-1->10->11\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Trees [0] 12/-1/-1->15->14 [1] 12/-1/-1->15->14\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Trees [0] -1/-1/-1->12->15 [1] -1/-1/-1->12->15\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Trees [0] 10/-1/-1->11->8 [1] 10/-1/-1->11->8\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Trees [0] 13/-1/-1->9->10 [1] 13/-1/-1->9->10\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Trees [0] 14/-1/-1->13->9 [1] 14/-1/-1->13->9\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Trees [0] 15/-1/-1->14->13 [1] 15/-1/-1->14->13\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Trees [0] 11/-1/-1->8->0 [1] 11/0/-1->8->-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 00/0 : 9[180] -> 13[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 00/0 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 00/0 : 13[1c0] -> 14[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 00/0 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 00/0 : 8[170] -> 11[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 00/0 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 01/0 : 9[180] -> 13[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 01/0 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 01/0 : 8[170] -> 11[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 01/0 : 13[1c0] -> 14[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 01/0 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 01/0 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 00/0 : 10[190] -> 9[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 00/0 : 14[1d0] -> 15[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 00/0 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 00/0 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 00/0 : 12[1b0] -> 0[170] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 01/0 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 01/0 : 10[190] -> 9[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 01/0 : 14[1d0] -> 15[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 00/0 : 4[1b0] -> 8[170] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 00/0 : 11[1a0] -> 10[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 01/0 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 00/0 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 01/0 : 11[1a0] -> 10[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 00/0 : 15[1e0] -> 12[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 01/0 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 00/0 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 01/0 : 15[1e0] -> 12[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 01/0 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 00/0 : 14[1d0] -> 13[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 00/0 : 13[1c0] -> 9[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 01/0 : 14[1d0] -> 13[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 01/0 : 13[1c0] -> 9[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 00/0 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 00/0 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 01/0 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 01/0 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 00/0 : 9[180] -> 10[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 01/0 : 9[180] -> 10[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 00/0 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 00/0 : 10[190] -> 11[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 01/0 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 01/0 : 10[190] -> 11[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 00/0 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 01/0 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 00/0 : 11[1a0] -> 8[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 01/0 : 11[1a0] -> 8[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 00/1 : 10[190] -> 12[1b0] via P2P/indirect/8[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 00/0 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 00/1 : 9[180] -> 12[1b0] via P2P/indirect/8[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 00/1 : 2[190] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 01/0 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 00/1 : 1[180] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 01/1 : 10[190] -> 12[1b0] via P2P/indirect/8[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 01/1 : 2[190] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 01/1 : 9[180] -> 12[1b0] via P2P/indirect/8[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 01/1 : 1[180] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 01/0 : 4[1b0] -> 8[170] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 01/0 : 12[1b0] -> 0[170] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:1288 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 00/0 : 4[1b0] -> 8[170] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:1355 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 00/0 : 12[1b0] -> 0[170] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:1288 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 01/0 : 4[1b0] -> 8[170] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:1355 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 01/0 : 12[1b0] -> 0[170] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 00/0 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 01/0 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 00/0 : 12[1b0] -> 15[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 01/0 : 12[1b0] -> 15[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 00/0 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 01/0 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 00/0 : 15[1e0] -> 14[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 01/0 : 15[1e0] -> 14[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:1288 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 00/0 : 0[170] -> 8[170] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:1355 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 00/0 : 8[170] -> 0[170] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:1288 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 01/0 : 0[170] -> 8[170] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:1355 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 01/0 : 8[170] -> 0[170] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 00/0 : 8[170] -> 0[170] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 00/0 : 0[170] -> 8[170] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 01/0 : 8[170] -> 0[170] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 01/0 : 0[170] -> 8[170] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 00/1 : 8[170] -> 13[1c0] via P2P/indirect/9[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 00/1 : 11[1a0] -> 12[1b0] via P2P/indirect/8[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO 2 coll channels, 2 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 00/1 : 0[170] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 00/1 : 3[1a0] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 01/1 : 11[1a0] -> 12[1b0] via P2P/indirect/8[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 01/1 : 8[170] -> 13[1c0] via P2P/indirect/9[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 01/1 : 3[1a0] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 01/1 : 0[170] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 00/1 : 11[1a0] -> 13[1c0] via P2P/indirect/9[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 00/1 : 3[1a0] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 01/1 : 11[1a0] -> 13[1c0] via P2P/indirect/9[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 01/1 : 3[1a0] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 00/1 : 11[1a0] -> 14[1d0] via P2P/indirect/15[1e0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 00/1 : 10[190] -> 13[1c0] via P2P/indirect/9[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 00/1 : 3[1a0] -> 6[1d0] via P2P/indirect/7[1e0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 00/1 : 2[190] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 01/1 : 11[1a0] -> 14[1d0] via P2P/indirect/15[1e0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 01/1 : 10[190] -> 13[1c0] via P2P/indirect/9[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 01/1 : 2[190] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 01/1 : 3[1a0] -> 6[1d0] via P2P/indirect/7[1e0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 00/1 : 12[1b0] -> 9[180] via P2P/indirect/13[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 00/1 : 9[180] -> 14[1d0] via P2P/indirect/13[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 00/1 : 10[190] -> 15[1e0] via P2P/indirect/14[1d0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 00/1 : 4[1b0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 00/1 : 1[180] -> 6[1d0] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 00/1 : 2[190] -> 7[1e0] via P2P/indirect/6[1d0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 01/1 : 12[1b0] -> 9[180] via P2P/indirect/13[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 01/1 : 4[1b0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 01/1 : 9[180] -> 14[1d0] via P2P/indirect/13[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 01/1 : 10[190] -> 15[1e0] via P2P/indirect/14[1d0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 01/1 : 1[180] -> 6[1d0] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 01/1 : 2[190] -> 7[1e0] via P2P/indirect/6[1d0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 00/1 : 9[180] -> 15[1e0] via P2P/indirect/11[1a0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 00/1 : 13[1c0] -> 8[170] via P2P/indirect/12[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 00/1 : 8[170] -> 14[1d0] via P2P/indirect/12[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 00/1 : 0[170] -> 6[1d0] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 00/1 : 5[1c0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 01/1 : 13[1c0] -> 8[170] via P2P/indirect/12[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 00/1 : 1[180] -> 7[1e0] via P2P/indirect/3[1a0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 01/1 : 5[1c0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 01/1 : 9[180] -> 15[1e0] via P2P/indirect/11[1a0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 01/1 : 0[170] -> 6[1d0] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 01/1 : 8[170] -> 14[1d0] via P2P/indirect/12[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 01/1 : 1[180] -> 7[1e0] via P2P/indirect/3[1a0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 00/1 : 8[170] -> 15[1e0] via P2P/indirect/12[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 00/1 : 14[1d0] -> 8[170] via P2P/indirect/12[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 01/1 : 8[170] -> 15[1e0] via P2P/indirect/12[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 00/1 : 6[1d0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 00/1 : 0[170] -> 7[1e0] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 01/1 : 14[1d0] -> 8[170] via P2P/indirect/12[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 01/1 : 6[1d0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 01/1 : 0[170] -> 7[1e0] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 00/1 : 15[1e0] -> 8[170] via P2P/indirect/12[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 01/1 : 15[1e0] -> 8[170] via P2P/indirect/12[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 00/1 : 7[1e0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 01/1 : 7[1e0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 00/1 : 15[1e0] -> 9[180] via P2P/indirect/13[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 01/1 : 15[1e0] -> 9[180] via P2P/indirect/13[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 00/1 : 7[1e0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 01/1 : 7[1e0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 00/1 : 14[1d0] -> 9[180] via P2P/indirect/13[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 00/1 : 15[1e0] -> 10[190] via P2P/indirect/11[1a0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 00/1 : 7[1e0] -> 2[190] via P2P/indirect/3[1a0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 01/1 : 14[1d0] -> 9[180] via P2P/indirect/13[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 00/1 : 6[1d0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 01/1 : 15[1e0] -> 10[190] via P2P/indirect/11[1a0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 01/1 : 7[1e0] -> 2[190] via P2P/indirect/3[1a0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 01/1 : 6[1d0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 00/1 : 13[1c0] -> 10[190] via P2P/indirect/9[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 00/1 : 5[1c0] -> 2[190] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 00/1 : 14[1d0] -> 11[1a0] via P2P/indirect/10[190]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 01/1 : 13[1c0] -> 10[190] via P2P/indirect/9[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 00/1 : 6[1d0] -> 3[1a0] via P2P/indirect/2[190]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 01/1 : 14[1d0] -> 11[1a0] via P2P/indirect/10[190]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 01/1 : 5[1c0] -> 2[190] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 01/1 : 6[1d0] -> 3[1a0] via P2P/indirect/2[190]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 00/1 : 13[1c0] -> 11[1a0] via P2P/indirect/9[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 00/1 : 5[1c0] -> 3[1a0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 00/1 : 12[1b0] -> 10[190] via P2P/indirect/14[1d0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 00/1 : 4[1b0] -> 2[190] via P2P/indirect/6[1d0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 01/1 : 13[1c0] -> 11[1a0] via P2P/indirect/9[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 01/1 : 12[1b0] -> 10[190] via P2P/indirect/14[1d0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 01/1 : 4[1b0] -> 2[190] via P2P/indirect/6[1d0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 00/1 : 12[1b0] -> 11[1a0] via P2P/indirect/8[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 01/1 : 5[1c0] -> 3[1a0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 01/1 : 12[1b0] -> 11[1a0] via P2P/indirect/8[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 00/1 : 4[1b0] -> 3[1a0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 01/1 : 4[1b0] -> 3[1a0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO comm 0x561378d17780 rank 2 nranks 16 cudaDev 2 busId 190 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO comm 0x56024a3c5210 rank 1 nranks 16 cudaDev 1 busId 180 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO comm 0x56039d2aa540 rank 12 nranks 16 cudaDev 4 busId 1b0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO comm 0x55707bbdf320 rank 15 nranks 16 cudaDev 7 busId 1e0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO comm 0x5600dc60cb50 rank 5 nranks 16 cudaDev 5 busId 1c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO comm 0x5572e795d650 rank 9 nranks 16 cudaDev 1 busId 180 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO comm 0x564db584f6f0 rank 6 nranks 16 cudaDev 6 busId 1d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO comm 0x56242eef3780 rank 10 nranks 16 cudaDev 2 busId 190 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO comm 0x56488c875190 rank 4 nranks 16 cudaDev 4 busId 1b0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO comm 0x559ef39502d0 rank 14 nranks 16 cudaDev 6 busId 1d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO comm 0x565245beb570 rank 8 nranks 16 cudaDev 0 busId 170 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO comm 0x562722c4e440 rank 7 nranks 16 cudaDev 7 busId 1e0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:NCCL version 2.14.3+cuda11.7\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO comm 0x564bf2a9f520 rank 3 nranks 16 cudaDev 3 busId 1a0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO comm 0x560bb622a530 rank 0 nranks 16 cudaDev 0 busId 170 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO comm 0x55d3d168cde0 rank 13 nranks 16 cudaDev 5 busId 1c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO comm 0x559039580860 rank 11 nranks 16 cudaDev 3 busId 1a0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Trees [0] 6/-1/-1->5->1 [1] 6/-1/-1->5->1 [2] 1/-1/-1->5->6 [3] 1/-1/-1->5->6 [4] 4/-1/-1->5->7 [5] 7/-1/-1->5->4 [6] 6/-1/-1->5->1 [7] 6/-1/-1->5->1 [8] 1/-1/-1->5->6 [9] 1/-1/-1->5->6 [10] 4/-1/-1->5->7 [11] 7/-1/-1->5->4\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 00/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 01/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 02/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 03/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 04/12 :    0   1   3   7   5   4   6   2\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 05/12 :    0   2   6   4   5   7   3   1\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 06/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 07/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 08/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 09/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 10/12 :    0   1   3   7   5   4   6   2\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 11/12 :    0   2   6   4   5   7   3   1\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Trees [0] 3/-1/-1->0->-1 [1] 3/-1/-1->0->-1 [2] 4/-1/-1->0->-1 [3] 4/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 3/-1/-1->0->-1 [7] 3/-1/-1->0->-1 [8] 4/-1/-1->0->-1 [9] 4/-1/-1->0->-1 [10] 1/-1/-1->0->-1 [11] 2/-1/-1->0->-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Trees [0] 1/-1/-1->2->3 [1] 1/-1/-1->2->3 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] -1/-1/-1->2->6 [5] 6/-1/-1->2->0 [6] 1/-1/-1->2->3 [7] 1/-1/-1->2->3 [8] 3/-1/-1->2->1 [9] 3/-1/-1->2->1 [10] -1/-1/-1->2->6 [11] 6/-1/-1->2->0\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Trees [0] 5/-1/-1->1->2 [1] 5/-1/-1->1->2 [2] 2/-1/-1->1->5 [3] 2/-1/-1->1->5 [4] 3/-1/-1->1->0 [5] -1/-1/-1->1->3 [6] 5/-1/-1->1->2 [7] 5/-1/-1->1->2 [8] 2/-1/-1->1->5 [9] 2/-1/-1->1->5 [10] 3/-1/-1->1->0 [11] -1/-1/-1->1->3\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Trees [0] 4/-1/-1->7->6 [1] 4/-1/-1->7->6 [2] 6/-1/-1->7->4 [3] 6/-1/-1->7->4 [4] 5/-1/-1->7->3 [5] 3/-1/-1->7->5 [6] 4/-1/-1->7->6 [7] 4/-1/-1->7->6 [8] 6/-1/-1->7->4 [9] 6/-1/-1->7->4 [10] 5/-1/-1->7->3 [11] 3/-1/-1->7->5\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 5/-1/-1->6->7 [3] 5/-1/-1->6->7 [4] 2/-1/-1->6->4 [5] 4/-1/-1->6->2 [6] 7/-1/-1->6->5 [7] 7/-1/-1->6->5 [8] 5/-1/-1->6->7 [9] 5/-1/-1->6->7 [10] 2/-1/-1->6->4 [11] 4/-1/-1->6->2\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Trees [0] -1/-1/-1->4->7 [1] -1/-1/-1->4->7 [2] 7/-1/-1->4->0 [3] 7/-1/-1->4->0 [4] 6/-1/-1->4->5 [5] 5/-1/-1->4->6 [6] -1/-1/-1->4->7 [7] -1/-1/-1->4->7 [8] 7/-1/-1->4->0 [9] 7/-1/-1->4->0 [10] 6/-1/-1->4->5 [11] 5/-1/-1->4->6\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Trees [0] 2/-1/-1->3->0 [1] 2/-1/-1->3->0 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] 7/-1/-1->3->1 [5] 1/-1/-1->3->7 [6] 2/-1/-1->3->0 [7] 2/-1/-1->3->0 [8] -1/-1/-1->3->2 [9] -1/-1/-1->3->2 [10] 7/-1/-1->3->1 [11] 1/-1/-1->3->7\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 05/0 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 04/0 : 0[170] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 10/0 : 0[170] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 11/0 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 5/-1/-1->6->7 [3] 5/-1/-1->6->7 [4] 2/-1/-1->6->4 [5] 4/-1/-1->6->2 [6] 7/-1/-1->6->5 [7] 7/-1/-1->6->5 [8] 5/-1/-1->6->7 [9] 5/-1/-1->6->7 [10] 2/-1/-1->6->4 [11] 4/-1/-1->6->2\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Trees [0] 2/-1/-1->3->0 [1] 2/-1/-1->3->0 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] 7/-1/-1->3->1 [5] 1/-1/-1->3->7 [6] 2/-1/-1->3->0 [7] 2/-1/-1->3->0 [8] -1/-1/-1->3->2 [9] -1/-1/-1->3->2 [10] 7/-1/-1->3->1 [11] 1/-1/-1->3->7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 00/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 01/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 02/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 03/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 04/12 :    0   1   3   7   5   4   6   2\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 05/12 :    0   2   6   4   5   7   3   1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 06/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 07/12 :    0   3   2   1   5   6   7   4\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 08/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 09/12 :    0   4   7   6   5   1   2   3\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 10/12 :    0   1   3   7   5   4   6   2\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 11/12 :    0   2   6   4   5   7   3   1\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Trees [0] -1/-1/-1->4->7 [1] -1/-1/-1->4->7 [2] 7/-1/-1->4->0 [3] 7/-1/-1->4->0 [4] 6/-1/-1->4->5 [5] 5/-1/-1->4->6 [6] -1/-1/-1->4->7 [7] -1/-1/-1->4->7 [8] 7/-1/-1->4->0 [9] 7/-1/-1->4->0 [10] 6/-1/-1->4->5 [11] 5/-1/-1->4->6\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Trees [0] 5/-1/-1->1->2 [1] 5/-1/-1->1->2 [2] 2/-1/-1->1->5 [3] 2/-1/-1->1->5 [4] 3/-1/-1->1->0 [5] -1/-1/-1->1->3 [6] 5/-1/-1->1->2 [7] 5/-1/-1->1->2 [8] 2/-1/-1->1->5 [9] 2/-1/-1->1->5 [10] 3/-1/-1->1->0 [11] -1/-1/-1->1->3\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Trees [0] 4/-1/-1->7->6 [1] 4/-1/-1->7->6 [2] 6/-1/-1->7->4 [3] 6/-1/-1->7->4 [4] 5/-1/-1->7->3 [5] 3/-1/-1->7->5 [6] 4/-1/-1->7->6 [7] 4/-1/-1->7->6 [8] 6/-1/-1->7->4 [9] 6/-1/-1->7->4 [10] 5/-1/-1->7->3 [11] 3/-1/-1->7->5\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Trees [0] 1/-1/-1->2->3 [1] 1/-1/-1->2->3 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] -1/-1/-1->2->6 [5] 6/-1/-1->2->0 [6] 1/-1/-1->2->3 [7] 1/-1/-1->2->3 [8] 3/-1/-1->2->1 [9] 3/-1/-1->2->1 [10] -1/-1/-1->2->6 [11] 6/-1/-1->2->0\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Trees [0] 6/-1/-1->5->1 [1] 6/-1/-1->5->1 [2] 1/-1/-1->5->6 [3] 1/-1/-1->5->6 [4] 4/-1/-1->5->7 [5] 7/-1/-1->5->4 [6] 6/-1/-1->5->1 [7] 6/-1/-1->5->1 [8] 1/-1/-1->5->6 [9] 1/-1/-1->5->6 [10] 4/-1/-1->5->7 [11] 7/-1/-1->5->4\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Trees [0] 3/-1/-1->0->-1 [1] 3/-1/-1->0->-1 [2] 4/-1/-1->0->-1 [3] 4/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 3/-1/-1->0->-1 [7] 3/-1/-1->0->-1 [8] 4/-1/-1->0->-1 [9] 4/-1/-1->0->-1 [10] 1/-1/-1->0->-1 [11] 2/-1/-1->0->-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 05/0 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 04/0 : 0[170] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 00/0 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 02/0 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 01/0 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 03/0 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 00/0 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 02/0 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 06/0 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 08/0 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 01/0 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 03/0 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 11/0 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 09/0 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 07/0 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 06/0 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 08/0 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 07/0 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 09/0 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 00/0 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 02/0 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 05/0 : 0[170] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 04/0 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 03/0 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 01/0 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 02/0 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 06/0 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 08/0 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 11/0 : 0[170] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 00/0 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 03/0 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 09/0 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 07/0 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 10/0 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 01/0 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 08/0 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 09/0 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 06/0 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 04/0 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 07/0 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 10/0 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 05/0 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 11/0 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 04/0 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 10/0 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 05/0 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 11/0 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 02/0 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 03/0 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 02/0 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 03/0 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 00/0 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 04/0 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 08/0 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 04/0 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 08/0 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 02/0 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 10/0 : 0[170] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 10/0 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 09/0 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 10/0 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 09/0 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 01/0 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 03/0 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 08/0 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 05/0 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 06/0 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 00/0 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 05/0 : 0[170] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 11/0 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 09/0 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 07/0 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 02/0 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 01/0 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 11/0 : 0[170] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 04/0 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 03/0 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 06/0 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 10/0 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 05/0 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 00/0 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 08/0 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 11/0 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 07/0 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 01/0 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 04/0 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 05/0 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 05/0 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 00/0 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 06/0 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 09/0 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 10/0 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 11/0 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 11/0 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 01/0 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 07/0 : 0[170] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 05/0 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 06/0 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 11/0 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 07/0 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 04/0 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 00/0 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 00/0 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 04/0 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 05/0 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 10/0 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 01/0 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 01/0 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 10/0 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 11/0 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 06/0 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 02/0 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 06/0 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 07/0 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 03/0 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 07/0 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 04/0 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 00/0 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 10/0 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 08/0 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 02/0 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 01/0 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 03/0 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 09/0 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 08/0 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 02/0 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 06/0 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 07/0 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 09/0 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 03/0 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 00/0 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 08/0 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 02/0 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 09/0 : 0[170] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 01/0 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 03/0 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 06/0 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 08/0 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 07/0 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 09/0 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 05/0 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 04/0 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 11/0 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 10/0 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 00/0 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 05/0 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 04/0 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 02/0 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 11/0 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 10/0 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 01/0 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 03/0 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 06/0 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 00/0 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 08/0 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 07/0 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 09/0 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 05/0 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 02/0 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 00/0 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 02/0 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 04/0 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 11/0 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 01/0 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 03/0 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 01/0 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 10/0 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 08/0 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 06/0 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 03/0 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 06/0 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 09/0 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 07/0 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 04/0 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 08/0 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 07/0 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 09/0 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 05/0 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 10/0 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 00/0 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 02/0 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 04/0 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 11/0 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 01/0 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 03/0 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 10/0 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 06/0 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 08/0 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 07/0 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 09/0 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 04/0 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 00/0 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 10/0 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 01/0 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 02/0 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 06/0 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 03/0 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 00/0 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 07/0 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 08/0 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 09/0 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 01/0 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 00/0 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 02/0 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 01/0 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 03/0 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 06/0 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 05/0 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 06/0 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 08/0 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 07/0 : 1[180] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 11/0 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 07/0 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 09/0 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 02/0 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 03/0 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 08/0 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 09/0 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 00/0 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 02/0 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 05/0 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 01/0 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 03/0 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 06/0 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 08/0 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 07/0 : 2[190] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 11/0 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 09/0 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 04/0 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 10/0 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 05/0 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 04/0 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 05/0 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 11/0 : 4[1b0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 10/0 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 05/0 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 00/0 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 11/0 : 1[180] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 11/0 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 01/0 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 04/0 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 02/0 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 05/0 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 06/0 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 03/0 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 10/0 : 5[1c0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 07/0 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 11/0 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 08/0 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 09/0 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 04/0 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 05/0 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 10/0 : 2[190] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 00/0 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 04/0 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 05/0 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 11/0 : 3[1a0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 10/0 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 00/0 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 11/0 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 01/0 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 06/0 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 01/0 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 00/0 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 07/0 : 4[1b0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 02/0 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 06/0 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 01/0 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 05/0 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 07/0 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 03/0 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 06/0 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 04/0 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 08/0 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 11/0 : 6[1d0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 02/0 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 10/0 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 07/0 : 5[1c0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 09/0 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 03/0 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 02/0 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 08/0 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 03/0 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 09/0 : 1[180] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 04/0 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 05/0 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 04/0 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 08/0 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 10/0 : 6[1d0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 10/0 : 7[1e0] -> 3[1a0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 09/0 : 4[1b0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 11/0 : 2[190] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 02/0 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 00/0 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 03/0 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 01/0 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 08/0 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 06/0 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 09/0 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 07/0 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 02/0 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 00/0 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 03/0 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 01/0 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 05/0 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 04/0 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 11/0 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 08/0 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 06/0 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 10/0 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 09/0 : 7[1e0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 07/0 : 3[1a0] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 00/0 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 02/0 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 05/0 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 04/0 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 01/0 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 11/0 : 7[1e0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 10/0 : 3[1a0] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 03/0 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 06/0 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 08/0 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 07/0 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 00/0 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 09/0 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 05/0 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 00/0 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 02/0 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 04/0 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 02/0 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 01/0 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 11/0 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 10/0 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 03/0 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 06/0 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 08/0 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 01/0 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 03/0 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 07/0 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 09/0 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 06/0 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 08/0 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 07/0 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 09/0 : 3[1a0] -> 2[190] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 05/0 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 04/0 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 02/0 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 00/0 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 10/0 : 1[180] -> 0[170] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 11/0 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 03/0 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 01/0 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 08/1 : 7[1e0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 08/0 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 06/0 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 08/1 : 3[1a0] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 09/0 : 2[190] -> 1[180] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 07/0 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 04/1 : 6[1d0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 04/1 : 2[190] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 09/1 : 3[1a0] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 09/1 : 7[1e0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 08/1 : 3[1a0] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 04/1 : 7[1e0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 04/1 : 3[1a0] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 05/1 : 6[1d0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 08/1 : 7[1e0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 05/1 : 2[190] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 05/1 : 7[1e0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 05/1 : 3[1a0] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 04/1 : 2[190] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 512 | 512\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 04/1 : 6[1d0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 09/1 : 7[1e0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 09/1 : 3[1a0] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 12/1 : 7[1e0] -> 2[190] via P2P/indirect/3[1a0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 12/1 : 3[1a0] -> 6[1d0] via P2P/indirect/7[1e0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 04/1 : 7[1e0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 05/1 : 6[1d0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 04/1 : 3[1a0] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 05/1 : 2[190] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 12/1 : 5[1c0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO Channel 13/1 : 7[1e0] -> 2[190] via P2P/indirect/3[1a0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 05/1 : 7[1e0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO Channel 13/1 : 3[1a0] -> 6[1d0] via P2P/indirect/7[1e0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 05/1 : 3[1a0] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 12/1 : 1[180] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 12/1 : 7[1e0] -> 2[190] via P2P/indirect/3[1a0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 12/1 : 6[1d0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 13/1 : 5[1c0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 13/1 : 1[180] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 12/1 : 2[190] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 12/1 : 3[1a0] -> 6[1d0] via P2P/indirect/7[1e0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 10/1 : 0[170] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO Channel 13/1 : 7[1e0] -> 2[190] via P2P/indirect/3[1a0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 13/1 : 6[1d0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 11/1 : 0[170] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 10/1 : 4[1b0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 13/1 : 2[190] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO Channel 13/1 : 3[1a0] -> 6[1d0] via P2P/indirect/7[1e0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 12/1 : 5[1c0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 11/1 : 4[1b0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 12/1 : 6[1d0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 12/1 : 1[180] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 12/1 : 2[190] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 13/1 : 5[1c0] -> 0[170] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 13/1 : 6[1d0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 13/1 : 1[180] -> 4[1b0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 13/1 : 2[190] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 10/1 : 6[1d0] -> 3[1a0] via P2P/indirect/2[190]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 10/1 : 0[170] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 10/1 : 1[180] -> 6[1d0] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO Channel 11/1 : 6[1d0] -> 3[1a0] via P2P/indirect/2[190]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 10/1 : 4[1b0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 11/1 : 1[180] -> 6[1d0] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 10/1 : 5[1c0] -> 2[190] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 10/1 : 2[190] -> 7[1e0] via P2P/indirect/6[1d0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 11/1 : 0[170] -> 5[1c0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 06/1 : 4[1b0] -> 2[190] via P2P/indirect/6[1d0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 11/1 : 5[1c0] -> 2[190] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 11/1 : 4[1b0] -> 1[180] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 06/1 : 1[180] -> 7[1e0] via P2P/indirect/3[1a0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO Channel 11/1 : 2[190] -> 7[1e0] via P2P/indirect/6[1d0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 07/1 : 4[1b0] -> 2[190] via P2P/indirect/6[1d0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 10/1 : 2[190] -> 7[1e0] via P2P/indirect/6[1d0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO Channel 07/1 : 1[180] -> 7[1e0] via P2P/indirect/3[1a0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 06/1 : 0[170] -> 6[1d0] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 10/1 : 6[1d0] -> 3[1a0] via P2P/indirect/2[190]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 10/1 : 5[1c0] -> 2[190] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO Channel 11/1 : 2[190] -> 7[1e0] via P2P/indirect/6[1d0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 10/1 : 1[180] -> 6[1d0] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 11/1 : 5[1c0] -> 2[190] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO Channel 11/1 : 6[1d0] -> 3[1a0] via P2P/indirect/2[190]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 07/1 : 0[170] -> 6[1d0] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 11/1 : 1[180] -> 6[1d0] via P2P/indirect/5[1c0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 06/1 : 5[1c0] -> 3[1a0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 14/1 : 0[170] -> 7[1e0] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO Channel 07/1 : 5[1c0] -> 3[1a0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 06/1 : 0[170] -> 6[1d0] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO Channel 15/1 : 0[170] -> 7[1e0] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 06/1 : 4[1b0] -> 2[190] via P2P/indirect/6[1d0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 14/1 : 4[1b0] -> 3[1a0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 07/1 : 0[170] -> 6[1d0] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 06/1 : 5[1c0] -> 3[1a0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO Channel 15/1 : 4[1b0] -> 3[1a0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 07/1 : 4[1b0] -> 2[190] via P2P/indirect/6[1d0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 06/1 : 1[180] -> 7[1e0] via P2P/indirect/3[1a0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO Channel 07/1 : 5[1c0] -> 3[1a0] via P2P/indirect/1[180]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO Channel 07/1 : 1[180] -> 7[1e0] via P2P/indirect/3[1a0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 14/1 : 0[170] -> 7[1e0] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 14/1 : 4[1b0] -> 3[1a0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO Channel 15/1 : 0[170] -> 7[1e0] via P2P/indirect/4[1b0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO Channel 15/1 : 4[1b0] -> 3[1a0] via P2P/indirect/0[170]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:algo-2:217:217 [6] NCCL INFO comm 0x559ef3b4b330 rank 6 nranks 8 cudaDev 6 busId 1d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:algo-2:212:212 [3] NCCL INFO comm 0x55903977b8c0 rank 3 nranks 8 cudaDev 3 busId 1a0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:algo-2:213:213 [1] NCCL INFO comm 0x5572e7b586b0 rank 1 nranks 8 cudaDev 1 busId 180 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:algo-2:208:208 [7] NCCL INFO comm 0x55707bdda380 rank 7 nranks 8 cudaDev 7 busId 1e0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:algo-2:605:605 [0] NCCL INFO comm 0x565245de65d0 rank 0 nranks 8 cudaDev 0 busId 170 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:algo-2:216:216 [5] NCCL INFO comm 0x55d3d1887e40 rank 5 nranks 8 cudaDev 5 busId 1c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:algo-2:142:142 [4] NCCL INFO comm 0x56039d4a55a0 rank 4 nranks 8 cudaDev 4 busId 1b0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:algo-2:209:209 [2] NCCL INFO comm 0x56242f0ee7e0 rank 2 nranks 8 cudaDev 2 busId 190 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:339:339 [1] NCCL INFO comm 0x56024a5c0270 rank 1 nranks 8 cudaDev 1 busId 180 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:algo-1:342:342 [5] NCCL INFO comm 0x5600dc807bb0 rank 5 nranks 8 cudaDev 5 busId 1c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:208:208 [3] NCCL INFO comm 0x564bf2c9a580 rank 3 nranks 8 cudaDev 3 busId 1a0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:algo-1:210:210 [4] NCCL INFO comm 0x56488ca701f0 rank 4 nranks 8 cudaDev 4 busId 1b0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:206:206 [2] NCCL INFO comm 0x561378f127e0 rank 2 nranks 8 cudaDev 2 busId 190 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:algo-1:343:343 [6] NCCL INFO comm 0x564db5a4a750 rank 6 nranks 8 cudaDev 6 busId 1d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:669:669 [0] NCCL INFO comm 0x560bb2c9aae0 rank 0 nranks 8 cudaDev 0 busId 170 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Running smdistributed.dataparallel v1.7.0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:SMDDP: Multi node ENA mode\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:algo-1:344:344 [7] NCCL INFO comm 0x562722e494a0 rank 7 nranks 8 cudaDev 7 busId 1e0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 8\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 9\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 10\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 11\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 12\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 13\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 14\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 15\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 12: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:=> using pre-trained model 'swin_b'\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:=> using pre-trained model 'swin_b'\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 14: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 13: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 15: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:=> using pre-trained model 'swin_b'\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:=> using pre-trained model 'swin_b'\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:=> using pre-trained model 'swin_b'\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:=> using pre-trained model 'swin_b'\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Swin_B_Weights.IMAGENET1K_V1`. You can also use `weights=Swin_B_Weights.DEFAULT` to get the most up-to-date weights.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:  warnings.warn(msg)\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Swin_B_Weights.IMAGENET1K_V1`. You can also use `weights=Swin_B_Weights.DEFAULT` to get the most up-to-date weights.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:  warnings.warn(msg)\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Swin_B_Weights.IMAGENET1K_V1`. You can also use `weights=Swin_B_Weights.DEFAULT` to get the most up-to-date weights.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:  warnings.warn(msg)\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Swin_B_Weights.IMAGENET1K_V1`. You can also use `weights=Swin_B_Weights.DEFAULT` to get the most up-to-date weights.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:  warnings.warn(msg)\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Swin_B_Weights.IMAGENET1K_V1`. You can also use `weights=Swin_B_Weights.DEFAULT` to get the most up-to-date weights.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:  warnings.warn(msg)\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Swin_B_Weights.IMAGENET1K_V1`. You can also use `weights=Swin_B_Weights.DEFAULT` to get the most up-to-date weights.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:  warnings.warn(msg)\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:=> using pre-trained model 'swin_b'\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Swin_B_Weights.IMAGENET1K_V1`. You can also use `weights=Swin_B_Weights.DEFAULT` to get the most up-to-date weights.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:  warnings.warn(msg)\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:=> using pre-trained model 'swin_b'\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:=> using pre-trained model 'swin_b'\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:=> using pre-trained model 'swin_b'\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:=> using pre-trained model 'swin_b'\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Swin_B_Weights.IMAGENET1K_V1`. You can also use `weights=Swin_B_Weights.DEFAULT` to get the most up-to-date weights.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:  warnings.warn(msg)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Swin_B_Weights.IMAGENET1K_V1`. You can also use `weights=Swin_B_Weights.DEFAULT` to get the most up-to-date weights.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:  warnings.warn(msg)\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Swin_B_Weights.IMAGENET1K_V1`. You can also use `weights=Swin_B_Weights.DEFAULT` to get the most up-to-date weights.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:  warnings.warn(msg)\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Swin_B_Weights.IMAGENET1K_V1`. You can also use `weights=Swin_B_Weights.DEFAULT` to get the most up-to-date weights.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:  warnings.warn(msg)\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:=> using pre-trained model 'swin_b'\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Swin_B_Weights.IMAGENET1K_V1`. You can also use `weights=Swin_B_Weights.DEFAULT` to get the most up-to-date weights.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:  warnings.warn(msg)\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:=> using pre-trained model 'swin_b'\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:=> using pre-trained model 'swin_b'\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:=> using pre-trained model 'swin_b'\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:=> using pre-trained model 'swin_b'\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Swin_B_Weights.IMAGENET1K_V1`. You can also use `weights=Swin_B_Weights.DEFAULT` to get the most up-to-date weights.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:  warnings.warn(msg)\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Swin_B_Weights.IMAGENET1K_V1`. You can also use `weights=Swin_B_Weights.DEFAULT` to get the most up-to-date weights.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:  warnings.warn(msg)\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:  warnings.warn(\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Swin_B_Weights.IMAGENET1K_V1`. You can also use `weights=Swin_B_Weights.DEFAULT` to get the most up-to-date weights.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:  warnings.warn(msg)\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Swin_B_Weights.IMAGENET1K_V1`. You can also use `weights=Swin_B_Weights.DEFAULT` to get the most up-to-date weights.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:  warnings.warn(msg)\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:Downloading: \"https://download.pytorch.org/models/swin_b-68c6b09e.pth\" to /root/.cache/torch/hub/checkpoints/swin_b-68c6b09e.pth\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:Downloading: \"https://download.pytorch.org/models/swin_b-68c6b09e.pth\" to /root/.cache/torch/hub/checkpoints/swin_b-68c6b09e.pth\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:Downloading: \"https://download.pytorch.org/models/swin_b-68c6b09e.pth\" to /root/.cache/torch/hub/checkpoints/swin_b-68c6b09e.pth\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:Downloading: \"https://download.pytorch.org/models/swin_b-68c6b09e.pth\" to /root/.cache/torch/hub/checkpoints/swin_b-68c6b09e.pth\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:Downloading: \"https://download.pytorch.org/models/swin_b-68c6b09e.pth\" to /root/.cache/torch/hub/checkpoints/swin_b-68c6b09e.pth\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:Downloading: \"https://download.pytorch.org/models/swin_b-68c6b09e.pth\" to /root/.cache/torch/hub/checkpoints/swin_b-68c6b09e.pth\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:Downloading: \"https://download.pytorch.org/models/swin_b-68c6b09e.pth\" to /root/.cache/torch/hub/checkpoints/swin_b-68c6b09e.pth\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:Downloading: \"https://download.pytorch.org/models/swin_b-68c6b09e.pth\" to /root/.cache/torch/hub/checkpoints/swin_b-68c6b09e.pth\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:Downloading: \"https://download.pytorch.org/models/swin_b-68c6b09e.pth\" to /root/.cache/torch/hub/checkpoints/swin_b-68c6b09e.pth\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:Downloading: \"https://download.pytorch.org/models/swin_b-68c6b09e.pth\" to /root/.cache/torch/hub/checkpoints/swin_b-68c6b09e.pth\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:Downloading: \"https://download.pytorch.org/models/swin_b-68c6b09e.pth\" to /root/.cache/torch/hub/checkpoints/swin_b-68c6b09e.pth\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:Downloading: \"https://download.pytorch.org/models/swin_b-68c6b09e.pth\" to /root/.cache/torch/hub/checkpoints/swin_b-68c6b09e.pth\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:Downloading: \"https://download.pytorch.org/models/swin_b-68c6b09e.pth\" to /root/.cache/torch/hub/checkpoints/swin_b-68c6b09e.pth\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:Downloading: \"https://download.pytorch.org/models/swin_b-68c6b09e.pth\" to /root/.cache/torch/hub/checkpoints/swin_b-68c6b09e.pth\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015  0%|          | 0.00/335M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015  0%|          | 0.00/335M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015  0%|          | 0.00/335M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015  0%|          | 0.00/335M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015  0%|          | 0.00/335M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015  0%|          | 0.00/335M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015  0%|          | 0.00/335M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015  0%|          | 0.00/335M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015  0%|          | 0.00/335M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015  0%|          | 0.00/335M [00:00<?, ?B/s][1,mpirank:4,algo-1]<stderr>:#015  0%|          | 0.00/335M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015  0%|          | 0.00/335M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015  0%|          | 0.00/335M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015  0%|          | 0.00/335M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:Downloading: \"https://download.pytorch.org/models/swin_b-68c6b09e.pth\" to /root/.cache/torch/hub/checkpoints/swin_b-68c6b09e.pth\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:Downloading: \"https://download.pytorch.org/models/swin_b-68c6b09e.pth\" to /root/.cache/torch/hub/checkpoints/swin_b-68c6b09e.pth\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015  2%|▏         | 6.88M/335M [00:00<00:04, 71.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015  2%|▏         | 7.32M/335M [00:00<00:04, 76.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015  2%|▏         | 7.49M/335M [00:00<00:04, 78.5MB/s][1,mpirank:11,algo-2]<stderr>:#015  2%|▏         | 7.51M/335M [00:00<00:04, 78.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015  2%|▏         | 7.59M/335M [00:00<00:04, 79.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015  2%|▏         | 7.84M/335M [00:00<00:04, 81.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015  0%|          | 0.00/335M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015  3%|▎         | 8.56M/335M [00:00<00:03, 89.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015  3%|▎         | 8.73M/335M [00:00<00:03, 91.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015  3%|▎         | 8.91M/335M [00:00<00:03, 93.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015  3%|▎         | 9.07M/335M [00:00<00:03, 95.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015  3%|▎         | 8.92M/335M [00:00<00:03, 93.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015  3%|▎         | 9.13M/335M [00:00<00:03, 95.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015  3%|▎         | 9.23M/335M [00:00<00:03, 96.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015  0%|          | 0.00/335M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015  3%|▎         | 9.50M/335M [00:00<00:03, 99.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015  4%|▍         | 13.7M/335M [00:00<00:04, 68.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015  4%|▍         | 14.5M/335M [00:00<00:02, 152MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015  4%|▍         | 14.6M/335M [00:00<00:04, 70.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015  4%|▍         | 15.0M/335M [00:00<00:04, 71.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015  4%|▍         | 15.0M/335M [00:00<00:04, 70.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015  5%|▍         | 15.2M/335M [00:00<00:04, 71.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015  5%|▍         | 15.6M/335M [00:00<00:04, 71.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015  3%|▎         | 10.0M/335M [00:00<00:03, 105MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015  5%|▌         | 17.1M/335M [00:00<00:04, 73.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015  5%|▌         | 17.5M/335M [00:00<00:04, 74.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015  5%|▌         | 17.8M/335M [00:00<00:04, 74.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015  5%|▌         | 17.8M/335M [00:00<00:04, 75.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015  5%|▌         | 18.1M/335M [00:00<00:04, 75.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015  5%|▌         | 18.2M/335M [00:00<00:04, 75.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015  5%|▌         | 18.4M/335M [00:00<00:04, 76.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015  6%|▌         | 19.0M/335M [00:00<00:04, 77.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015  6%|▌         | 20.2M/335M [00:00<00:04, 66.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015  6%|▋         | 21.8M/335M [00:00<00:04, 68.4MB/s][1,mpirank:8,algo-2]<stderr>:#015  6%|▋         | 21.4M/335M [00:00<00:04, 66.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015  6%|▋         | 21.8M/335M [00:00<00:04, 68.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015  7%|▋         | 22.0M/335M [00:00<00:04, 68.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015  6%|▌         | 20.0M/335M [00:00<00:03, 104MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015  7%|▋         | 22.5M/335M [00:00<00:04, 69.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015  7%|▋         | 24.3M/335M [00:00<00:04, 66.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015  7%|▋         | 24.7M/335M [00:00<00:05, 65.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015  7%|▋         | 25.1M/335M [00:00<00:05, 64.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015  8%|▊         | 25.3M/335M [00:00<00:05, 64.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015  8%|▊         | 25.6M/335M [00:00<00:05, 62.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015  8%|▊         | 25.7M/335M [00:00<00:05, 61.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015  8%|▊         | 25.9M/335M [00:00<00:05, 62.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015  8%|▊         | 26.6M/335M [00:00<00:05, 57.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015  8%|▊         | 26.6M/335M [00:00<00:05, 62.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015  8%|▊         | 27.8M/335M [00:00<00:05, 58.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015  8%|▊         | 28.3M/335M [00:00<00:05, 58.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015  8%|▊         | 28.3M/335M [00:00<00:05, 58.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015  9%|▊         | 28.6M/335M [00:00<00:05, 59.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015  9%|▊         | 29.0M/335M [00:00<00:04, 75.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015  9%|▊         | 29.2M/335M [00:00<00:05, 59.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015  9%|▉         | 29.9M/335M [00:00<00:03, 81.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015  9%|▉         | 30.7M/335M [00:00<00:05, 62.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015  9%|▉         | 31.1M/335M [00:00<00:05, 62.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015  9%|▉         | 31.4M/335M [00:00<00:05, 63.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015  9%|▉         | 31.6M/335M [00:00<00:05, 63.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015  9%|▉         | 31.8M/335M [00:00<00:05, 63.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 10%|▉         | 31.9M/335M [00:00<00:05, 62.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 10%|▉         | 32.1M/335M [00:00<00:05, 62.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 10%|▉         | 32.5M/335M [00:00<00:05, 59.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 10%|▉         | 32.9M/335M [00:00<00:05, 62.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 10%|█         | 33.7M/335M [00:00<00:05, 59.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 10%|█         | 34.1M/335M [00:00<00:05, 57.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 10%|█         | 34.1M/335M [00:00<00:05, 56.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 10%|█         | 34.3M/335M [00:00<00:06, 50.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 10%|█         | 35.1M/335M [00:00<00:06, 45.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 11%|█         | 36.7M/335M [00:00<00:06, 45.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 11%|█         | 37.2M/335M [00:00<00:09, 32.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 11%|█         | 37.6M/335M [00:00<00:09, 31.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 11%|█▏        | 37.8M/335M [00:00<00:09, 31.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 11%|█▏        | 38.0M/335M [00:00<00:09, 31.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 11%|█▏        | 38.2M/335M [00:00<00:08, 37.5MB/s][1,mpirank:1,algo-1]<stderr>:#015 11%|█▏        | 38.1M/335M [00:00<00:08, 38.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 11%|█▏        | 38.1M/335M [00:00<00:09, 31.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 11%|█▏        | 38.2M/335M [00:00<00:10, 30.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 11%|█▏        | 38.3M/335M [00:00<00:09, 31.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 12%|█▏        | 39.0M/335M [00:00<00:09, 32.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 12%|█▏        | 39.3M/335M [00:00<00:10, 30.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 12%|█▏        | 39.5M/335M [00:00<00:10, 30.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 12%|█▏        | 39.5M/335M [00:00<00:10, 30.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 12%|█▏        | 39.6M/335M [00:00<00:10, 30.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 12%|█▏        | 39.8M/335M [00:00<00:09, 31.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 12%|█▏        | 41.5M/335M [00:00<00:09, 32.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 12%|█▏        | 41.6M/335M [00:00<00:08, 35.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 13%|█▎        | 43.5M/335M [00:01<00:08, 37.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 13%|█▎        | 44.0M/335M [00:01<00:08, 37.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 13%|█▎        | 44.1M/335M [00:01<00:08, 37.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 13%|█▎        | 44.2M/335M [00:00<00:07, 42.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 13%|█▎        | 44.2M/335M [00:00<00:07, 42.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 13%|█▎        | 44.2M/335M [00:01<00:08, 37.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 13%|█▎        | 44.2M/335M [00:01<00:08, 36.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 13%|█▎        | 44.2M/335M [00:01<00:08, 37.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 13%|█▎        | 44.5M/335M [00:01<00:08, 36.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 13%|█▎        | 44.6M/335M [00:01<00:08, 35.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 13%|█▎        | 44.6M/335M [00:01<00:08, 34.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 13%|█▎        | 44.7M/335M [00:01<00:08, 34.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 13%|█▎        | 44.7M/335M [00:01<00:08, 34.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 13%|█▎        | 45.0M/335M [00:01<00:08, 35.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 14%|█▎        | 45.8M/335M [00:01<00:08, 35.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 14%|█▎        | 46.0M/335M [00:01<00:08, 37.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 14%|█▍        | 48.5M/335M [00:01<00:08, 35.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 15%|█▍        | 48.9M/335M [00:01<00:08, 34.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 15%|█▍        | 49.0M/335M [00:01<00:08, 35.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 15%|█▍        | 49.0M/335M [00:01<00:08, 36.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 15%|█▍        | 49.1M/335M [00:01<00:08, 35.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 15%|█▍        | 49.2M/335M [00:01<00:08, 34.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 15%|█▍        | 49.1M/335M [00:01<00:08, 34.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 15%|█▍        | 49.2M/335M [00:01<00:08, 36.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 15%|█▍        | 49.2M/335M [00:01<00:08, 36.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 15%|█▍        | 49.2M/335M [00:01<00:08, 36.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 15%|█▍        | 49.2M/335M [00:01<00:08, 34.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 15%|█▍        | 49.3M/335M [00:01<00:08, 36.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 15%|█▍        | 49.8M/335M [00:01<00:08, 34.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 15%|█▍        | 49.9M/335M [00:01<00:07, 39.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 15%|█▍        | 50.0M/335M [00:01<00:07, 40.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 15%|█▍        | 50.3M/335M [00:01<00:08, 37.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 16%|█▌        | 53.8M/335M [00:01<00:07, 39.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 16%|█▌        | 54.2M/335M [00:01<00:07, 39.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 16%|█▌        | 54.2M/335M [00:01<00:07, 39.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 16%|█▌        | 54.2M/335M [00:01<00:07, 39.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 16%|█▌        | 54.5M/335M [00:01<00:07, 39.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 16%|█▌        | 54.4M/335M [00:01<00:07, 39.3MB/s][1,mpirank:14,algo-2]<stderr>:#015 16%|█▌        | 54.5M/335M [00:01<00:07, 40.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 16%|█▌        | 54.5M/335M [00:01<00:07, 39.3MB/s][1,mpirank:0,algo-1]<stderr>:#015 16%|█▋        | 54.5M/335M [00:01<00:07, 40.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 16%|█▌        | 54.5M/335M [00:01<00:07, 40.2MB/s][1,mpirank:9,algo-2]<stderr>:#015 16%|█▌        | 54.5M/335M [00:01<00:07, 39.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 16%|█▋        | 54.6M/335M [00:01<00:07, 40.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 16%|█▋        | 55.2M/335M [00:01<00:07, 39.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 16%|█▋        | 55.3M/335M [00:01<00:06, 43.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 17%|█▋        | 55.4M/335M [00:01<00:06, 43.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 17%|█▋        | 55.5M/335M [00:01<00:07, 41.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 17%|█▋        | 58.5M/335M [00:01<00:06, 41.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 18%|█▊        | 58.8M/335M [00:01<00:07, 41.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 18%|█▊        | 58.9M/335M [00:01<00:07, 41.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 18%|█▊        | 58.9M/335M [00:01<00:06, 42.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 18%|█▊        | 59.0M/335M [00:01<00:06, 41.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 18%|█▊        | 59.0M/335M [00:01<00:07, 41.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 18%|█▊        | 59.0M/335M [00:01<00:07, 41.1MB/s][1,mpirank:8,algo-2]<stderr>:#015 18%|█▊        | 59.0M/335M [00:01<00:07, 41.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 18%|█▊        | 59.2M/335M [00:01<00:06, 42.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 18%|█▊        | 59.1M/335M [00:01<00:06, 42.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 18%|█▊        | 59.2M/335M [00:01<00:06, 42.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 18%|█▊        | 59.1M/335M [00:01<00:06, 42.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 18%|█▊        | 60.0M/335M [00:01<00:06, 42.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 18%|█▊        | 60.4M/335M [00:01<00:06, 45.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 18%|█▊        | 60.4M/335M [00:01<00:06, 45.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 18%|█▊        | 60.5M/335M [00:01<00:06, 44.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 19%|█▉        | 64.2M/335M [00:01<00:06, 46.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 19%|█▉        | 64.6M/335M [00:01<00:06, 46.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 19%|█▉        | 64.7M/335M [00:01<00:06, 46.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 19%|█▉        | 64.7M/335M [00:01<00:06, 46.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 19%|█▉        | 64.8M/335M [00:01<00:06, 46.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 19%|█▉        | 64.8M/335M [00:01<00:06, 46.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 19%|█▉        | 64.9M/335M [00:01<00:06, 46.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 19%|█▉        | 64.8M/335M [00:01<00:06, 46.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 19%|█▉        | 65.0M/335M [00:01<00:06, 46.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 19%|█▉        | 65.0M/335M [00:01<00:06, 46.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 19%|█▉        | 65.0M/335M [00:01<00:06, 46.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 19%|█▉        | 65.0M/335M [00:01<00:06, 46.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 20%|█▉        | 65.6M/335M [00:01<00:06, 46.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 20%|█▉        | 65.7M/335M [00:01<00:05, 47.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 20%|█▉        | 65.8M/335M [00:01<00:05, 48.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 20%|█▉        | 65.9M/335M [00:01<00:05, 47.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 21%|██        | 69.7M/335M [00:01<00:05, 49.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 21%|██        | 70.1M/335M [00:01<00:05, 49.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 21%|██        | 70.1M/335M [00:01<00:05, 49.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 21%|██        | 70.2M/335M [00:01<00:05, 49.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 21%|██        | 70.2M/335M [00:01<00:05, 49.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 21%|██        | 70.3M/335M [00:01<00:05, 49.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 21%|██        | 70.3M/335M [00:01<00:05, 49.0MB/s][1,mpirank:8,algo-2]<stderr>:#015 21%|██        | 70.3M/335M [00:01<00:05, 49.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 21%|██        | 70.4M/335M [00:01<00:05, 49.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 21%|██        | 70.4M/335M [00:01<00:05, 49.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 21%|██        | 70.4M/335M [00:01<00:05, 49.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 21%|██        | 70.5M/335M [00:01<00:05, 49.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 21%|██▏       | 71.3M/335M [00:01<00:05, 50.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 21%|██▏       | 71.6M/335M [00:01<00:05, 51.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 21%|██▏       | 71.4M/335M [00:01<00:05, 50.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 21%|██▏       | 71.9M/335M [00:01<00:05, 51.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 22%|██▏       | 75.2M/335M [00:01<00:05, 51.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 23%|██▎       | 75.6M/335M [00:01<00:05, 51.3MB/s][1,mpirank:10,algo-2]<stderr>:#015 23%|██▎       | 75.6M/335M [00:01<00:05, 51.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 23%|██▎       | 75.7M/335M [00:01<00:05, 51.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 23%|██▎       | 75.7M/335M [00:01<00:05, 51.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 23%|██▎       | 75.8M/335M [00:01<00:05, 51.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 23%|██▎       | 75.8M/335M [00:01<00:05, 51.4MB/s][1,mpirank:9,algo-2]<stderr>:#015 23%|██▎       | 75.8M/335M [00:01<00:05, 51.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 23%|██▎       | 75.9M/335M [00:01<00:05, 51.6MB/s][1,mpirank:0,algo-1]<stderr>:#015 23%|██▎       | 75.9M/335M [00:01<00:05, 51.5MB/s][1,mpirank:5,algo-1]<stderr>:#015 23%|██▎       | 75.9M/335M [00:01<00:05, 51.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 23%|██▎       | 76.0M/335M [00:01<00:05, 51.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 23%|██▎       | 76.8M/335M [00:01<00:05, 52.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 23%|██▎       | 77.0M/335M [00:01<00:05, 52.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 23%|██▎       | 77.0M/335M [00:01<00:05, 52.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 23%|██▎       | 77.2M/335M [00:01<00:05, 52.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 24%|██▍       | 81.7M/335M [00:01<00:04, 55.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 24%|██▍       | 82.1M/335M [00:01<00:04, 55.8MB/s][1,mpirank:10,algo-2]<stderr>:#015 24%|██▍       | 82.0M/335M [00:01<00:04, 56.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 24%|██▍       | 82.1M/335M [00:01<00:04, 56.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 24%|██▍       | 82.1M/335M [00:01<00:04, 55.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 25%|██▍       | 82.2M/335M [00:01<00:04, 55.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 25%|██▍       | 82.3M/335M [00:01<00:04, 55.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 25%|██▍       | 82.2M/335M [00:01<00:04, 55.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 25%|██▍       | 82.4M/335M [00:01<00:04, 56.1MB/s][1,mpirank:0,algo-1]<stderr>:#015 25%|██▍       | 82.4M/335M [00:01<00:04, 56.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 25%|██▍       | 82.3M/335M [00:01<00:04, 55.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 25%|██▍       | 82.3M/335M [00:01<00:04, 54.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 25%|██▍       | 83.0M/335M [00:01<00:04, 55.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 25%|██▍       | 83.3M/335M [00:01<00:04, 56.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 25%|██▍       | 83.3M/335M [00:01<00:04, 56.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 25%|██▍       | 83.5M/335M [00:01<00:04, 56.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 26%|██▌       | 87.8M/335M [00:01<00:04, 58.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 26%|██▋       | 88.1M/335M [00:01<00:04, 57.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 26%|██▋       | 88.1M/335M [00:01<00:04, 57.8MB/s][1,mpirank:13,algo-2]<stderr>:#015 26%|██▋       | 88.1M/335M [00:01<00:04, 57.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 26%|██▋       | 88.1M/335M [00:01<00:04, 57.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 26%|██▋       | 88.1M/335M [00:01<00:04, 57.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 26%|██▋       | 88.1M/335M [00:01<00:04, 57.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 26%|██▋       | 88.2M/335M [00:01<00:04, 57.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 26%|██▋       | 88.3M/335M [00:01<00:04, 57.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 26%|██▋       | 88.2M/335M [00:01<00:04, 57.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 26%|██▋       | 88.3M/335M [00:01<00:04, 57.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 26%|██▋       | 88.7M/335M [00:01<00:04, 57.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 26%|██▋       | 88.8M/335M [00:01<00:04, 57.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 27%|██▋       | 89.0M/335M [00:01<00:04, 57.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 27%|██▋       | 89.0M/335M [00:01<00:04, 57.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 27%|██▋       | 89.1M/335M [00:01<00:04, 56.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 28%|██▊       | 93.6M/335M [00:01<00:04, 58.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 28%|██▊       | 94.0M/335M [00:02<00:04, 59.0MB/s][1,mpirank:10,algo-2]<stderr>:#015 28%|██▊       | 94.0M/335M [00:02<00:04, 59.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 28%|██▊       | 94.1M/335M [00:02<00:04, 59.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 28%|██▊       | 94.1M/335M [00:02<00:04, 59.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 28%|██▊       | 94.0M/335M [00:01<00:04, 59.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 28%|██▊       | 94.1M/335M [00:02<00:04, 59.0MB/s][1,mpirank:8,algo-2]<stderr>:#015 28%|██▊       | 94.2M/335M [00:02<00:04, 59.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 28%|██▊       | 94.2M/335M [00:01<00:04, 59.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 28%|██▊       | 94.2M/335M [00:01<00:04, 58.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 28%|██▊       | 94.3M/335M [00:01<00:04, 59.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 28%|██▊       | 94.9M/335M [00:01<00:04, 59.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 28%|██▊       | 95.1M/335M [00:02<00:04, 59.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 28%|██▊       | 95.4M/335M [00:01<00:04, 60.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 28%|██▊       | 95.4M/335M [00:01<00:04, 60.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 29%|██▊       | 95.7M/335M [00:02<00:04, 60.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 30%|██▉       | 100M/335M [00:02<00:03, 62.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 30%|███       | 101M/335M [00:02<00:03, 62.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 30%|███       | 101M/335M [00:02<00:03, 62.4MB/s] [1,mpirank:13,algo-2]<stderr>:#015 30%|███       | 101M/335M [00:02<00:03, 62.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 30%|███       | 101M/335M [00:02<00:03, 62.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 30%|███       | 101M/335M [00:02<00:03, 62.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 30%|███       | 101M/335M [00:02<00:03, 62.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 30%|███       | 101M/335M [00:02<00:03, 62.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 30%|███       | 101M/335M [00:02<00:03, 62.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 30%|███       | 101M/335M [00:02<00:03, 62.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 30%|███       | 101M/335M [00:02<00:03, 62.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 30%|███       | 102M/335M [00:02<00:03, 63.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 30%|███       | 102M/335M [00:02<00:03, 63.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 30%|███       | 102M/335M [00:02<00:03, 62.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 30%|███       | 102M/335M [00:02<00:03, 63.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 31%|███       | 102M/335M [00:02<00:03, 62.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 32%|███▏      | 107M/335M [00:02<00:03, 63.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 32%|███▏      | 107M/335M [00:02<00:03, 63.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 32%|███▏      | 107M/335M [00:02<00:03, 62.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 32%|███▏      | 107M/335M [00:02<00:03, 62.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 32%|███▏      | 107M/335M [00:02<00:03, 62.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 32%|███▏      | 107M/335M [00:02<00:03, 62.6MB/s][1,mpirank:11,algo-2]<stderr>:#015 32%|███▏      | 107M/335M [00:02<00:03, 62.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 32%|███▏      | 107M/335M [00:02<00:03, 62.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 32%|███▏      | 107M/335M [00:02<00:03, 62.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 32%|███▏      | 107M/335M [00:02<00:03, 62.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 32%|███▏      | 107M/335M [00:02<00:03, 62.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 32%|███▏      | 108M/335M [00:02<00:03, 62.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 32%|███▏      | 108M/335M [00:02<00:03, 62.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 32%|███▏      | 108M/335M [00:02<00:03, 62.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 32%|███▏      | 108M/335M [00:02<00:03, 62.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 32%|███▏      | 109M/335M [00:02<00:03, 63.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 34%|███▎      | 113M/335M [00:02<00:03, 61.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 34%|███▎      | 113M/335M [00:02<00:03, 61.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 34%|███▎      | 113M/335M [00:02<00:03, 61.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 34%|███▎      | 113M/335M [00:02<00:03, 61.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 34%|███▎      | 113M/335M [00:02<00:03, 61.9MB/s][1,mpirank:4,algo-1]<stderr>:#015 34%|███▎      | 113M/335M [00:02<00:03, 61.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 34%|███▎      | 113M/335M [00:02<00:03, 61.7MB/s][1,mpirank:11,algo-2]<stderr>:#015 34%|███▎      | 113M/335M [00:02<00:03, 61.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 34%|███▎      | 113M/335M [00:02<00:03, 61.8MB/s][1,mpirank:9,algo-2]<stderr>:#015 34%|███▎      | 113M/335M [00:02<00:03, 61.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 34%|███▍      | 113M/335M [00:02<00:03, 61.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 34%|███▍      | 114M/335M [00:02<00:03, 62.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 34%|███▍      | 114M/335M [00:02<00:03, 61.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 34%|███▍      | 114M/335M [00:02<00:03, 62.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 34%|███▍      | 114M/335M [00:02<00:03, 62.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 34%|███▍      | 115M/335M [00:02<00:03, 62.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 35%|███▌      | 119M/335M [00:02<00:03, 61.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 35%|███▌      | 119M/335M [00:02<00:03, 61.9MB/s][1,mpirank:13,algo-2]<stderr>:#015 36%|███▌      | 119M/335M [00:02<00:03, 61.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 36%|███▌      | 119M/335M [00:02<00:03, 61.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 35%|███▌      | 119M/335M [00:02<00:03, 61.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 36%|███▌      | 119M/335M [00:02<00:03, 61.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 36%|███▌      | 119M/335M [00:02<00:03, 61.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 35%|███▌      | 119M/335M [00:02<00:03, 61.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 35%|███▌      | 119M/335M [00:02<00:03, 61.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 36%|███▌      | 119M/335M [00:02<00:03, 61.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 36%|███▌      | 119M/335M [00:02<00:03, 62.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 36%|███▌      | 120M/335M [00:02<00:03, 62.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 36%|███▌      | 120M/335M [00:02<00:03, 62.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 36%|███▌      | 120M/335M [00:02<00:03, 62.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 36%|███▌      | 120M/335M [00:02<00:03, 62.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 36%|███▌      | 121M/335M [00:02<00:03, 62.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 37%|███▋      | 125M/335M [00:02<00:03, 64.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 37%|███▋      | 126M/335M [00:02<00:03, 64.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 37%|███▋      | 126M/335M [00:02<00:03, 64.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 37%|███▋      | 126M/335M [00:02<00:03, 64.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 37%|███▋      | 126M/335M [00:02<00:03, 64.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 38%|███▊      | 126M/335M [00:02<00:03, 64.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 37%|███▋      | 126M/335M [00:02<00:03, 64.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 38%|███▊      | 126M/335M [00:02<00:03, 64.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 38%|███▊      | 126M/335M [00:02<00:03, 64.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 38%|███▊      | 126M/335M [00:02<00:03, 64.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 38%|███▊      | 126M/335M [00:02<00:03, 64.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 38%|███▊      | 127M/335M [00:02<00:03, 64.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 38%|███▊      | 127M/335M [00:02<00:03, 63.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 38%|███▊      | 127M/335M [00:02<00:03, 63.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 38%|███▊      | 127M/335M [00:02<00:03, 63.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 38%|███▊      | 127M/335M [00:02<00:03, 63.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 39%|███▉      | 132M/335M [00:02<00:03, 61.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 39%|███▉      | 132M/335M [00:02<00:03, 61.9MB/s][1,mpirank:13,algo-2]<stderr>:#015 39%|███▉      | 132M/335M [00:02<00:03, 61.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 39%|███▉      | 132M/335M [00:02<00:03, 61.9MB/s][1,mpirank:14,algo-2]<stderr>:#015 39%|███▉      | 132M/335M [00:02<00:03, 61.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 39%|███▉      | 132M/335M [00:02<00:03, 61.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 39%|███▉      | 132M/335M [00:02<00:03, 62.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 39%|███▉      | 132M/335M [00:02<00:03, 61.7MB/s][1,mpirank:15,algo-2]<stderr>:#015 39%|███▉      | 132M/335M [00:02<00:03, 62.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 39%|███▉      | 132M/335M [00:02<00:03, 61.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 39%|███▉      | 132M/335M [00:02<00:03, 62.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 40%|███▉      | 133M/335M [00:02<00:03, 62.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 40%|███▉      | 133M/335M [00:02<00:03, 62.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 40%|███▉      | 133M/335M [00:02<00:03, 62.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 40%|███▉      | 133M/335M [00:02<00:03, 62.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 40%|███▉      | 133M/335M [00:02<00:03, 62.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 41%|████      | 138M/335M [00:02<00:03, 63.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 41%|████      | 138M/335M [00:02<00:03, 62.9MB/s][1,mpirank:0,algo-1]<stderr>:#015 41%|████      | 138M/335M [00:02<00:03, 62.8MB/s][1,mpirank:8,algo-2]<stderr>:#015 41%|████      | 138M/335M [00:02<00:03, 62.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 41%|████      | 138M/335M [00:02<00:03, 62.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 41%|████      | 138M/335M [00:02<00:03, 62.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 41%|████      | 138M/335M [00:02<00:03, 62.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 41%|████      | 138M/335M [00:02<00:03, 62.8MB/s][1,mpirank:4,algo-1]<stderr>:#015 41%|████      | 138M/335M [00:02<00:03, 62.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 41%|████▏     | 138M/335M [00:02<00:03, 62.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 41%|████▏     | 138M/335M [00:02<00:03, 62.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 41%|████▏     | 139M/335M [00:02<00:03, 62.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 41%|████▏     | 139M/335M [00:02<00:03, 62.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 41%|████▏     | 139M/335M [00:02<00:03, 62.9MB/s][1,mpirank:2,algo-1]<stderr>:#015 41%|████▏     | 139M/335M [00:02<00:03, 62.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 42%|████▏     | 139M/335M [00:02<00:03, 62.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 43%|████▎     | 144M/335M [00:02<00:03, 64.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 43%|████▎     | 145M/335M [00:02<00:03, 64.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 43%|████▎     | 145M/335M [00:02<00:03, 64.5MB/s][1,mpirank:8,algo-2]<stderr>:#015 43%|████▎     | 145M/335M [00:02<00:03, 64.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 43%|████▎     | 145M/335M [00:02<00:03, 64.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 43%|████▎     | 145M/335M [00:02<00:03, 64.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 43%|████▎     | 145M/335M [00:02<00:03, 64.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 43%|████▎     | 145M/335M [00:02<00:03, 64.6MB/s][1,mpirank:4,algo-1]<stderr>:#015 43%|████▎     | 145M/335M [00:02<00:03, 64.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 43%|████▎     | 144M/335M [00:02<00:03, 63.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 43%|████▎     | 145M/335M [00:02<00:03, 64.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 43%|████▎     | 145M/335M [00:02<00:03, 64.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 43%|████▎     | 146M/335M [00:02<00:03, 64.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 43%|████▎     | 146M/335M [00:02<00:03, 64.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 43%|████▎     | 146M/335M [00:02<00:03, 64.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 43%|████▎     | 146M/335M [00:02<00:03, 64.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 45%|████▍     | 151M/335M [00:02<00:02, 64.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 45%|████▌     | 151M/335M [00:02<00:02, 64.8MB/s][1,mpirank:0,algo-1]<stderr>:#015 45%|████▌     | 151M/335M [00:02<00:02, 64.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 45%|████▌     | 151M/335M [00:02<00:02, 64.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 45%|████▌     | 151M/335M [00:02<00:02, 64.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 45%|████▍     | 151M/335M [00:02<00:02, 64.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 45%|████▌     | 151M/335M [00:02<00:02, 64.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 45%|████▌     | 151M/335M [00:02<00:02, 64.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 45%|████▌     | 151M/335M [00:02<00:02, 64.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 45%|████▌     | 151M/335M [00:02<00:02, 65.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 45%|████▌     | 151M/335M [00:02<00:02, 64.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 45%|████▌     | 152M/335M [00:02<00:02, 64.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 45%|████▌     | 152M/335M [00:02<00:02, 64.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 45%|████▌     | 152M/335M [00:02<00:02, 64.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 45%|████▌     | 152M/335M [00:02<00:02, 64.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 45%|████▌     | 152M/335M [00:02<00:02, 64.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 47%|████▋     | 157M/335M [00:03<00:02, 64.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 47%|████▋     | 157M/335M [00:03<00:02, 64.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 47%|████▋     | 157M/335M [00:03<00:02, 64.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 47%|████▋     | 157M/335M [00:03<00:02, 64.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 47%|████▋     | 157M/335M [00:03<00:02, 64.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 47%|████▋     | 157M/335M [00:03<00:02, 64.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 47%|████▋     | 157M/335M [00:03<00:02, 64.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 47%|████▋     | 157M/335M [00:03<00:02, 64.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 47%|████▋     | 157M/335M [00:03<00:02, 64.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 47%|████▋     | 158M/335M [00:03<00:02, 65.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 47%|████▋     | 157M/335M [00:03<00:02, 64.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 47%|████▋     | 158M/335M [00:03<00:02, 65.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 47%|████▋     | 158M/335M [00:03<00:02, 64.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 47%|████▋     | 158M/335M [00:02<00:02, 65.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 47%|████▋     | 158M/335M [00:02<00:02, 65.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 47%|████▋     | 158M/335M [00:03<00:02, 65.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 49%|████▊     | 163M/335M [00:03<00:03, 57.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 49%|████▊     | 163M/335M [00:03<00:03, 56.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 49%|████▊     | 163M/335M [00:03<00:03, 56.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 49%|████▊     | 163M/335M [00:03<00:03, 56.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 49%|████▊     | 163M/335M [00:03<00:03, 56.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 49%|████▊     | 163M/335M [00:03<00:03, 56.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 49%|████▊     | 163M/335M [00:03<00:03, 56.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 49%|████▊     | 163M/335M [00:03<00:03, 56.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 49%|████▊     | 163M/335M [00:03<00:03, 56.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 49%|████▉     | 164M/335M [00:03<00:03, 55.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 49%|████▉     | 164M/335M [00:03<00:03, 55.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 49%|████▉     | 164M/335M [00:03<00:03, 54.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 49%|████▉     | 164M/335M [00:03<00:03, 54.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 49%|████▉     | 165M/335M [00:03<00:03, 53.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 49%|████▉     | 165M/335M [00:03<00:03, 53.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 49%|████▉     | 165M/335M [00:03<00:03, 52.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 50%|█████     | 169M/335M [00:03<00:03, 50.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 50%|█████     | 169M/335M [00:03<00:03, 50.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 50%|█████     | 169M/335M [00:03<00:03, 50.4MB/s][1,mpirank:0,algo-1]<stderr>:#015 50%|█████     | 169M/335M [00:03<00:03, 50.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 50%|█████     | 169M/335M [00:03<00:03, 50.3MB/s][1,mpirank:10,algo-2]<stderr>:#015 50%|█████     | 169M/335M [00:03<00:03, 50.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 50%|█████     | 169M/335M [00:03<00:03, 50.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 50%|█████     | 169M/335M [00:03<00:03, 50.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 50%|█████     | 169M/335M [00:03<00:03, 50.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 50%|█████     | 169M/335M [00:03<00:03, 50.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 50%|█████     | 169M/335M [00:03<00:03, 50.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 51%|█████     | 170M/335M [00:03<00:03, 50.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 51%|█████     | 170M/335M [00:03<00:03, 50.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 51%|█████     | 170M/335M [00:03<00:03, 51.4MB/s][1,mpirank:2,algo-1]<stderr>:#015 51%|█████     | 170M/335M [00:03<00:03, 51.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 51%|█████     | 170M/335M [00:03<00:03, 51.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 52%|█████▏    | 175M/335M [00:03<00:03, 55.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 52%|█████▏    | 175M/335M [00:03<00:03, 55.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 52%|█████▏    | 176M/335M [00:03<00:02, 55.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 52%|█████▏    | 176M/335M [00:03<00:02, 55.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 52%|█████▏    | 176M/335M [00:03<00:03, 55.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 52%|█████▏    | 176M/335M [00:03<00:02, 55.8MB/s][1,mpirank:10,algo-2]<stderr>:#015 52%|█████▏    | 176M/335M [00:03<00:02, 55.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 52%|█████▏    | 176M/335M [00:03<00:02, 56.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 52%|█████▏    | 176M/335M [00:03<00:02, 56.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 52%|█████▏    | 176M/335M [00:03<00:02, 55.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 53%|█████▎    | 176M/335M [00:03<00:02, 56.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 53%|█████▎    | 176M/335M [00:03<00:02, 56.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 53%|█████▎    | 176M/335M [00:03<00:02, 56.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 53%|█████▎    | 177M/335M [00:03<00:02, 56.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 53%|█████▎    | 177M/335M [00:03<00:02, 56.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 53%|█████▎    | 177M/335M [00:03<00:02, 56.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 54%|█████▍    | 181M/335M [00:03<00:02, 56.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 54%|█████▍    | 181M/335M [00:03<00:02, 56.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 54%|█████▍    | 181M/335M [00:03<00:02, 56.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 54%|█████▍    | 181M/335M [00:03<00:02, 56.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 54%|█████▍    | 181M/335M [00:03<00:02, 56.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 54%|█████▍    | 181M/335M [00:03<00:02, 56.5MB/s][1,mpirank:15,algo-2]<stderr>:#015 54%|█████▍    | 181M/335M [00:03<00:02, 56.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 54%|█████▍    | 182M/335M [00:03<00:02, 56.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 54%|█████▍    | 182M/335M [00:03<00:02, 56.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 54%|█████▍    | 182M/335M [00:03<00:02, 56.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 54%|█████▍    | 182M/335M [00:03<00:02, 55.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 54%|█████▍    | 182M/335M [00:03<00:02, 55.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 54%|█████▍    | 182M/335M [00:03<00:02, 54.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 54%|█████▍    | 182M/335M [00:03<00:02, 53.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 54%|█████▍    | 182M/335M [00:03<00:03, 53.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 54%|█████▍    | 182M/335M [00:03<00:03, 53.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 56%|█████▌    | 187M/335M [00:03<00:03, 51.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 56%|█████▌    | 187M/335M [00:03<00:03, 51.7MB/s][1,mpirank:8,algo-2]<stderr>:#015 56%|█████▌    | 187M/335M [00:03<00:02, 51.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 56%|█████▌    | 187M/335M [00:03<00:03, 51.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 56%|█████▌    | 187M/335M [00:03<00:03, 51.7MB/s][1,mpirank:0,algo-1]<stderr>:#015 56%|█████▌    | 187M/335M [00:03<00:03, 51.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 56%|█████▌    | 187M/335M [00:03<00:03, 51.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 56%|█████▌    | 187M/335M [00:03<00:03, 51.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 56%|█████▌    | 187M/335M [00:03<00:02, 51.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 56%|█████▌    | 187M/335M [00:03<00:03, 51.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 56%|█████▌    | 187M/335M [00:03<00:02, 52.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 56%|█████▌    | 187M/335M [00:03<00:02, 52.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 56%|█████▌    | 187M/335M [00:03<00:02, 52.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 56%|█████▌    | 188M/335M [00:03<00:02, 52.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 56%|█████▌    | 188M/335M [00:03<00:02, 52.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 56%|█████▌    | 188M/335M [00:03<00:02, 53.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 57%|█████▋    | 193M/335M [00:03<00:02, 53.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 57%|█████▋    | 193M/335M [00:03<00:02, 53.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 57%|█████▋    | 193M/335M [00:03<00:02, 53.4MB/s][1,mpirank:15,algo-2]<stderr>:#015 57%|█████▋    | 193M/335M [00:03<00:02, 53.5MB/s][1,mpirank:0,algo-1]<stderr>:#015 57%|█████▋    | 193M/335M [00:03<00:02, 53.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 57%|█████▋    | 193M/335M [00:03<00:02, 53.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 57%|█████▋    | 193M/335M [00:03<00:02, 53.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 57%|█████▋    | 193M/335M [00:03<00:02, 53.6MB/s][1,mpirank:5,algo-1]<stderr>:#015 57%|█████▋    | 193M/335M [00:03<00:02, 53.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 57%|█████▋    | 192M/335M [00:03<00:02, 52.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 58%|█████▊    | 193M/335M [00:03<00:02, 53.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 58%|█████▊    | 193M/335M [00:03<00:02, 53.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 58%|█████▊    | 193M/335M [00:03<00:02, 54.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 58%|█████▊    | 193M/335M [00:03<00:02, 54.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 58%|█████▊    | 193M/335M [00:03<00:02, 54.4MB/s][1,mpirank:6,algo-1]<stderr>:#015 58%|█████▊    | 193M/335M [00:03<00:02, 54.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 59%|█████▉    | 199M/335M [00:03<00:02, 55.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 59%|█████▉    | 199M/335M [00:03<00:02, 56.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 59%|█████▉    | 199M/335M [00:03<00:02, 56.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 59%|█████▉    | 199M/335M [00:03<00:02, 56.1MB/s][1,mpirank:14,algo-2]<stderr>:#015 59%|█████▉    | 199M/335M [00:03<00:02, 55.6MB/s][1,mpirank:15,algo-2]<stderr>:#015 59%|█████▉    | 199M/335M [00:03<00:02, 55.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 59%|█████▉    | 199M/335M [00:03<00:02, 55.5MB/s][1,mpirank:0,algo-1]<stderr>:#015 59%|█████▉    | 199M/335M [00:03<00:02, 55.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 59%|█████▉    | 199M/335M [00:03<00:02, 55.8MB/s][1,mpirank:9,algo-2]<stderr>:#015 59%|█████▉    | 199M/335M [00:03<00:02, 55.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 59%|█████▉    | 199M/335M [00:03<00:02, 55.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 59%|█████▉    | 199M/335M [00:03<00:02, 55.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 59%|█████▉    | 199M/335M [00:03<00:02, 55.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 59%|█████▉    | 199M/335M [00:03<00:02, 56.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 59%|█████▉    | 199M/335M [00:03<00:02, 56.0MB/s][1,mpirank:6,algo-1]<stderr>:#015 59%|█████▉    | 199M/335M [00:03<00:02, 56.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 61%|██████    | 205M/335M [00:03<00:02, 58.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 61%|██████    | 205M/335M [00:03<00:02, 59.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 61%|██████    | 205M/335M [00:03<00:02, 59.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 61%|██████    | 205M/335M [00:03<00:02, 59.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 61%|██████    | 205M/335M [00:03<00:02, 59.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 61%|██████    | 205M/335M [00:03<00:02, 59.4MB/s][1,mpirank:4,algo-1]<stderr>:#015 61%|██████    | 205M/335M [00:03<00:02, 59.2MB/s][1,mpirank:12,algo-2]<stderr>:#015 61%|██████    | 205M/335M [00:03<00:02, 59.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 61%|██████    | 205M/335M [00:03<00:02, 58.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 61%|██████    | 205M/335M [00:03<00:02, 58.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 61%|██████    | 205M/335M [00:03<00:02, 59.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 61%|██████    | 205M/335M [00:03<00:02, 59.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 61%|██████    | 205M/335M [00:03<00:02, 59.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 61%|██████▏   | 206M/335M [00:03<00:02, 59.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 61%|██████▏   | 206M/335M [00:03<00:02, 59.7MB/s][1,mpirank:2,algo-1]<stderr>:#015 61%|██████▏   | 206M/335M [00:03<00:02, 59.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 63%|██████▎   | 210M/335M [00:04<00:02, 57.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 63%|██████▎   | 210M/335M [00:04<00:02, 57.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 63%|██████▎   | 211M/335M [00:04<00:02, 56.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 63%|██████▎   | 211M/335M [00:04<00:02, 57.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 63%|██████▎   | 211M/335M [00:04<00:02, 56.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 63%|██████▎   | 211M/335M [00:04<00:02, 56.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 63%|██████▎   | 211M/335M [00:04<00:02, 56.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 63%|██████▎   | 211M/335M [00:04<00:02, 56.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 63%|██████▎   | 211M/335M [00:04<00:02, 56.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 63%|██████▎   | 211M/335M [00:04<00:02, 56.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 63%|██████▎   | 211M/335M [00:04<00:02, 56.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 63%|██████▎   | 211M/335M [00:04<00:02, 56.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 63%|██████▎   | 211M/335M [00:04<00:02, 55.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 63%|██████▎   | 211M/335M [00:04<00:02, 55.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 63%|██████▎   | 211M/335M [00:04<00:02, 55.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 63%|██████▎   | 211M/335M [00:03<00:02, 54.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 64%|██████▍   | 216M/335M [00:04<00:02, 48.2MB/s][1,mpirank:14,algo-2]<stderr>:#015 64%|██████▍   | 216M/335M [00:04<00:02, 48.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 64%|██████▍   | 216M/335M [00:04<00:02, 48.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 64%|██████▍   | 216M/335M [00:04<00:02, 48.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 64%|██████▍   | 216M/335M [00:04<00:02, 48.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 65%|██████▍   | 216M/335M [00:04<00:02, 48.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 65%|██████▍   | 216M/335M [00:04<00:02, 48.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 65%|██████▍   | 217M/335M [00:04<00:02, 48.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 65%|██████▍   | 216M/335M [00:04<00:02, 48.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 65%|██████▍   | 216M/335M [00:04<00:02, 48.4MB/s][1,mpirank:5,algo-1]<stderr>:#015 65%|██████▍   | 216M/335M [00:04<00:02, 48.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 65%|██████▍   | 217M/335M [00:04<00:02, 48.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 65%|██████▍   | 217M/335M [00:04<00:02, 48.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 65%|██████▍   | 217M/335M [00:04<00:02, 48.7MB/s][1,mpirank:2,algo-1]<stderr>:#015 65%|██████▍   | 217M/335M [00:04<00:02, 48.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 65%|██████▍   | 217M/335M [00:04<00:02, 46.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 66%|██████▌   | 222M/335M [00:04<00:02, 50.4MB/s][1,mpirank:11,algo-2]<stderr>:#015 66%|██████▌   | 222M/335M [00:04<00:02, 50.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 66%|██████▌   | 222M/335M [00:04<00:02, 50.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 66%|██████▌   | 222M/335M [00:04<00:02, 50.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 66%|██████▌   | 222M/335M [00:04<00:02, 50.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 66%|██████▌   | 222M/335M [00:04<00:02, 50.7MB/s][1,mpirank:15,algo-2]<stderr>:#015 66%|██████▌   | 222M/335M [00:04<00:02, 50.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 66%|██████▌   | 222M/335M [00:04<00:02, 50.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 66%|██████▌   | 222M/335M [00:04<00:02, 50.6MB/s][1,mpirank:5,algo-1]<stderr>:#015 66%|██████▌   | 222M/335M [00:04<00:02, 49.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 66%|██████▌   | 222M/335M [00:04<00:02, 50.9MB/s][1,mpirank:9,algo-2]<stderr>:#015 66%|██████▌   | 222M/335M [00:04<00:02, 50.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 66%|██████▋   | 222M/335M [00:04<00:02, 51.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 66%|██████▋   | 222M/335M [00:04<00:02, 51.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 66%|██████▋   | 222M/335M [00:04<00:02, 50.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 66%|██████▋   | 223M/335M [00:04<00:02, 50.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 68%|██████▊   | 228M/335M [00:04<00:02, 54.8MB/s][1,mpirank:11,algo-2]<stderr>:#015 68%|██████▊   | 228M/335M [00:04<00:02, 54.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 68%|██████▊   | 228M/335M [00:04<00:02, 54.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 68%|██████▊   | 228M/335M [00:04<00:02, 54.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 68%|██████▊   | 228M/335M [00:04<00:02, 54.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 68%|██████▊   | 228M/335M [00:04<00:02, 54.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 68%|██████▊   | 228M/335M [00:04<00:02, 54.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 68%|██████▊   | 228M/335M [00:04<00:02, 54.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 68%|██████▊   | 228M/335M [00:04<00:02, 54.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 68%|██████▊   | 228M/335M [00:04<00:02, 55.0MB/s][1,mpirank:5,algo-1]<stderr>:#015 68%|██████▊   | 228M/335M [00:04<00:02, 55.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 68%|██████▊   | 228M/335M [00:04<00:02, 54.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 68%|██████▊   | 229M/335M [00:04<00:02, 55.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 68%|██████▊   | 229M/335M [00:04<00:02, 55.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 68%|██████▊   | 229M/335M [00:04<00:02, 55.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 69%|██████▊   | 230M/335M [00:04<00:01, 56.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 70%|██████▉   | 234M/335M [00:04<00:01, 58.5MB/s][1,mpirank:11,algo-2]<stderr>:#015 70%|██████▉   | 234M/335M [00:04<00:01, 58.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 70%|██████▉   | 235M/335M [00:04<00:01, 58.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 70%|██████▉   | 235M/335M [00:04<00:01, 58.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 70%|██████▉   | 235M/335M [00:04<00:01, 58.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 70%|███████   | 235M/335M [00:04<00:01, 58.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 70%|███████   | 235M/335M [00:04<00:01, 58.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 70%|███████   | 235M/335M [00:04<00:01, 58.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 70%|███████   | 235M/335M [00:04<00:01, 58.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 70%|███████   | 235M/335M [00:04<00:01, 58.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 70%|███████   | 235M/335M [00:04<00:01, 58.7MB/s][1,mpirank:5,algo-1]<stderr>:#015 70%|███████   | 235M/335M [00:04<00:01, 58.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 70%|███████   | 235M/335M [00:04<00:01, 58.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 70%|███████   | 235M/335M [00:04<00:01, 58.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 70%|███████   | 235M/335M [00:04<00:01, 59.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 71%|███████   | 237M/335M [00:04<00:01, 60.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 72%|███████▏  | 240M/335M [00:04<00:01, 55.6MB/s][1,mpirank:11,algo-2]<stderr>:#015 72%|███████▏  | 240M/335M [00:04<00:01, 55.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 72%|███████▏  | 240M/335M [00:04<00:01, 55.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 72%|███████▏  | 240M/335M [00:04<00:01, 55.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 72%|███████▏  | 240M/335M [00:04<00:01, 55.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 72%|███████▏  | 241M/335M [00:04<00:01, 55.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 72%|███████▏  | 241M/335M [00:04<00:01, 55.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 72%|███████▏  | 241M/335M [00:04<00:01, 55.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 72%|███████▏  | 241M/335M [00:04<00:01, 55.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 72%|███████▏  | 241M/335M [00:04<00:01, 55.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 72%|███████▏  | 241M/335M [00:04<00:01, 55.6MB/s][1,mpirank:9,algo-2]<stderr>:#015 72%|███████▏  | 241M/335M [00:04<00:01, 55.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 72%|███████▏  | 241M/335M [00:04<00:01, 55.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 72%|███████▏  | 241M/335M [00:04<00:01, 55.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 72%|███████▏  | 241M/335M [00:04<00:01, 55.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 72%|███████▏  | 243M/335M [00:04<00:01, 56.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 74%|███████▎  | 247M/335M [00:04<00:01, 59.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 74%|███████▎  | 247M/335M [00:04<00:01, 59.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 74%|███████▎  | 247M/335M [00:04<00:01, 59.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 74%|███████▎  | 247M/335M [00:04<00:01, 59.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 74%|███████▎  | 247M/335M [00:04<00:01, 59.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 74%|███████▍  | 247M/335M [00:04<00:01, 59.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 74%|███████▍  | 247M/335M [00:04<00:01, 59.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 74%|███████▍  | 247M/335M [00:04<00:01, 59.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 74%|███████▍  | 248M/335M [00:04<00:01, 59.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 74%|███████▍  | 247M/335M [00:04<00:01, 59.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 74%|███████▍  | 247M/335M [00:04<00:01, 59.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 74%|███████▍  | 247M/335M [00:04<00:01, 59.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 74%|███████▍  | 248M/335M [00:04<00:01, 59.8MB/s][1,mpirank:1,algo-1]<stderr>:#015 74%|███████▍  | 248M/335M [00:04<00:01, 59.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 74%|███████▍  | 248M/335M [00:04<00:01, 59.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 74%|███████▍  | 249M/335M [00:04<00:01, 60.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 76%|███████▌  | 254M/335M [00:04<00:01, 62.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 76%|███████▌  | 254M/335M [00:04<00:01, 62.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 76%|███████▌  | 254M/335M [00:04<00:01, 62.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 76%|███████▌  | 254M/335M [00:04<00:01, 62.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 76%|███████▌  | 254M/335M [00:04<00:01, 62.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 76%|███████▌  | 254M/335M [00:04<00:01, 62.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 76%|███████▌  | 254M/335M [00:04<00:01, 62.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 76%|███████▌  | 254M/335M [00:04<00:01, 62.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 76%|███████▌  | 254M/335M [00:04<00:01, 62.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 76%|███████▌  | 254M/335M [00:04<00:01, 62.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 76%|███████▌  | 254M/335M [00:04<00:01, 62.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 76%|███████▌  | 254M/335M [00:04<00:01, 62.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 76%|███████▌  | 254M/335M [00:04<00:01, 62.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 76%|███████▌  | 254M/335M [00:04<00:01, 62.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 76%|███████▌  | 254M/335M [00:04<00:01, 62.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 76%|███████▋  | 256M/335M [00:04<00:01, 62.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 78%|███████▊  | 260M/335M [00:04<00:01, 64.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 78%|███████▊  | 260M/335M [00:04<00:01, 64.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 78%|███████▊  | 260M/335M [00:04<00:01, 64.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 78%|███████▊  | 261M/335M [00:04<00:01, 64.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 78%|███████▊  | 261M/335M [00:04<00:01, 64.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 78%|███████▊  | 261M/335M [00:04<00:01, 64.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 78%|███████▊  | 261M/335M [00:04<00:01, 64.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 78%|███████▊  | 261M/335M [00:04<00:01, 64.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 78%|███████▊  | 261M/335M [00:04<00:01, 64.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 78%|███████▊  | 261M/335M [00:04<00:01, 64.7MB/s][1,mpirank:9,algo-2]<stderr>:#015 78%|███████▊  | 261M/335M [00:04<00:01, 64.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 78%|███████▊  | 261M/335M [00:04<00:01, 64.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 78%|███████▊  | 261M/335M [00:04<00:01, 64.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 78%|███████▊  | 261M/335M [00:04<00:01, 64.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 78%|███████▊  | 261M/335M [00:04<00:01, 64.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 78%|███████▊  | 262M/335M [00:04<00:01, 62.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 79%|███████▉  | 266M/335M [00:05<00:01, 59.4MB/s][1,mpirank:14,algo-2]<stderr>:#015 79%|███████▉  | 266M/335M [00:05<00:01, 59.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 80%|███████▉  | 267M/335M [00:05<00:01, 59.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 80%|███████▉  | 267M/335M [00:05<00:01, 59.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 80%|███████▉  | 267M/335M [00:05<00:01, 59.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 80%|███████▉  | 267M/335M [00:05<00:01, 59.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 80%|███████▉  | 267M/335M [00:05<00:01, 59.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 80%|███████▉  | 267M/335M [00:05<00:01, 59.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 80%|███████▉  | 267M/335M [00:05<00:01, 59.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 80%|███████▉  | 267M/335M [00:05<00:01, 59.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 80%|███████▉  | 267M/335M [00:05<00:01, 59.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 80%|███████▉  | 267M/335M [00:05<00:01, 59.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 80%|███████▉  | 267M/335M [00:04<00:01, 59.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 80%|███████▉  | 267M/335M [00:05<00:01, 59.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 80%|███████▉  | 267M/335M [00:05<00:01, 59.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 80%|████████  | 268M/335M [00:05<00:01, 59.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 81%|████████  | 272M/335M [00:05<00:01, 59.4MB/s][1,mpirank:11,algo-2]<stderr>:#015 81%|████████  | 272M/335M [00:05<00:01, 59.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 81%|████████  | 272M/335M [00:05<00:01, 59.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 81%|████████▏ | 273M/335M [00:05<00:01, 59.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 81%|████████▏ | 273M/335M [00:05<00:01, 59.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 81%|████████▏ | 273M/335M [00:05<00:01, 59.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 81%|████████▏ | 273M/335M [00:05<00:01, 59.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 81%|████████▏ | 273M/335M [00:05<00:01, 59.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 81%|████████▏ | 273M/335M [00:05<00:01, 59.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 81%|████████▏ | 273M/335M [00:05<00:01, 59.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 81%|████████▏ | 273M/335M [00:05<00:01, 59.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 81%|████████▏ | 273M/335M [00:05<00:01, 59.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 81%|████████▏ | 273M/335M [00:05<00:01, 59.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 81%|████████▏ | 273M/335M [00:05<00:01, 59.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 81%|████████▏ | 273M/335M [00:05<00:01, 59.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 82%|████████▏ | 274M/335M [00:05<00:01, 59.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 83%|████████▎ | 278M/335M [00:05<00:00, 61.1MB/s][1,mpirank:11,algo-2]<stderr>:#015 83%|████████▎ | 278M/335M [00:05<00:00, 61.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 83%|████████▎ | 279M/335M [00:05<00:00, 61.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 83%|████████▎ | 279M/335M [00:05<00:00, 61.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 83%|████████▎ | 279M/335M [00:05<00:00, 61.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 83%|████████▎ | 279M/335M [00:05<00:00, 61.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 83%|████████▎ | 279M/335M [00:05<00:00, 60.0MB/s][1,mpirank:2,algo-1]<stderr>:#015 83%|████████▎ | 279M/335M [00:05<00:00, 59.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 83%|████████▎ | 279M/335M [00:05<00:00, 60.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 83%|████████▎ | 279M/335M [00:05<00:00, 59.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 83%|████████▎ | 279M/335M [00:05<00:00, 59.9MB/s][1,mpirank:4,algo-1]<stderr>:#015 83%|████████▎ | 279M/335M [00:05<00:00, 60.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 83%|████████▎ | 279M/335M [00:05<00:00, 60.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 83%|████████▎ | 279M/335M [00:05<00:00, 59.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 83%|████████▎ | 279M/335M [00:05<00:00, 59.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 83%|████████▎ | 280M/335M [00:05<00:00, 59.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 85%|████████▍ | 284M/335M [00:05<00:00, 60.8MB/s][1,mpirank:11,algo-2]<stderr>:#015 85%|████████▍ | 284M/335M [00:05<00:00, 60.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 85%|████████▍ | 285M/335M [00:05<00:00, 59.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 85%|████████▍ | 285M/335M [00:05<00:00, 59.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 85%|████████▍ | 285M/335M [00:05<00:00, 60.2MB/s][1,mpirank:10,algo-2]<stderr>:#015 85%|████████▍ | 285M/335M [00:05<00:00, 59.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 85%|████████▍ | 285M/335M [00:05<00:00, 60.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 85%|████████▍ | 285M/335M [00:05<00:00, 60.1MB/s][1,mpirank:8,algo-2]<stderr>:#015 85%|████████▍ | 285M/335M [00:05<00:00, 60.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 85%|████████▍ | 285M/335M [00:05<00:00, 60.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 85%|████████▍ | 285M/335M [00:05<00:00, 60.2MB/s][1,mpirank:15,algo-2]<stderr>:#015 85%|████████▍ | 285M/335M [00:05<00:00, 59.8MB/s][1,mpirank:5,algo-1]<stderr>:#015 85%|████████▍ | 285M/335M [00:05<00:00, 60.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 85%|████████▍ | 285M/335M [00:05<00:00, 60.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 85%|████████▍ | 285M/335M [00:05<00:00, 60.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 85%|████████▌ | 286M/335M [00:05<00:00, 60.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 87%|████████▋ | 291M/335M [00:05<00:00, 61.7MB/s][1,mpirank:11,algo-2]<stderr>:#015 87%|████████▋ | 291M/335M [00:05<00:00, 61.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 87%|████████▋ | 291M/335M [00:05<00:00, 62.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 87%|████████▋ | 291M/335M [00:05<00:00, 62.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 87%|████████▋ | 291M/335M [00:05<00:00, 62.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 87%|████████▋ | 292M/335M [00:05<00:00, 62.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 87%|████████▋ | 291M/335M [00:05<00:00, 61.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 87%|████████▋ | 292M/335M [00:05<00:00, 62.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 87%|████████▋ | 292M/335M [00:05<00:00, 62.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 87%|████████▋ | 292M/335M [00:05<00:00, 62.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 87%|████████▋ | 292M/335M [00:05<00:00, 62.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 87%|████████▋ | 292M/335M [00:05<00:00, 62.6MB/s][1,mpirank:4,algo-1]<stderr>:#015 87%|████████▋ | 292M/335M [00:05<00:00, 62.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 87%|████████▋ | 292M/335M [00:05<00:00, 62.5MB/s][1,mpirank:9,algo-2]<stderr>:#015 87%|████████▋ | 292M/335M [00:05<00:00, 62.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 87%|████████▋ | 292M/335M [00:05<00:00, 62.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 88%|████████▊ | 297M/335M [00:05<00:00, 62.8MB/s][1,mpirank:11,algo-2]<stderr>:#015 88%|████████▊ | 297M/335M [00:05<00:00, 62.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 89%|████████▊ | 298M/335M [00:05<00:00, 63.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 89%|████████▉ | 298M/335M [00:05<00:00, 63.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 89%|████████▉ | 298M/335M [00:05<00:00, 63.4MB/s][1,mpirank:0,algo-1]<stderr>:#015 89%|████████▉ | 298M/335M [00:05<00:00, 63.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 89%|████████▉ | 298M/335M [00:05<00:00, 63.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 89%|████████▉ | 298M/335M [00:05<00:00, 63.5MB/s][1,mpirank:1,algo-1]<stderr>:#015 89%|████████▉ | 298M/335M [00:05<00:00, 63.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 89%|████████▉ | 298M/335M [00:05<00:00, 63.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 89%|████████▉ | 298M/335M [00:05<00:00, 63.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 89%|████████▉ | 298M/335M [00:05<00:00, 63.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 89%|████████▉ | 298M/335M [00:05<00:00, 63.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 89%|████████▉ | 298M/335M [00:05<00:00, 63.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 89%|████████▉ | 298M/335M [00:05<00:00, 63.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 89%|████████▉ | 299M/335M [00:05<00:00, 63.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 90%|█████████ | 303M/335M [00:05<00:00, 63.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 90%|█████████ | 303M/335M [00:05<00:00, 63.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 91%|█████████ | 304M/335M [00:05<00:00, 63.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 91%|█████████ | 304M/335M [00:05<00:00, 63.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 91%|█████████ | 304M/335M [00:05<00:00, 63.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 91%|█████████ | 304M/335M [00:05<00:00, 63.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 91%|█████████ | 304M/335M [00:05<00:00, 63.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 91%|█████████ | 304M/335M [00:05<00:00, 63.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 91%|█████████ | 304M/335M [00:05<00:00, 63.6MB/s][1,mpirank:4,algo-1]<stderr>:#015 91%|█████████ | 304M/335M [00:05<00:00, 63.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 91%|█████████ | 304M/335M [00:05<00:00, 63.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 91%|█████████ | 304M/335M [00:05<00:00, 63.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 91%|█████████ | 304M/335M [00:05<00:00, 63.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 91%|█████████ | 304M/335M [00:05<00:00, 63.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 91%|█████████ | 304M/335M [00:05<00:00, 62.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 91%|█████████ | 305M/335M [00:05<00:00, 63.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 92%|█████████▏| 309M/335M [00:05<00:00, 59.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 92%|█████████▏| 309M/335M [00:05<00:00, 60.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 92%|█████████▏| 310M/335M [00:05<00:00, 60.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 92%|█████████▏| 310M/335M [00:05<00:00, 60.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 92%|█████████▏| 310M/335M [00:05<00:00, 60.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 92%|█████████▏| 310M/335M [00:05<00:00, 60.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 92%|█████████▏| 310M/335M [00:05<00:00, 60.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 92%|█████████▏| 310M/335M [00:05<00:00, 60.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 92%|█████████▏| 310M/335M [00:05<00:00, 60.2MB/s][1,mpirank:8,algo-2]<stderr>:#015 92%|█████████▏| 310M/335M [00:05<00:00, 60.3MB/s][1,mpirank:4,algo-1]<stderr>:#015 92%|█████████▏| 310M/335M [00:05<00:00, 60.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 92%|█████████▏| 310M/335M [00:05<00:00, 60.3MB/s][1,mpirank:12,algo-2]<stderr>:#015 92%|█████████▏| 310M/335M [00:05<00:00, 60.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 92%|█████████▏| 310M/335M [00:05<00:00, 60.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 92%|█████████▏| 310M/335M [00:05<00:00, 60.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 93%|█████████▎| 311M/335M [00:05<00:00, 60.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 94%|█████████▍| 315M/335M [00:05<00:00, 61.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 94%|█████████▍| 315M/335M [00:05<00:00, 61.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 94%|█████████▍| 316M/335M [00:05<00:00, 62.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 94%|█████████▍| 316M/335M [00:05<00:00, 62.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 94%|█████████▍| 316M/335M [00:05<00:00, 62.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 94%|█████████▍| 316M/335M [00:05<00:00, 62.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 94%|█████████▍| 316M/335M [00:05<00:00, 62.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 94%|█████████▍| 316M/335M [00:05<00:00, 62.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 94%|█████████▍| 316M/335M [00:05<00:00, 62.2MB/s][1,mpirank:8,algo-2]<stderr>:#015 94%|█████████▍| 316M/335M [00:05<00:00, 62.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 94%|█████████▍| 316M/335M [00:05<00:00, 62.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 94%|█████████▍| 316M/335M [00:05<00:00, 62.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 94%|█████████▍| 316M/335M [00:05<00:00, 62.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 94%|█████████▍| 317M/335M [00:05<00:00, 62.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 94%|█████████▍| 317M/335M [00:05<00:00, 62.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 95%|█████████▍| 317M/335M [00:05<00:00, 62.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 96%|█████████▌| 322M/335M [00:06<00:00, 63.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 96%|█████████▌| 322M/335M [00:06<00:00, 63.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 96%|█████████▌| 322M/335M [00:06<00:00, 62.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 96%|█████████▋| 323M/335M [00:05<00:00, 64.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 96%|█████████▋| 323M/335M [00:06<00:00, 63.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 96%|█████████▋| 323M/335M [00:06<00:00, 63.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 96%|█████████▋| 323M/335M [00:05<00:00, 64.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 96%|█████████▋| 323M/335M [00:06<00:00, 64.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015 96%|█████████▋| 323M/335M [00:06<00:00, 64.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 96%|█████████▋| 323M/335M [00:06<00:00, 64.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 96%|█████████▋| 323M/335M [00:06<00:00, 64.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 96%|█████████▋| 323M/335M [00:06<00:00, 63.7MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 96%|█████████▋| 323M/335M [00:06<00:00, 64.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 96%|█████████▋| 323M/335M [00:06<00:00, 64.0MB/s][1,mpirank:5,algo-1]<stderr>:#015 96%|█████████▋| 323M/335M [00:06<00:00, 64.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 96%|█████████▋| 324M/335M [00:06<00:00, 63.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015 98%|█████████▊| 328M/335M [00:06<00:00, 64.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015 98%|█████████▊| 328M/335M [00:06<00:00, 64.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015 98%|█████████▊| 329M/335M [00:06<00:00, 64.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015 98%|█████████▊| 328M/335M [00:06<00:00, 62.6MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015 98%|█████████▊| 329M/335M [00:06<00:00, 64.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015 98%|█████████▊| 329M/335M [00:06<00:00, 64.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015 98%|█████████▊| 329M/335M [00:06<00:00, 64.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015 98%|█████████▊| 329M/335M [00:06<00:00, 63.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015 98%|█████████▊| 329M/335M [00:06<00:00, 64.0MB/s][1,mpirank:4,algo-1]<stderr>:#015 98%|█████████▊| 329M/335M [00:06<00:00, 64.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015 98%|█████████▊| 329M/335M [00:06<00:00, 64.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015 98%|█████████▊| 329M/335M [00:06<00:00, 64.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015 98%|█████████▊| 329M/335M [00:06<00:00, 64.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015 98%|█████████▊| 329M/335M [00:06<00:00, 64.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015 98%|█████████▊| 329M/335M [00:06<00:00, 64.0MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015 98%|█████████▊| 330M/335M [00:06<00:00, 64.1MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015100%|█████████▉| 335M/335M [00:06<00:00, 65.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015100%|█████████▉| 335M/335M [00:06<00:00, 65.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:#015100%|██████████| 335M/335M [00:06<00:00, 57.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:#015100%|██████████| 335M/335M [00:06<00:00, 56.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:#015100%|██████████| 335M/335M [00:06<00:00, 56.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:#015100%|██████████| 335M/335M [00:06<00:00, 56.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:#015100%|██████████| 335M/335M [00:06<00:00, 56.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:#015100%|██████████| 335M/335M [00:06<00:00, 56.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:#015100%|██████████| 335M/335M [00:06<00:00, 56.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:#015100%|██████████| 335M/335M [00:06<00:00, 56.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:#015100%|██████████| 335M/335M [00:06<00:00, 56.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:#015100%|██████████| 335M/335M [00:06<00:00, 56.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:#015100%|██████████| 335M/335M [00:06<00:00, 56.2MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:#015100%|██████████| 335M/335M [00:06<00:00, 56.3MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:#015100%|██████████| 335M/335M [00:06<00:00, 56.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:#015100%|██████████| 335M/335M [00:06<00:00, 56.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015100%|█████████▉| 335M/335M [00:06<00:00, 62.8MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:#015100%|██████████| 335M/335M [00:06<00:00, 57.4MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015100%|█████████▉| 335M/335M [00:06<00:00, 55.5MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:#015100%|██████████| 335M/335M [00:06<00:00, 55.9MB/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Processes 369/5899 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Processes 369/5899 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Processes 369/5899 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:__main__:Processes 369/5899 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:__main__:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Processes 734/734 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>: local_rank : 0, local_batch_size : 40\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:__main__:Processes 734/734 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Processes 734/734 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>: local_rank : 3, local_batch_size : 40\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:__main__:Processes 734/734 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Processes 369/5899 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:__main__:Processes 369/5899 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:__main__:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Processes 734/734 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>: local_rank : 1, local_batch_size : 40\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:__main__:Processes 734/734 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Processes 369/5899 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:__main__:Processes 369/5899 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:__main__:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:__main__:Processes 369/5899 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:__main__:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Processes 369/5899 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:__main__:Processes 734/734 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Processes 734/734 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>: local_rank : 2, local_batch_size : 40\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:__main__:Processes 734/734 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Processes 734/734 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>: local_rank : 5, local_batch_size : 40\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Processes 369/5899 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:__main__:Processes 369/5899 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:__main__:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Processes 734/734 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>: local_rank : 6, local_batch_size : 40\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:__main__:Processes 734/734 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Processes 369/5899 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:__main__:Processes 369/5899 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:__main__:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Processes 369/5899 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:__main__:Processes 369/5899 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:__main__:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Processes 734/734 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>: local_rank : 4, local_batch_size : 40\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:__main__:Processes 734/734 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Processes 734/734 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>: local_rank : 7, local_batch_size : 40\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:__main__:Processes 734/734 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:Processes 369/5899 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:Processes 369/5899 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:Processes 369/5899 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:__main__:Processes 369/5899 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:__main__:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:__main__:Processes 369/5899 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:__main__:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:Processes 369/5899 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:Processes 369/5899 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:Processes 369/5899 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:__main__:Processes 369/5899 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:__main__:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:__main__:Processes 369/5899 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:__main__:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:__main__:Processes 369/5899 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:__main__:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:__main__:Processes 369/5899 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:__main__:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:Processes 369/5899 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:__main__:Processes 369/5899 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:__main__:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:Processes 734/734 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:Processes 734/734 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>: local_rank : 6, local_batch_size : 40\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:__main__:Processes 734/734 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:__main__:Processes 734/734 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>: local_rank : 3, local_batch_size : 40\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:Processes 734/734 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>: local_rank : 7, local_batch_size : 40[1,mpirank:12,algo-2]<stdout>:Processes 369/5899 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:__main__:Processes 734/734 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:__main__:Processes 369/5899 (6%) of train data\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:__main__:Processes 734/734 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:Processes 734/734 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>: local_rank : 1, local_batch_size : 40\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:Processes 734/734 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>: local_rank : 0, local_batch_size : 40\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:__main__:Get test data loader\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:__main__:Processes 734/734 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:__main__:Processes 734/734 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:Processes 734/734 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>: local_rank : 2, local_batch_size : 40\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:__main__:Processes 734/734 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:Processes 734/734 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>: local_rank : 5, local_batch_size : 40\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:Processes 734/734 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>: local_rank : 4, local_batch_size : 40\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:__main__:Processes 734/734 (100%) of test data\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-07-02 09:05:27.948 algo-1:669 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2023-07-02 09:05:27.951 algo-1:208 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2023-07-02 09:05:27.957 algo-1:339 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2023-07-02 09:05:27.962 algo-1:342 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2023-07-02 09:05:27.965 algo-1:343 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2023-07-02 09:05:27.965 algo-1:206 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2023-07-02 09:05:27.970 algo-1:210 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2023-07-02 09:05:27.979 algo-1:344 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:[2023-07-02 09:05:27.979 algo-2:208 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:[2023-07-02 09:05:27.979 algo-2:217 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:[2023-07-02 09:05:27.979 algo-2:212 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:[2023-07-02 09:05:27.980 algo-2:213 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:[2023-07-02 09:05:27.982 algo-2:605 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:[2023-07-02 09:05:27.983 algo-2:209 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:[2023-07-02 09:05:27.983 algo-2:216 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:[2023-07-02 09:05:27.993 algo-2:142 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2023-07-02 09:05:28.430 algo-1:342 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2023-07-02 09:05:28.430 algo-1:343 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2023-07-02 09:05:28.430 algo-1:339 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2023-07-02 09:05:28.430 algo-1:210 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2023-07-02 09:05:28.430 algo-1:344 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-07-02 09:05:28.436 algo-1:669 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2023-07-02 09:05:28.441 algo-1:208 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:[2023-07-02 09:05:28.445 algo-2:217 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:[2023-07-02 09:05:28.446 algo-2:208 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:[2023-07-02 09:05:28.447 algo-2:605 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:[2023-07-02 09:05:28.447 algo-2:209 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:[2023-07-02 09:05:28.453 algo-2:213 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2023-07-02 09:05:28.454 algo-1:206 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:[2023-07-02 09:05:28.454 algo-2:216 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:[2023-07-02 09:05:28.461 algo-2:212 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:[2023-07-02 09:05:28.503 algo-2:142 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [1][0/10] Train_Time=2.080: avg-2.080, Train_Speed=307.712 (307.712), Train_Loss=13.2123851776:(13.2124), Train_Prec@1=0.000:(0.000), Train_Prec@5=0.000:(0.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.nn.parallel.distributed:Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.nn.parallel.distributed:Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.nn.parallel.distributed:Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.nn.parallel.distributed:Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.nn.parallel.distributed:Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.nn.parallel.distributed:Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.nn.parallel.distributed:Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.nn.parallel.distributed:Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.nn.parallel.distributed:Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.nn.parallel.distributed:Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.nn.parallel.distributed:Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.nn.parallel.distributed:Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.nn.parallel.distributed:Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.nn.parallel.distributed:Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.nn.parallel.distributed:Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.nn.parallel.distributed:Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [1][1/10] Train_Time=0.260: avg-1.170, Train_Speed=2463.922 (547.098), Train_Loss=10.5491075516:(11.8807), Train_Prec@1=0.000:(0.000), Train_Prec@5=0.000:(0.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [1][2/10] Train_Time=0.249: avg-0.863, Train_Speed=2573.658 (741.802), Train_Loss=8.6122722626:(10.7913), Train_Prec@1=0.000:(0.000), Train_Prec@5=0.000:(0.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [1][3/10] Train_Time=0.310: avg-0.724, Train_Speed=2067.538 (883.418), Train_Loss=7.2212743759:(9.8988), Train_Prec@1=0.000:(0.000), Train_Prec@5=0.000:(0.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [1][4/10] Train_Time=0.271: avg-0.634, Train_Speed=2357.742 (1009.692), Train_Loss=5.9680967331:(9.1126), Train_Prec@1=0.000:(0.000), Train_Prec@5=10.000:(2.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [1][5/10] Train_Time=0.192: avg-0.560, Train_Speed=3338.320 (1142.518), Train_Loss=5.2399535179:(8.4672), Train_Prec@1=5.000:(0.833), Train_Prec@5=20.000:(5.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [1][6/10] Train_Time=0.082: avg-0.492, Train_Speed=7800.581 (1301.175), Train_Loss=4.8414807320:(7.9492), Train_Prec@1=0.000:(0.714), Train_Prec@5=15.000:(6.429)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [1][7/10] Train_Time=0.077: avg-0.440, Train_Speed=8324.561 (1454.578), Train_Loss=4.6641449928:(7.5386), Train_Prec@1=2.500:(0.938), Train_Prec@5=22.500:(8.438)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [1][8/10] Train_Time=0.074: avg-0.399, Train_Speed=8637.064 (1602.661), Train_Loss=4.6902103424:(7.2221), Train_Prec@1=2.500:(1.111), Train_Prec@5=7.500:(8.333)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [1][9/10] Train_Time=0.070: avg-0.366, Train_Speed=9100.722 (1746.560), Train_Loss=4.8944625854:(7.1653), Train_Prec@1=0.000:(1.084), Train_Prec@5=0.000:(8.130)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [0/4]  Test_Time=5.561:(5.561), Test_Speed=115.085:(115.085), Test_Loss=4.4823:(4.4823), Test_Prec@1=2.500:(2.500), Test_Prec@5=13.000:(13.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [1/4]  Test_Time=7.731:(6.646), Test_Speed=82.779:(96.294), Test_Loss=3.6749:(4.0786), Test_Prec@1=3.500:(3.000), Test_Prec@5=22.500:(17.750)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [2/4]  Test_Time=4.289:(5.860), Test_Speed=149.223:(109.206), Test_Loss=3.6397:(3.9323), Test_Prec@1=12.500:(6.167), Test_Prec@5=23.500:(19.667)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [3/4]  Test_Time=1.988:(4.892), Test_Speed=321.992:(130.819), Test_Loss=4.1083:(3.9644), Test_Prec@1=0.746:(5.177), Test_Prec@5=11.194:(18.120)[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:util:Saving the model.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Saving the model.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [2][0/10] Train_Time=0.203: avg-0.203, Train_Speed=3151.282 (3151.282), Train_Loss=4.1077394485:(4.1077), Train_Prec@1=5.000:(5.000), Train_Prec@5=20.000:(20.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [2][1/10] Train_Time=0.078: avg-0.141, Train_Speed=8164.508 (4547.392), Train_Loss=4.0614018440:(4.0846), Train_Prec@1=5.000:(5.000), Train_Prec@5=15.000:(17.500)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [2][2/10] Train_Time=0.084: avg-0.122, Train_Speed=7603.598 (5250.913), Train_Loss=3.9333519936:(4.0342), Train_Prec@1=10.000:(6.667), Train_Prec@5=15.000:(16.667)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [2][3/10] Train_Time=0.077: avg-0.111, Train_Speed=8302.229 (5782.195), Train_Loss=3.8538944721:(3.9891), Train_Prec@1=7.500:(6.875), Train_Prec@5=12.500:(15.625)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [2][4/10] Train_Time=0.078: avg-0.104, Train_Speed=8206.099 (6145.229), Train_Loss=3.7976939678:(3.9508), Train_Prec@1=0.000:(5.500), Train_Prec@5=15.000:(15.500)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [2][5/10] Train_Time=0.085: avg-0.101, Train_Speed=7510.482 (6337.225), Train_Loss=3.6345515251:(3.8981), Train_Prec@1=5.000:(5.417), Train_Prec@5=12.500:(15.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [2][6/10] Train_Time=0.086: avg-0.099, Train_Speed=7413.710 (6471.464), Train_Loss=3.7581901550:(3.8781), Train_Prec@1=0.000:(4.643), Train_Prec@5=7.500:(13.929)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [2][7/10] Train_Time=0.086: avg-0.097, Train_Speed=7436.499 (6578.170), Train_Loss=3.7341594696:(3.8601), Train_Prec@1=0.000:(4.062), Train_Prec@5=22.500:(15.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [2][8/10] Train_Time=0.083: avg-0.096, Train_Speed=7696.368 (6686.105), Train_Loss=3.7751414776:(3.8507), Train_Prec@1=2.500:(3.889), Train_Prec@5=15.000:(15.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [2][9/10] Train_Time=0.084: avg-0.095, Train_Speed=7608.033 (6768.120), Train_Loss=3.7229185104:(3.8476), Train_Prec@1=0.000:(3.794), Train_Prec@5=0.000:(14.634)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [0/4]  Test_Time=5.592:(5.592), Test_Speed=114.441:(114.441), Test_Loss=3.4037:(3.4037), Test_Prec@1=11.000:(11.000), Test_Prec@5=33.000:(33.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [1/4]  Test_Time=4.327:(4.960), Test_Speed=147.912:(129.041), Test_Loss=3.5968:(3.5003), Test_Prec@1=2.000:(6.500), Test_Prec@5=11.000:(22.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [2/4]  Test_Time=5.739:(5.219), Test_Speed=111.515:(122.618), Test_Loss=3.5669:(3.5225), Test_Prec@1=7.000:(6.667), Test_Prec@5=30.500:(24.833)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [3/4]  Test_Time=3.903:(4.890), Test_Speed=163.973:(130.869), Test_Loss=3.6831:(3.5518), Test_Prec@1=0.000:(5.450), Test_Prec@5=5.970:(21.390)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Saving the model.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:util:Saving the model.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [3][0/10] Train_Time=0.206: avg-0.206, Train_Speed=3105.980 (3105.980), Train_Loss=3.6086375713:(3.6086), Train_Prec@1=2.500:(2.500), Train_Prec@5=17.500:(17.500)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [3][1/10] Train_Time=0.082: avg-0.144, Train_Speed=7841.112 (4449.463), Train_Loss=3.7509589195:(3.6798), Train_Prec@1=2.500:(2.500), Train_Prec@5=20.000:(18.750)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [3][2/10] Train_Time=0.085: avg-0.124, Train_Speed=7528.754 (5151.837), Train_Loss=3.7196998596:(3.6931), Train_Prec@1=2.500:(2.500), Train_Prec@5=12.500:(16.667)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [3][3/10] Train_Time=0.081: avg-0.113, Train_Speed=7941.093 (5647.772), Train_Loss=3.5043473244:(3.6459), Train_Prec@1=5.000:(3.125), Train_Prec@5=27.500:(19.375)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [3][4/10] Train_Time=0.084: avg-0.108, Train_Speed=7598.080 (5953.401), Train_Loss=3.5085463524:(3.6184), Train_Prec@1=2.500:(3.000), Train_Prec@5=20.000:(19.500)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [3][5/10] Train_Time=0.079: avg-0.103, Train_Speed=8096.580 (6228.169), Train_Loss=3.4984855652:(3.5984), Train_Prec@1=10.000:(4.167), Train_Prec@5=32.500:(21.667)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [3][6/10] Train_Time=0.077: avg-0.099, Train_Speed=8289.461 (6457.564), Train_Loss=3.6021206379:(3.5990), Train_Prec@1=5.000:(4.286), Train_Prec@5=20.000:(21.429)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [3][7/10] Train_Time=0.077: avg-0.096, Train_Speed=8361.324 (6646.735), Train_Loss=3.4643046856:(3.5821), Train_Prec@1=5.000:(4.375), Train_Prec@5=32.500:(22.812)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [3][8/10] Train_Time=0.078: avg-0.094, Train_Speed=8192.400 (6789.057), Train_Loss=3.3196282387:(3.5530), Train_Prec@1=12.500:(5.278), Train_Prec@5=35.000:(24.167)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [3][9/10] Train_Time=0.078: avg-0.093, Train_Speed=8166.052 (6905.501), Train_Loss=3.6429014206:(3.5552), Train_Prec@1=0.000:(5.149), Train_Prec@5=22.222:(24.119)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [0/4]  Test_Time=5.524:(5.524), Test_Speed=115.858:(115.858), Test_Loss=3.0949:(3.0949), Test_Prec@1=23.500:(23.500), Test_Prec@5=57.500:(57.500)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [1/4]  Test_Time=10.058:(7.791), Test_Speed=63.629:(82.145), Test_Loss=3.4141:(3.2545), Test_Prec@1=9.500:(16.500), Test_Prec@5=26.500:(42.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [2/4]  Test_Time=4.780:(6.787), Test_Speed=133.888:(94.292), Test_Loss=3.3243:(3.2777), Test_Prec@1=13.500:(15.500), Test_Prec@5=30.500:(38.167)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [3/4]  Test_Time=1.204:(5.392), Test_Speed=531.433:(118.702), Test_Loss=3.3187:(3.2852), Test_Prec@1=7.463:(14.033), Test_Prec@5=41.791:(38.828)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:util:Saving the model.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Saving the model.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [4][0/10] Train_Time=0.192: avg-0.192, Train_Speed=3325.753 (3325.753), Train_Loss=3.3506069183:(3.3506), Train_Prec@1=5.000:(5.000), Train_Prec@5=37.500:(37.500)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [4][1/10] Train_Time=0.083: avg-0.138, Train_Speed=7734.443 (4651.427), Train_Loss=3.6223335266:(3.4865), Train_Prec@1=10.000:(7.500), Train_Prec@5=15.000:(26.250)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [4][2/10] Train_Time=0.075: avg-0.117, Train_Speed=8511.973 (5479.881), Train_Loss=3.2405631542:(3.4045), Train_Prec@1=20.000:(11.667), Train_Prec@5=37.500:(30.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [4][3/10] Train_Time=0.081: avg-0.108, Train_Speed=7865.042 (5929.422), Train_Loss=3.4384264946:(3.4130), Train_Prec@1=12.500:(11.875), Train_Prec@5=40.000:(32.500)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [4][4/10] Train_Time=0.087: avg-0.104, Train_Speed=7349.197 (6167.728), Train_Loss=3.4443652630:(3.4193), Train_Prec@1=5.000:(10.500), Train_Prec@5=30.000:(32.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [4][5/10] Train_Time=0.082: avg-0.100, Train_Speed=7850.395 (6396.224), Train_Loss=3.4348251820:(3.4219), Train_Prec@1=5.000:(9.583), Train_Prec@5=32.500:(32.083)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [4][6/10] Train_Time=0.075: avg-0.097, Train_Speed=8491.697 (6629.946), Train_Loss=3.2087364197:(3.3914), Train_Prec@1=12.500:(10.000), Train_Prec@5=40.000:(33.214)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [4][7/10] Train_Time=0.076: avg-0.094, Train_Speed=8401.483 (6809.426), Train_Loss=3.3682034016:(3.3885), Train_Prec@1=2.500:(9.062), Train_Prec@5=32.500:(33.125)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [4][8/10] Train_Time=0.078: avg-0.092, Train_Speed=8184.008 (6938.921), Train_Loss=3.1167869568:(3.3583), Train_Prec@1=12.500:(9.444), Train_Prec@5=55.000:(35.556)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [4][9/10] Train_Time=0.082: avg-0.091, Train_Speed=7812.259 (7017.369), Train_Loss=2.6225409508:(3.3404), Train_Prec@1=22.222:(9.756), Train_Prec@5=55.556:(36.043)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [0/4]  Test_Time=5.441:(5.441), Test_Speed=117.627:(117.627), Test_Loss=2.8117:(2.8117), Test_Prec@1=23.500:(23.500), Test_Prec@5=63.000:(63.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [1/4]  Test_Time=4.669:(5.055), Test_Speed=137.073:(126.608), Test_Loss=2.8677:(2.8397), Test_Prec@1=14.000:(18.750), Test_Prec@5=58.000:(60.500)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [2/4]  Test_Time=3.009:(4.373), Test_Speed=212.674:(146.350), Test_Loss=2.5927:(2.7574), Test_Prec@1=29.000:(22.167), Test_Prec@5=62.000:(61.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [3/4]  Test_Time=2.827:(3.986), Test_Speed=226.412:(160.542), Test_Loss=3.4538:(2.8845), Test_Prec@1=6.716:(19.346), Test_Prec@5=28.358:(55.041)[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Saving the model.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:util:Saving the model.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [5][0/10] Train_Time=0.193: avg-0.193, Train_Speed=3317.923 (3317.923), Train_Loss=2.9986789227:(2.9987), Train_Prec@1=15.000:(15.000), Train_Prec@5=47.500:(47.500)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [5][1/10] Train_Time=0.089: avg-0.141, Train_Speed=7174.844 (4537.522), Train_Loss=2.9379010201:(2.9683), Train_Prec@1=10.000:(12.500), Train_Prec@5=47.500:(47.500)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [5][2/10] Train_Time=0.090: avg-0.124, Train_Speed=7141.547 (5165.335), Train_Loss=2.9515042305:(2.9627), Train_Prec@1=15.000:(13.333), Train_Prec@5=60.000:(51.667)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [5][3/10] Train_Time=0.084: avg-0.114, Train_Speed=7656.743 (5622.726), Train_Loss=2.8524458408:(2.9351), Train_Prec@1=17.500:(14.375), Train_Prec@5=52.500:(51.875)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [5][4/10] Train_Time=0.083: avg-0.108, Train_Speed=7679.959 (5941.010), Train_Loss=2.9669632912:(2.9415), Train_Prec@1=30.000:(17.500), Train_Prec@5=60.000:(53.500)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [5][5/10] Train_Time=0.077: avg-0.103, Train_Speed=8358.965 (6241.939), Train_Loss=2.8268237114:(2.9224), Train_Prec@1=22.500:(18.333), Train_Prec@5=47.500:(52.500)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [5][6/10] Train_Time=0.078: avg-0.099, Train_Speed=8235.803 (6465.552), Train_Loss=3.0546443462:(2.9413), Train_Prec@1=17.500:(18.214), Train_Prec@5=52.500:(52.500)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [5][7/10] Train_Time=0.085: avg-0.097, Train_Speed=7567.727 (6585.441), Train_Loss=2.6283802986:(2.9022), Train_Prec@1=27.500:(19.375), Train_Prec@5=62.500:(53.750)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [5][8/10] Train_Time=0.077: avg-0.095, Train_Speed=8361.340 (6744.609), Train_Loss=2.7966251373:(2.8904), Train_Prec@1=22.500:(19.722), Train_Prec@5=57.500:(54.167)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [5][9/10] Train_Time=0.071: avg-0.093, Train_Speed=8998.583 (6917.889), Train_Loss=2.9459862709:(2.8918), Train_Prec@1=0.000:(19.241), Train_Prec@5=55.556:(54.201)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [0/4]  Test_Time=5.519:(5.519), Test_Speed=115.972:(115.972), Test_Loss=1.9735:(1.9735), Test_Prec@1=44.500:(44.500), Test_Prec@5=79.000:(79.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [1/4]  Test_Time=5.225:(5.372), Test_Speed=122.480:(119.137), Test_Loss=2.5305:(2.2520), Test_Prec@1=26.000:(35.250), Test_Prec@5=68.000:(73.500)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [2/4]  Test_Time=8.564:(6.436), Test_Speed=74.727:(99.439), Test_Loss=1.8235:(2.1092), Test_Prec@1=52.500:(41.000), Test_Prec@5=80.500:(75.833)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [3/4]  Test_Time=1.558:(5.217), Test_Speed=410.657:(122.683), Test_Loss=2.3916:(2.1607), Test_Prec@1=24.627:(38.011), Test_Prec@5=76.866:(76.022)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Saving the model.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:util:Saving the model.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [6][0/10] Train_Time=0.199: avg-0.199, Train_Speed=3208.670 (3208.670), Train_Loss=2.6435601711:(2.6436), Train_Prec@1=20.000:(20.000), Train_Prec@5=65.000:(65.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [6][1/10] Train_Time=0.085: avg-0.142, Train_Speed=7548.294 (4503.126), Train_Loss=2.2736904621:(2.4586), Train_Prec@1=32.500:(26.250), Train_Prec@5=75.000:(70.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [6][2/10] Train_Time=0.084: avg-0.123, Train_Speed=7605.666 (5211.801), Train_Loss=2.3207097054:(2.4127), Train_Prec@1=30.000:(27.500), Train_Prec@5=72.500:(70.833)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [6][3/10] Train_Time=0.090: avg-0.115, Train_Speed=7101.012 (5583.147), Train_Loss=2.6631219387:(2.4753), Train_Prec@1=30.000:(28.125), Train_Prec@5=62.500:(68.750)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [6][4/10] Train_Time=0.076: avg-0.107, Train_Speed=8367.318 (5981.188), Train_Loss=2.0550198555:(2.3912), Train_Prec@1=50.000:(32.500), Train_Prec@5=77.500:(70.500)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [6][5/10] Train_Time=0.084: avg-0.103, Train_Speed=7649.394 (6206.787), Train_Loss=2.1495366096:(2.3509), Train_Prec@1=40.000:(33.750), Train_Prec@5=75.000:(71.250)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [6][6/10] Train_Time=0.085: avg-0.101, Train_Speed=7518.847 (6365.472), Train_Loss=2.2757160664:(2.3402), Train_Prec@1=37.500:(34.286), Train_Prec@5=70.000:(71.071)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [6][7/10] Train_Time=0.075: avg-0.097, Train_Speed=8487.562 (6570.830), Train_Loss=1.9579169750:(2.2924), Train_Prec@1=47.500:(35.938), Train_Prec@5=75.000:(71.562)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [6][8/10] Train_Time=0.077: avg-0.095, Train_Speed=8342.402 (6729.617), Train_Loss=2.3541994095:(2.2993), Train_Prec@1=30.000:(35.278), Train_Prec@5=72.500:(71.667)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [6][9/10] Train_Time=0.071: avg-0.093, Train_Speed=8999.065 (6903.720), Train_Loss=2.4439833164:(2.3028), Train_Prec@1=22.222:(34.959), Train_Prec@5=66.667:(71.545)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [0/4]  Test_Time=5.673:(5.673), Test_Speed=112.824:(112.824), Test_Loss=1.3090:(1.3090), Test_Prec@1=59.000:(59.000), Test_Prec@5=91.500:(91.500)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [1/4]  Test_Time=6.410:(6.041), Test_Speed=99.841:(105.936), Test_Loss=2.3080:(1.8085), Test_Prec@1=23.000:(41.000), Test_Prec@5=76.500:(84.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [2/4]  Test_Time=6.697:(6.260), Test_Speed=95.558:(102.235), Test_Loss=1.2497:(1.6222), Test_Prec@1=68.000:(50.000), Test_Prec@5=90.000:(86.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [3/4]  Test_Time=2.555:(5.334), Test_Speed=250.455:(119.988), Test_Loss=1.3643:(1.5751), Test_Prec@1=69.403:(53.542), Test_Prec@5=91.045:(86.921)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Saving the model.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:util:Saving the model.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [7][0/10] Train_Time=0.199: avg-0.199, Train_Speed=3211.219 (3211.219), Train_Loss=2.1009678841:(2.1010), Train_Prec@1=40.000:(40.000), Train_Prec@5=80.000:(80.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [7][1/10] Train_Time=0.085: avg-0.142, Train_Speed=7544.692 (4504.994), Train_Loss=1.7594921589:(1.9302), Train_Prec@1=42.500:(41.250), Train_Prec@5=82.500:(81.250)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [7][2/10] Train_Time=0.081: avg-0.122, Train_Speed=7924.584 (5261.853), Train_Loss=1.9830576181:(1.9478), Train_Prec@1=47.500:(43.333), Train_Prec@5=77.500:(80.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [7][3/10] Train_Time=0.084: avg-0.112, Train_Speed=7598.489 (5700.064), Train_Loss=1.8839476109:(1.9319), Train_Prec@1=50.000:(45.000), Train_Prec@5=72.500:(78.125)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [7][4/10] Train_Time=0.083: avg-0.106, Train_Speed=7740.907 (6017.352), Train_Loss=1.6288344860:(1.8713), Train_Prec@1=57.500:(47.500), Train_Prec@5=87.500:(80.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [7][5/10] Train_Time=0.084: avg-0.103, Train_Speed=7651.043 (6239.397), Train_Loss=1.4133325815:(1.7949), Train_Prec@1=62.500:(50.000), Train_Prec@5=90.000:(81.667)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [7][6/10] Train_Time=0.075: avg-0.099, Train_Speed=8484.129 (6484.492), Train_Loss=1.8177483082:(1.7982), Train_Prec@1=50.000:(50.000), Train_Prec@5=92.500:(83.214)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [7][7/10] Train_Time=0.074: avg-0.096, Train_Speed=8601.798 (6690.343), Train_Loss=1.4221055508:(1.7512), Train_Prec@1=65.000:(51.875), Train_Prec@5=85.000:(83.438)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [7][8/10] Train_Time=0.076: avg-0.093, Train_Speed=8411.408 (6845.983), Train_Loss=1.6067453623:(1.7351), Train_Prec@1=55.000:(52.222), Train_Prec@5=87.500:(83.889)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [7][9/10] Train_Time=0.070: avg-0.091, Train_Speed=9143.545 (7022.441), Train_Loss=0.9219682217:(1.7153), Train_Prec@1=77.778:(52.846), Train_Prec@5=77.778:(83.740)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [0/4]  Test_Time=5.529:(5.529), Test_Speed=115.754:(115.754), Test_Loss=0.9726:(0.9726), Test_Prec@1=70.000:(70.000), Test_Prec@5=97.500:(97.500)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [1/4]  Test_Time=7.165:(6.347), Test_Speed=89.321:(100.834), Test_Loss=1.2605:(1.1165), Test_Prec@1=63.000:(66.500), Test_Prec@5=89.000:(93.250)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [2/4]  Test_Time=5.711:(6.135), Test_Speed=112.056:(104.317), Test_Loss=0.8266:(1.0199), Test_Prec@1=76.000:(69.667), Test_Prec@5=94.000:(93.500)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [3/4]  Test_Time=1.909:(5.079), Test_Speed=335.250:(126.018), Test_Loss=0.9211:(1.0018), Test_Prec@1=76.866:(70.981), Test_Prec@5=93.284:(93.460)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Saving the model.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:util:Saving the model.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [8][0/10] Train_Time=0.191: avg-0.191, Train_Speed=3355.531 (3355.531), Train_Loss=1.5858459473:(1.5858), Train_Prec@1=55.000:(55.000), Train_Prec@5=82.500:(82.500)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [8][1/10] Train_Time=0.092: avg-0.141, Train_Speed=6958.418 (4527.691), Train_Loss=1.1652669907:(1.3756), Train_Prec@1=67.500:(61.250), Train_Prec@5=95.000:(88.750)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [8][2/10] Train_Time=0.083: avg-0.122, Train_Speed=7695.097 (5247.699), Train_Loss=1.4644672871:(1.4052), Train_Prec@1=62.500:(61.667), Train_Prec@5=87.500:(88.333)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [8][3/10] Train_Time=0.086: avg-0.113, Train_Speed=7455.302 (5667.233), Train_Loss=1.4803739786:(1.4240), Train_Prec@1=55.000:(60.000), Train_Prec@5=87.500:(88.125)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [8][4/10] Train_Time=0.077: avg-0.106, Train_Speed=8338.608 (6055.205), Train_Loss=1.4431465864:(1.4278), Train_Prec@1=47.500:(57.500), Train_Prec@5=92.500:(89.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [8][5/10] Train_Time=0.081: avg-0.102, Train_Speed=7922.016 (6302.743), Train_Loss=1.4755251408:(1.4358), Train_Prec@1=62.500:(58.333), Train_Prec@5=87.500:(88.750)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [8][6/10] Train_Time=0.082: avg-0.099, Train_Speed=7817.259 (6482.151), Train_Loss=1.1890274286:(1.4005), Train_Prec@1=70.000:(60.000), Train_Prec@5=90.000:(88.929)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [8][7/10] Train_Time=0.075: avg-0.096, Train_Speed=8558.254 (6684.856), Train_Loss=1.1216810942:(1.3657), Train_Prec@1=60.000:(60.000), Train_Prec@5=95.000:(89.688)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [8][8/10] Train_Time=0.076: avg-0.094, Train_Speed=8444.574 (6843.305), Train_Loss=1.3731523752:(1.3665), Train_Prec@1=67.500:(60.833), Train_Prec@5=92.500:(90.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [8][9/10] Train_Time=0.068: avg-0.091, Train_Speed=9365.578 (7032.705), Train_Loss=1.2134242058:(1.3628), Train_Prec@1=66.667:(60.976), Train_Prec@5=88.889:(89.973)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [0/4]  Test_Time=5.504:(5.504), Test_Speed=116.271:(116.271), Test_Loss=0.7213:(0.7213), Test_Prec@1=76.500:(76.500), Test_Prec@5=98.000:(98.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [1/4]  Test_Time=8.114:(6.809), Test_Speed=78.878:(93.992), Test_Loss=0.6891:(0.7052), Test_Prec@1=78.500:(77.500), Test_Prec@5=97.500:(97.750)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [2/4]  Test_Time=6.000:(6.539), Test_Speed=106.672:(97.870), Test_Loss=0.7161:(0.7088), Test_Prec@1=81.500:(78.833), Test_Prec@5=95.000:(96.833)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [3/4]  Test_Time=1.422:(5.260), Test_Speed=450.133:(121.675), Test_Loss=0.6422:(0.6967), Test_Prec@1=78.358:(78.747), Test_Prec@5=94.776:(96.458)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:util:Saving the model.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Saving the model.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [9][0/10] Train_Time=0.202: avg-0.202, Train_Speed=3170.809 (3170.809), Train_Loss=1.1237343550:(1.1237), Train_Prec@1=67.500:(67.500), Train_Prec@5=87.500:(87.500)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [9][1/10] Train_Time=0.083: avg-0.142, Train_Speed=7732.304 (4497.369), Train_Loss=1.4102339745:(1.2670), Train_Prec@1=65.000:(66.250), Train_Prec@5=77.500:(82.500)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [9][2/10] Train_Time=0.078: avg-0.121, Train_Speed=8256.687 (5302.055), Train_Loss=0.7826581597:(1.1055), Train_Prec@1=82.500:(71.667), Train_Prec@5=95.000:(86.667)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [9][3/10] Train_Time=0.075: avg-0.109, Train_Speed=8582.355 (5862.210), Train_Loss=1.3019566536:(1.1546), Train_Prec@1=62.500:(69.375), Train_Prec@5=92.500:(88.125)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [9][4/10] Train_Time=0.080: avg-0.103, Train_Speed=8050.111 (6199.179), Train_Loss=1.3896020651:(1.2016), Train_Prec@1=65.000:(68.500), Train_Prec@5=90.000:(88.500)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [9][5/10] Train_Time=0.076: avg-0.099, Train_Speed=8436.400 (6485.839), Train_Loss=1.2484924793:(1.2094), Train_Prec@1=60.000:(67.083), Train_Prec@5=90.000:(88.750)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [9][6/10] Train_Time=0.076: avg-0.095, Train_Speed=8469.417 (6710.352), Train_Loss=1.2255108356:(1.2117), Train_Prec@1=52.500:(65.000), Train_Prec@5=97.500:(90.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [9][7/10] Train_Time=0.075: avg-0.093, Train_Speed=8477.045 (6889.841), Train_Loss=1.1420165300:(1.2030), Train_Prec@1=65.000:(65.000), Train_Prec@5=90.000:(90.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [9][8/10] Train_Time=0.076: avg-0.091, Train_Speed=8456.466 (7034.643), Train_Loss=1.1703811884:(1.1994), Train_Prec@1=67.500:(65.278), Train_Prec@5=90.000:(90.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [9][9/10] Train_Time=0.070: avg-0.089, Train_Speed=9127.210 (7199.708), Train_Loss=0.4490440786:(1.1811), Train_Prec@1=88.889:(65.854), Train_Prec@5=100.000:(90.244)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [0/4]  Test_Time=5.628:(5.628), Test_Speed=113.714:(113.714), Test_Loss=0.6146:(0.6146), Test_Prec@1=78.500:(78.500), Test_Prec@5=99.000:(99.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [1/4]  Test_Time=4.553:(5.091), Test_Speed=140.552:(125.717), Test_Loss=0.5520:(0.5833), Test_Prec@1=83.000:(80.750), Test_Prec@5=97.500:(98.250)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [2/4]  Test_Time=5.734:(5.305), Test_Speed=111.615:(120.636), Test_Loss=0.4670:(0.5445), Test_Prec@1=87.500:(83.000), Test_Prec@5=97.500:(98.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [3/4]  Test_Time=2.198:(4.528), Test_Speed=291.126:(141.327), Test_Loss=0.4645:(0.5299), Test_Prec@1=85.075:(83.379), Test_Prec@5=99.254:(98.229)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Saving the model.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:util:Saving the model.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [10][0/10] Train_Time=0.209: avg-0.209, Train_Speed=3068.576 (3068.576), Train_Loss=0.9989653826:(0.9990), Train_Prec@1=67.500:(67.500), Train_Prec@5=92.500:(92.500)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [10][1/10] Train_Time=0.081: avg-0.145, Train_Speed=7917.329 (4422.926), Train_Loss=0.6035019159:(0.8012), Train_Prec@1=80.000:(73.750), Train_Prec@5=100.000:(96.250)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [10][2/10] Train_Time=0.086: avg-0.125, Train_Speed=7473.243 (5119.454), Train_Loss=1.2590620518:(0.9538), Train_Prec@1=65.000:(70.833), Train_Prec@5=95.000:(95.833)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [10][3/10] Train_Time=0.085: avg-0.115, Train_Speed=7485.559 (5558.717), Train_Loss=1.3455102444:(1.0518), Train_Prec@1=55.000:(66.875), Train_Prec@5=85.000:(93.125)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [10][4/10] Train_Time=0.087: avg-0.110, Train_Speed=7352.023 (5843.801), Train_Loss=1.0824329853:(1.0579), Train_Prec@1=70.000:(67.500), Train_Prec@5=92.500:(93.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [10][5/10] Train_Time=0.075: avg-0.104, Train_Speed=8482.590 (6163.353), Train_Loss=1.1350269318:(1.0707), Train_Prec@1=62.500:(66.667), Train_Prec@5=92.500:(92.917)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [10][6/10] Train_Time=0.084: avg-0.101, Train_Speed=7621.266 (6336.517), Train_Loss=0.7468171120:(1.0245), Train_Prec@1=77.500:(68.214), Train_Prec@5=95.000:(93.214)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [10][7/10] Train_Time=0.082: avg-0.099, Train_Speed=7785.856 (6487.472), Train_Loss=1.1302279234:(1.0377), Train_Prec@1=75.000:(69.062), Train_Prec@5=90.000:(92.812)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [10][8/10] Train_Time=0.077: avg-0.096, Train_Speed=8339.172 (6651.581), Train_Loss=1.0281229019:(1.0366), Train_Prec@1=65.000:(68.611), Train_Prec@5=97.500:(93.333)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [10][9/10] Train_Time=0.077: avg-0.094, Train_Speed=8263.402 (6783.904), Train_Loss=1.3782483339:(1.0450), Train_Prec@1=33.333:(67.751), Train_Prec@5=88.889:(93.225)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [0/4]  Test_Time=5.526:(5.526), Test_Speed=115.808:(115.808), Test_Loss=0.6036:(0.6036), Test_Prec@1=78.500:(78.500), Test_Prec@5=99.000:(99.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [1/4]  Test_Time=7.225:(6.376), Test_Speed=88.581:(100.381), Test_Loss=0.4806:(0.5421), Test_Prec@1=83.500:(81.000), Test_Prec@5=98.000:(98.500)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [2/4]  Test_Time=4.251:(5.667), Test_Speed=150.568:(112.928), Test_Loss=0.3729:(0.4857), Test_Prec@1=91.000:(84.333), Test_Prec@5=99.000:(98.667)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [3/4]  Test_Time=2.291:(4.823), Test_Speed=279.344:(132.690), Test_Loss=0.3230:(0.4560), Test_Prec@1=91.045:(85.559), Test_Prec@5=100.000:(98.910)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Saving the model.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:util:Saving the model.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [11][0/10] Train_Time=0.201: avg-0.201, Train_Speed=3189.490 (3189.490), Train_Loss=0.8286902308:(0.8287), Train_Prec@1=72.500:(72.500), Train_Prec@5=97.500:(97.500)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [11][1/10] Train_Time=0.084: avg-0.142, Train_Speed=7627.433 (4498.067), Train_Loss=1.1078059673:(0.9682), Train_Prec@1=65.000:(68.750), Train_Prec@5=92.500:(95.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [11][2/10] Train_Time=0.086: avg-0.123, Train_Speed=7468.054 (5185.475), Train_Loss=0.7389863729:(0.8918), Train_Prec@1=72.500:(70.000), Train_Prec@5=97.500:(95.833)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [11][3/10] Train_Time=0.087: avg-0.114, Train_Speed=7316.981 (5592.782), Train_Loss=1.2803102732:(0.9889), Train_Prec@1=67.500:(69.375), Train_Prec@5=85.000:(93.125)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [11][4/10] Train_Time=0.090: avg-0.109, Train_Speed=7146.874 (5847.072), Train_Loss=0.9544256926:(0.9820), Train_Prec@1=72.500:(70.000), Train_Prec@5=90.000:(92.500)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [11][5/10] Train_Time=0.085: avg-0.105, Train_Speed=7501.680 (6070.218), Train_Loss=0.9359269142:(0.9744), Train_Prec@1=72.500:(70.417), Train_Prec@5=92.500:(92.500)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [11][6/10] Train_Time=0.076: avg-0.101, Train_Speed=8407.341 (6321.250), Train_Loss=0.8768768311:(0.9604), Train_Prec@1=80.000:(71.786), Train_Prec@5=95.000:(92.857)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [11][7/10] Train_Time=0.075: avg-0.098, Train_Speed=8518.661 (6531.864), Train_Loss=0.9064676166:(0.9537), Train_Prec@1=75.000:(72.188), Train_Prec@5=95.000:(93.125)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [11][8/10] Train_Time=0.081: avg-0.096, Train_Speed=7902.715 (6660.233), Train_Loss=0.7273988128:(0.9285), Train_Prec@1=82.500:(73.333), Train_Prec@5=92.500:(93.056)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [11][9/10] Train_Time=0.070: avg-0.093, Train_Speed=9180.111 (6848.212), Train_Loss=0.9379640222:(0.9288), Train_Prec@1=66.667:(73.171), Train_Prec@5=100.000:(93.225)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [0/4]  Test_Time=5.533:(5.533), Test_Speed=115.663:(115.663), Test_Loss=0.5710:(0.5710), Test_Prec@1=81.000:(81.000), Test_Prec@5=99.000:(99.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [1/4]  Test_Time=4.310:(4.922), Test_Speed=148.501:(130.041), Test_Loss=0.4356:(0.5033), Test_Prec@1=86.500:(83.750), Test_Prec@5=98.500:(98.750)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [2/4]  Test_Time=4.128:(4.657), Test_Speed=155.049:(137.429), Test_Loss=0.2413:(0.4160), Test_Prec@1=94.500:(87.333), Test_Prec@5=99.500:(99.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [3/4]  Test_Time=4.924:(4.724), Test_Speed=129.963:(135.484), Test_Loss=0.3322:(0.4007), Test_Prec@1=89.552:(87.738), Test_Prec@5=100.000:(99.183)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Saving the model.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:util:Saving the model.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [12][0/10] Train_Time=0.192: avg-0.192, Train_Speed=3333.138 (3333.138), Train_Loss=0.8345602751:(0.8346), Train_Prec@1=80.000:(80.000), Train_Prec@5=95.000:(95.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [12][1/10] Train_Time=0.085: avg-0.139, Train_Speed=7488.730 (4613.061), Train_Loss=0.7747018933:(0.8046), Train_Prec@1=77.500:(78.750), Train_Prec@5=92.500:(93.750)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [12][2/10] Train_Time=0.076: avg-0.118, Train_Speed=8366.625 (5424.228), Train_Loss=0.7131794095:(0.7741), Train_Prec@1=82.500:(80.000), Train_Prec@5=97.500:(95.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [12][3/10] Train_Time=0.079: avg-0.108, Train_Speed=8079.531 (5909.784), Train_Loss=0.6930959225:(0.7539), Train_Prec@1=80.000:(80.000), Train_Prec@5=95.000:(95.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [12][4/10] Train_Time=0.080: avg-0.103, Train_Speed=8034.089 (6239.757), Train_Loss=0.7309237719:(0.7493), Train_Prec@1=77.500:(79.500), Train_Prec@5=97.500:(95.500)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [12][5/10] Train_Time=0.079: avg-0.099, Train_Speed=8059.227 (6483.720), Train_Loss=0.9301735163:(0.7794), Train_Prec@1=72.500:(78.333), Train_Prec@5=92.500:(95.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [12][6/10] Train_Time=0.075: avg-0.095, Train_Speed=8578.032 (6718.034), Train_Loss=0.6907287836:(0.7668), Train_Prec@1=77.500:(78.214), Train_Prec@5=90.000:(94.286)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [12][7/10] Train_Time=0.078: avg-0.093, Train_Speed=8182.955 (6871.809), Train_Loss=0.7705169916:(0.7672), Train_Prec@1=75.000:(77.812), Train_Prec@5=95.000:(94.375)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [12][8/10] Train_Time=0.075: avg-0.091, Train_Speed=8482.777 (7019.938), Train_Loss=0.8436209559:(0.7757), Train_Prec@1=72.500:(77.222), Train_Prec@5=92.500:(94.167)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [12][9/10] Train_Time=0.071: avg-0.089, Train_Speed=9011.736 (7178.601), Train_Loss=0.8510024548:(0.7776), Train_Prec@1=77.778:(77.236), Train_Prec@5=88.889:(94.038)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [0/4]  Test_Time=5.628:(5.628), Test_Speed=113.716:(113.716), Test_Loss=0.4730:(0.4730), Test_Prec@1=82.000:(82.000), Test_Prec@5=99.500:(99.500)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [1/4]  Test_Time=3.759:(4.693), Test_Speed=170.260:(136.359), Test_Loss=0.3683:(0.4207), Test_Prec@1=86.000:(84.000), Test_Prec@5=99.500:(99.500)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [2/4]  Test_Time=4.316:(4.568), Test_Speed=148.278:(140.113), Test_Loss=0.2196:(0.3536), Test_Prec@1=94.500:(87.500), Test_Prec@5=99.000:(99.333)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [3/4]  Test_Time=4.551:(4.564), Test_Speed=140.615:(140.238), Test_Loss=0.1971:(0.3251), Test_Prec@1=94.030:(88.692), Test_Prec@5=100.000:(99.455)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:util:Saving the model.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Saving the model.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [13][0/10] Train_Time=0.239: avg-0.239, Train_Speed=2682.513 (2682.513), Train_Loss=0.7501503229:(0.7502), Train_Prec@1=85.000:(85.000), Train_Prec@5=90.000:(90.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [13][1/10] Train_Time=0.078: avg-0.158, Train_Speed=8168.001 (4038.660), Train_Loss=0.9136956334:(0.8319), Train_Prec@1=72.500:(78.750), Train_Prec@5=92.500:(91.250)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [13][2/10] Train_Time=0.077: avg-0.131, Train_Speed=8353.009 (4878.596), Train_Loss=0.5808140039:(0.7482), Train_Prec@1=75.000:(77.500), Train_Prec@5=97.500:(93.333)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [13][3/10] Train_Time=0.080: avg-0.118, Train_Speed=7989.897 (5404.755), Train_Loss=0.4589876533:(0.6759), Train_Prec@1=80.000:(78.125), Train_Prec@5=97.500:(94.375)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [13][4/10] Train_Time=0.088: avg-0.112, Train_Speed=7280.996 (5698.441), Train_Loss=0.7718492746:(0.6951), Train_Prec@1=70.000:(76.500), Train_Prec@5=95.000:(94.500)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [13][5/10] Train_Time=0.087: avg-0.108, Train_Speed=7360.216 (5921.256), Train_Loss=0.5784369111:(0.6757), Train_Prec@1=80.000:(77.083), Train_Prec@5=95.000:(94.583)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [13][6/10] Train_Time=0.085: avg-0.105, Train_Speed=7569.208 (6111.334), Train_Loss=0.4758160710:(0.6471), Train_Prec@1=80.000:(77.500), Train_Prec@5=100.000:(95.357)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [13][7/10] Train_Time=0.081: avg-0.102, Train_Speed=7905.424 (6289.762), Train_Loss=0.8234942555:(0.6692), Train_Prec@1=72.500:(76.875), Train_Prec@5=92.500:(95.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [13][8/10] Train_Time=0.075: avg-0.099, Train_Speed=8501.449 (6476.986), Train_Loss=0.6405639648:(0.6660), Train_Prec@1=75.000:(76.667), Train_Prec@5=97.500:(95.278)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [13][9/10] Train_Time=0.069: avg-0.096, Train_Speed=9287.132 (6679.085), Train_Loss=0.8634245396:(0.6708), Train_Prec@1=77.778:(76.694), Train_Prec@5=88.889:(95.122)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [0/4]  Test_Time=5.551:(5.551), Test_Speed=115.293:(115.293), Test_Loss=0.4177:(0.4177), Test_Prec@1=84.000:(84.000), Test_Prec@5=99.500:(99.500)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [1/4]  Test_Time=7.227:(6.389), Test_Speed=88.554:(100.170), Test_Loss=0.3299:(0.3738), Test_Prec@1=89.000:(86.500), Test_Prec@5=99.000:(99.250)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [2/4]  Test_Time=3.267:(5.348), Test_Speed=195.897:(119.661), Test_Loss=0.2432:(0.3303), Test_Prec@1=94.500:(89.167), Test_Prec@5=98.500:(99.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [3/4]  Test_Time=2.443:(4.622), Test_Speed=262.017:(138.469), Test_Loss=0.1863:(0.3040), Test_Prec@1=92.537:(89.782), Test_Prec@5=100.000:(99.183)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Saving the model.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:util:Saving the model.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [14][0/10] Train_Time=0.208: avg-0.208, Train_Speed=3083.479 (3083.479), Train_Loss=0.6051532030:(0.6052), Train_Prec@1=82.500:(82.500), Train_Prec@5=97.500:(97.500)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [14][1/10] Train_Time=0.097: avg-0.152, Train_Speed=6591.323 (4201.472), Train_Loss=0.7911351323:(0.6981), Train_Prec@1=70.000:(76.250), Train_Prec@5=92.500:(95.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [14][2/10] Train_Time=0.080: avg-0.128, Train_Speed=8017.565 (4993.760), Train_Loss=0.8843487501:(0.7602), Train_Prec@1=75.000:(75.833), Train_Prec@5=90.000:(93.333)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [14][3/10] Train_Time=0.076: avg-0.115, Train_Speed=8390.858 (5556.118), Train_Loss=0.6116586924:(0.7231), Train_Prec@1=85.000:(78.125), Train_Prec@5=95.000:(93.750)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [14][4/10] Train_Time=0.079: avg-0.108, Train_Speed=8109.137 (5929.476), Train_Loss=0.9750863910:(0.7735), Train_Prec@1=70.000:(76.500), Train_Prec@5=90.000:(93.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [14][5/10] Train_Time=0.075: avg-0.102, Train_Speed=8528.497 (6246.755), Train_Loss=0.7230252624:(0.7651), Train_Prec@1=77.500:(76.667), Train_Prec@5=97.500:(93.750)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [14][6/10] Train_Time=0.078: avg-0.099, Train_Speed=8196.748 (6466.523), Train_Loss=0.9424335361:(0.7904), Train_Prec@1=65.000:(75.000), Train_Prec@5=95.000:(93.929)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [14][7/10] Train_Time=0.077: avg-0.096, Train_Speed=8313.650 (6651.244), Train_Loss=0.5744396448:(0.7634), Train_Prec@1=82.500:(75.938), Train_Prec@5=100.000:(94.688)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [14][8/10] Train_Time=0.077: avg-0.094, Train_Speed=8334.212 (6803.905), Train_Loss=0.7431421280:(0.7612), Train_Prec@1=70.000:(75.278), Train_Prec@5=97.500:(95.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [14][9/10] Train_Time=0.070: avg-0.092, Train_Speed=9160.932 (6983.586), Train_Loss=0.2147655785:(0.7478), Train_Prec@1=100.000:(75.881), Train_Prec@5=100.000:(95.122)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [0/4]  Test_Time=5.520:(5.520), Test_Speed=115.943:(115.943), Test_Loss=0.4138:(0.4138), Test_Prec@1=86.500:(86.500), Test_Prec@5=100.000:(100.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [1/4]  Test_Time=5.114:(5.317), Test_Speed=125.144:(120.368), Test_Loss=0.2462:(0.3300), Test_Prec@1=92.500:(89.500), Test_Prec@5=99.500:(99.750)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [2/4]  Test_Time=5.327:(5.320), Test_Speed=120.141:(120.292), Test_Loss=0.2575:(0.3059), Test_Prec@1=94.000:(91.000), Test_Prec@5=98.500:(99.333)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [3/4]  Test_Time=3.602:(4.891), Test_Speed=177.672:(130.857), Test_Loss=0.2758:(0.3004), Test_Prec@1=88.060:(90.463), Test_Prec@5=99.254:(99.319)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Saving the model.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:util:Saving the model.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [15][0/10] Train_Time=0.200: avg-0.200, Train_Speed=3194.864 (3194.864), Train_Loss=0.7077129483:(0.7077), Train_Prec@1=77.500:(77.500), Train_Prec@5=100.000:(100.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [15][1/10] Train_Time=0.084: avg-0.142, Train_Speed=7654.957 (4508.193), Train_Loss=0.7298768759:(0.7188), Train_Prec@1=72.500:(75.000), Train_Prec@5=97.500:(98.750)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [15][2/10] Train_Time=0.079: avg-0.121, Train_Speed=8122.652 (5293.347), Train_Loss=0.6259239912:(0.6878), Train_Prec@1=77.500:(75.833), Train_Prec@5=95.000:(97.500)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [15][3/10] Train_Time=0.076: avg-0.110, Train_Speed=8398.156 (5832.409), Train_Loss=0.2863280177:(0.5875), Train_Prec@1=95.000:(80.625), Train_Prec@5=100.000:(98.125)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [15][4/10] Train_Time=0.076: avg-0.103, Train_Speed=8396.816 (6211.830), Train_Loss=0.3539518118:(0.5408), Train_Prec@1=90.000:(82.500), Train_Prec@5=97.500:(98.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [15][5/10] Train_Time=0.075: avg-0.098, Train_Speed=8494.105 (6503.047), Train_Loss=0.4953709245:(0.5332), Train_Prec@1=85.000:(82.917), Train_Prec@5=97.500:(97.917)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [15][6/10] Train_Time=0.076: avg-0.095, Train_Speed=8379.239 (6717.934), Train_Loss=0.7050105333:(0.5577), Train_Prec@1=77.500:(82.143), Train_Prec@5=95.000:(97.500)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [15][7/10] Train_Time=0.079: avg-0.093, Train_Speed=8060.554 (6860.781), Train_Loss=0.7342107296:(0.5798), Train_Prec@1=77.500:(81.562), Train_Prec@5=97.500:(97.500)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [15][8/10] Train_Time=0.076: avg-0.091, Train_Speed=8421.156 (7005.000), Train_Loss=0.5453255773:(0.5760), Train_Prec@1=75.000:(80.833), Train_Prec@5=100.000:(97.778)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Epoch: [15][9/10] Train_Time=0.073: avg-0.090, Train_Speed=8734.198 (7146.487), Train_Loss=0.9097739458:(0.5841), Train_Prec@1=66.667:(80.488), Train_Prec@5=100.000:(97.832)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [0/4]  Test_Time=5.628:(5.628), Test_Speed=113.707:(113.707), Test_Loss=0.4443:(0.4443), Test_Prec@1=87.000:(87.000), Test_Prec@5=99.000:(99.000)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [1/4]  Test_Time=6.238:(5.933), Test_Speed=102.593:(107.864), Test_Loss=0.2860:(0.3651), Test_Prec@1=90.000:(88.500), Test_Prec@5=100.000:(99.500)[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [2/4]  Test_Time=3.799:(5.222), Test_Speed=168.459:(122.559), Test_Loss=0.2269:(0.3190), Test_Prec@1=95.500:(90.833), Test_Prec@5=98.500:(99.167)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Test: [3/4]  Test_Time=2.757:(4.606), Test_Speed=232.135:(138.957), Test_Loss=0.1984:(0.2970), Test_Prec@1=91.791:(91.008), Test_Prec@5=100.000:(99.319)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:util:Saving the model.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Saving the model.\u001b[0m\n",
      "\u001b[34m2023-07-02 09:15:42,211 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-07-02 09:15:42,211 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-07-02 09:15:42,212 sagemaker-training-toolkit INFO     Begin writing status file from leader node to worker nodes\u001b[0m\n",
      "\u001b[34m2023-07-02 09:15:42,212 sagemaker-training-toolkit INFO     Start writing mpirun finished status to algo-2\u001b[0m\n",
      "\u001b[34m2023-07-02 09:15:42,369 sagemaker-training-toolkit INFO     output from subprocess run CompletedProcess(args=['ssh', 'algo-2', 'touch', '/tmp/done.algo-1'], returncode=0, stdout='', stderr='')\u001b[0m\n",
      "\u001b[34m2023-07-02 09:15:42,369 sagemaker-training-toolkit INFO     Finished writing status file\u001b[0m\n",
      "\u001b[35m2023-07-02 09:15:42,244 sagemaker-training-toolkit INFO     Invoked on_terminate from psutil.wait_for_procs\u001b[0m\n",
      "\u001b[35m2023-07-02 09:15:42,244 sagemaker-training-toolkit INFO     process psutil.Process(pid=68, name='orted', status='terminated', started='09:05:04') terminated with exit code None\u001b[0m\n",
      "\u001b[35m2023-07-02 09:15:42,244 sagemaker-training-toolkit INFO     Reporting status for ORTEd process. gone: [psutil.Process(pid=68, name='orted', status='terminated', started='09:05:04')] alive: []\u001b[0m\n",
      "\u001b[35m2023-07-02 09:15:42,244 sagemaker-training-toolkit INFO     Orted process exited\u001b[0m\n",
      "\u001b[34m2023-07-02 09:16:12,399 sagemaker-training-toolkit INFO     Finished writing status file from leader node to worker nodes\u001b[0m\n",
      "\u001b[34m2023-07-02 09:16:12,400 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\u001b[35m2023-07-02 09:16:12,274 sagemaker-training-toolkit INFO     Begin looking for status file on algo-2\u001b[0m\n",
      "\u001b[35m2023-07-02 09:16:12,275 sagemaker-training-toolkit INFO     MPI training job status file found. Exit gracefully\u001b[0m\n",
      "\u001b[35m2023-07-02 09:16:12,275 sagemaker-training-toolkit INFO     End looking for status file\u001b[0m\n",
      "\u001b[35m2023-07-02 09:16:12,275 sagemaker-training-toolkit INFO     MPI process finished.\u001b[0m\n",
      "\u001b[35m2023-07-02 09:16:12,275 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-07-02 09:16:31 Uploading - Uploading generated training model\n",
      "2023-07-02 09:18:37 Completed - Training job completed\n",
      "Training seconds: 2182\n",
      "Billable seconds: 2182\n"
     ]
    }
   ],
   "source": [
    "estimator.logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_dir = './result/model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-west-2-322537213286/oxford-ml-p3-16xlarge-0702-08121688285551/output/\n",
      "2023-07-02 08:30:57    1.8 GiB model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "artifacts_dir = estimator.model_data.replace('model.tar.gz', '')\n",
    "print(artifacts_dir)\n",
    "!aws s3 ls --human-readable {artifacts_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-west-2-322537213286/oxford-ml-p3-16xlarge-0702-08121688285551/output/model.tar.gz to result/model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp {artifacts_dir}model.tar.gz {model_dir}/model.tar.gz\n",
    "!tar -xzf {model_dir}/model.tar.gz -C {model_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json , os\n",
    "\n",
    "with open(os.path.join(model_dir, 'model_history.p'), \"r\") as f:\n",
    "    model_history = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_curves(history): \n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 4), sharex=True)\n",
    "    \n",
    "    ax = axes[0]\n",
    "    ax.plot(history['epoch'], history['losses'], label='train')\n",
    "    ax.plot(history['val_avg_epoch'], history['val_avg_losses'], label='validation')\n",
    "    ax.set(\n",
    "        title='model loss',\n",
    "        ylabel='loss',\n",
    "        xlabel='epoch')\n",
    "    ax.legend()\n",
    "    \n",
    "    # ax = axes[1]\n",
    "    # ax.plot(history['epoch'], history['batch_time'], label='train')\n",
    "    # ax.plot(history['val_avg_epoch'], history['val_avg_batch_time'], label='validation')\n",
    "    # ax.set(\n",
    "    #     title='model batch_time',\n",
    "    #     ylabel='batch_time',\n",
    "    #     xlabel='epoch')\n",
    "    # ax.legend()\n",
    "    \n",
    "    \n",
    "    ax = axes[1]\n",
    "    ax.plot(history['epoch'], history['top1'], label='train')\n",
    "    ax.plot(history['val_avg_epoch'], history['val_avg_top1'], label='validation')\n",
    "    ax.set(\n",
    "        title='top1 accuracy',\n",
    "        ylabel='accuracy',\n",
    "        xlabel='epoch')\n",
    "    ax.legend()\n",
    "    \n",
    "    ax = axes[2]\n",
    "    ax.plot(history['epoch'], history['top5'], label='train')\n",
    "    ax.plot(history['val_avg_epoch'], history['val_avg_top5'], label='validation')\n",
    "    ax.set(\n",
    "        title='top5 accuracy',\n",
    "        ylabel='accuracy',\n",
    "        xlabel='epoch')\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    \n",
    "plot_training_curves(model_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
