{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Multigpu Distributed Training-ScriptMode\n",
    "---\n",
    "\n",
    "본 모듈에서는 Amzaon SageMaker API을 효과적으로 이용하기 위해 multigpu-distributed 학습을 위한 PyTorch 프레임워크 기반 모델 훈련을 수행해 봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sagemaker notebook 설명\n",
    "<p>Sagemaker notebook은 완전 관리형 서비스로 컨테이너 기반으로 구성되어 있습니다. 사용자가 직접 컨테이너를 볼 수 없지만, 내부적으로는 아래와 같은 원리로 동작합니다. </p>\n",
    "<p><img src=\"./imgs/fig00.png\" width=\"800\", height=\"80\"></p>\n",
    "\n",
    "- **S3 (Simple Storage Serivce)** : Object Storage로서 학습할 데이터 파일과 학습 결과인 model, checkpoint, tensorboard를 위한 event 파일, 로그 정보 등을 저장하는데 사용합니다.\n",
    "- **SageMaker Notebook** : 학습을 위한 스크립트 작성과 디버깅, 그리고 실제 학습을 수행하기 위한 Python을 개발하기 위한 환경을 제공합니다.\n",
    "- **Amazon Elastic Container Registry(ECR)** :  Docker 컨테이너 이미지를 손쉽게 저장, 관리 및 배포할 수 있게 해주는 완전관리형 Docker 컨테이너 레지스트리입니다. Sagemaker는 기본적인 컨테이너를 제공하기 때문에 별도 ECR에 컨테이너 이미지를 등록할 필요는 없습니다. 하지만, 별도의 학습 및 배포 환경이 필요한 경우 custom 컨테이너 이미지를 만들어서 ECR에 등록한 후 이 환경을 활용할 수 있습니다.\n",
    "\n",
    "<p>학습과 추론을 하는 hosting 서비스는 각각 다른 컨테이너 환경에서 수행할 수 있으며, 쉽게 다량으로 컨테이너 환경을 확장할 수 있으므로 다량의 학습과 hosting이 동시에 가능합니다.   \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install_needed = True  # should only be True once\n",
    "# install_needed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import IPython\n",
    "\n",
    "if install_needed:\n",
    "    print(\"installing deps and restarting kernel\")\n",
    "    !{sys.executable} -m pip install -U split-folders tqdm albumentations crc32c wget\n",
    "    # !{sys.executable} -m pip install 'sagemaker[local]' --upgrade\n",
    "    !{sys.executable} -m pip install -U bokeh smdebug\n",
    "    !{sys.executable} -m pip install sagemaker\n",
    "    IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 환경 설정\n",
    "\n",
    "<p>Sagemaker 학습에 필요한 기본적인 package를 import 합니다. </p>\n",
    "<p>boto3는 HTTP API 호출을 숨기는 편한 추상화 모델을 가지고 있고, Amazon EC2 인스턴스 및 S3 버켓과 같은 AWS 리소스와 동작하는 파이선 클래스를 제공합니다. </p>\n",
    "<p>sagemaker python sdk는 Amazon SageMaker에서 기계 학습 모델을 교육 및 배포하기 위한 오픈 소스 라이브러리입니다.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import sagemaker\n",
    "import splitfolders\n",
    "\n",
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import wget\n",
    "import tarfile\n",
    "import shutil\n",
    "\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "from sagemaker.debugger import (Rule,\n",
    "                                rule_configs,\n",
    "                                ProfilerConfig, \n",
    "                                FrameworkProfile, \n",
    "                                DetailedProfilingConfig, \n",
    "                                DataloaderProfilingConfig, \n",
    "                                PythonProfilingConfig)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = boto3.Session()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "sm = sess.client('sagemaker')\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. S3의 저장 데이터 위치 가져오기\n",
    "<p> 데이터를 정하기 위한 S3의 bucket 위치는 아래 data_bucket 이름으로 생성하며, 기본적으로 SageMaker에서 학습한 모델과 로그 정보를 남기는 위치는 자동으로 생성되는 bucket 이름으로 저장됩니다. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a s3 bucket to hold data, note that your account might already created a bucket with the same name\n",
    "account_id = sess.client('sts').get_caller_identity()[\"Account\"]\n",
    "job_bucket = 'sagemaker-experiments-{}-{}'.format(sess.region_name, account_id)\n",
    "data_bucket = 'sagemaker-{}-{}'.format(sess.region_name, account_id)\n",
    "try:\n",
    "    if sess.region_name == \"us-east-1\":\n",
    "        sess.client('s3').create_bucket(Bucket=data_bucket)\n",
    "    else:\n",
    "        sess.client('s3').create_bucket(Bucket=data_bucket, \n",
    "                                        CreateBucketConfiguration={'LocationConstraint': sess.region_name})\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dataset 소개 및 split 후 S3 upload하기\n",
    "<p>이번 학습에 사용할 이미지 데이터는 <strong><a href=\"https://www.robots.ox.ac.uk/~vgg/data/pets/\" target=\"_blank\" class ='btn-default'>Oxford-IIIT Pet Dataset</a></strong> 입니다. Oxford-IIIT Pet Dataset은 <strong>37</strong>개 다른 종의 개와 고양이 이미지를 각각 200장 씩 제공하고 있으며, Ground Truth 또한 Classification, Object Detection, Segmentation와 관련된 모든 정보가 있으나, 이번 학습에서는 37개 class에 대해 일부 이미지로 Classification 문제를 해결하기 위해 학습을 진행할 예정입니다.</p>\n",
    "<p><img src=\"./imgs/pet_annotations.jpg\" width=\"700\", height=\"70\"></p>    \n",
    "<p>이미지 파일을 학습하기 위해 SageMaker Notebook 환경으로 upload를 합니다. 폴더 구조는 아래와 같은 형태로 구성되어야 합니다. </p>\n",
    "<pre>\n",
    "<div style='line-height:80%'>\n",
    "    image_path/class1/Aimage_1<br>\n",
    "                      Aimage_2<br>\n",
    "                       ...<br>\n",
    "                      Aimage_N<br>\n",
    "    image_path/class2/Bimage_1<br>\n",
    "                      Bimage_2<br>\n",
    "                       ...<br>\n",
    "                      Bimage_M<br>\n",
    "</div>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>SageMaker 학습을 위해 train/val로 분리한 폴더를 S3내 이전에 지정한 data_bucket 내 prefix 하위 폴더로 upload합니다. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dir(img_path, delete=True):\n",
    "    import shutil, os\n",
    "    try:\n",
    "        if not os.path.exists(img_path):\n",
    "            os.makedirs(img_path)\n",
    "        else:\n",
    "            if delete:\n",
    "                shutil.rmtree(img_path)\n",
    "    except OSError:\n",
    "        print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawimg_path = 'raw_img'\n",
    "output_path = 'data'\n",
    "dataset_path = './dataset'\n",
    "\n",
    "make_dir(rawimg_path)\n",
    "make_dir(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (os.path.isfile(\"images.tar.gz\") and tarfile.is_tarfile(\"images.tar.gz\")):\n",
    "    wget.download('https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz')\n",
    "tar = tarfile.open(\"images.tar.gz\")\n",
    "tar.extractall(path=rawimg_path)\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def checkImage(path):\n",
    "#     print(path)\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            data = f.read()\n",
    "            f.seek(-2,2)\n",
    "            value = f.read()\n",
    "\n",
    "        encoded_img = np.frombuffer(data, dtype = np.uint8)\n",
    "        img_cv = cv2.imdecode(encoded_img, cv2.IMREAD_COLOR)\n",
    "#         print(img_cv)\n",
    "        if img_cv.shape[0]>0 and value == b'\\xff\\xd9':\n",
    "            return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupt_img = ['Egyptian_Mau_14.jpg','Egyptian_Mau_139.jpg','Egyptian_Mau_145.jpg','Egyptian_Mau_156.jpg',\n",
    "               'Egyptian_Mau_167.jpg','Egyptian_Mau_177.jpg','Egyptian_Mau_186.jpg','Egyptian_Mau_191.jpg',\n",
    "               'Abyssinian_5.jpg','Abyssinian_34.jpg','chihuahua_121.jpg','beagle_116.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = os.path.join(rawimg_path, 'images')\n",
    "output_dir = os.path.join(rawimg_path, output_path)\n",
    "\n",
    "for file_path in glob.glob(file_dir + \"/*\"):\n",
    "    filename = file_path.split(\"/\")[2]\n",
    "    if checkImage(file_path) and filename not in corrupt_img:\n",
    "        dir_name = filename.split(\"_\")\n",
    "        dir_name.pop()\n",
    "        dir_name = \"_\".join(dir_name)\n",
    "        dir_path = os.path.join(output_dir, dir_name)\n",
    "        make_dir(dir_path, False)\n",
    "        target_path = os.path.join(dir_path, filename)\n",
    "        shutil.copyfile(file_path, target_path)\n",
    "    else:\n",
    "        print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num = 0\n",
    "# for file_path in glob.glob(output_dir + \"/*/*\"):\n",
    "# #     print(file_path)\n",
    "#     if not checkImage(file_path):\n",
    "# #         print(file_path)\n",
    "#         num += 1\n",
    "# print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "splitfolders.ratio(output_dir, output=dataset_path, seed=1337, ratio=(.8, .1, .1)) # default values\n",
    "s3_data_path = 's3://{}/{}'.format(data_bucket, 'oxford_pet_dataset')\n",
    "!aws s3 rm $s3_data_path --quiet --recursive\n",
    "!aws s3 cp ./dataset $s3_data_path --quiet --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Distributed Training\n",
    "\n",
    "AWS에서 Multigpu distributed training은 `data_parallel`와 `model_parallel` 를 모두 사용할 수 있으며, 아래 예제는 data_parallel 중심으로 학습을 하게 됩니다. \n",
    "\n",
    "<!-- \n",
    "이번에는 Pytorch에서 활용할 수 있는 [APEX](https://github.com/NVIDIA/apex) (A Pytorch EXtension) 패키지를 이용하여 Multigpu distributed training을 수행합니다. APEX 패키지에는 distributed training 기능과 함께 mixed precision training도 할 수 있도록 지원하고 있습니다. \n",
    "\n",
    "<!-- \n",
    "<p><img src=\"./imgs/apex.png\" width=\"1100\", height=\"150\"></p>  -->\n",
    "<!-- - mixed precision training (apex.amp) : FP16과 FP32연산을 mixed하여 처리 속도와 정확도를 동시에 잡기 위해 학습을 하는 방법입니다. Tensor Cores에서 FP16를 이용하면 compute 처리량은 8배, 메모리 처리량은 2배 증가하는 반면 메모리 저장은 50% 절감됩니다. (FP : Floating Point, AMP: Automatic Mixed Precision) -->\n",
    "\n",
    "- **[SageMaker Distributed Data Parallel](https://docs.aws.amazon.com/sagemaker/latest/dg/data-parallel.html)** : AWS의 네트워크 인프라와 Balanced Fusion Buffers 를 이용하여 AWS SageMaker에 최적화된 data parallel 분산학습 알고리즘을 제공합니다.\n",
    "\n",
    "- **[SageMaker Distributed Model Parallel](https://docs.aws.amazon.com/sagemaker/latest/dg/model-parallel.html)** : 각 GPU 또는 노드 간에 모델을 분할하고 GPU Utilization을 최대화하기 위해 모델을 학습하기 위한 효율적인 파이프 라인을 만든 후 mini-batch를 micro-batch를 분리하여 파이프 라인을 따라 Forward pass와 Backward pass를 동시에 수행할 수 있도록 제공하여 GPU의 Utilization을 최적화한 분산학습 알고리즘을 제공합니다. \n",
    "\n",
    "\n",
    "- **DataParallel (DP)** : 데이터 샘플의 미니 배치를 여러 개의 더 작은 미니 배치로 나누고 병렬로 작은 미니 배치를 각각 계산하는 방식이며, 단일 host에서 multi-gpu인 경우와 cpu 연산일 경우에 사용합니다. DP의 단점은 GPU가 즐어나면서 communication 비용이 높아지게 되면서 성능저하가 발생하게 되는데 일반적으로 4 gpu 이상일 경우 발생한다고 합니다. 또한, 타 GPU 메모리 대비 0번 GPU 메모리 사용량이 증가하는 현상도 발생합니다.  \n",
    "\n",
    "- **Distributed Data Parallel (DDP)** : 모듈 수준에서 데이터 병렬 처리를 구현하는 것으로 torch.distributed 패키지의 communication collectives를 사용하여 gradient, parameters, buffers를 동기화합니다. 프로세스 내와 프로세스 간을 사용하는 multi-host의 multi-gpu 와 같은 경우에 사용하게 되는데, 프로세스 내에서는 DDP는 input 모듈을 device_id에 특정한 device로 복제하고, 그에 따라 배치 크기로 input을 분산시키며, outputs는 DataParallel과 유사하게 output_device로 모으게 됩니다.  \n",
    "\n",
    "- **[APEX](https://nvidia.github.io/apex)** : apex.parallel.DistributedDataParallel는 모듈 wrapper이며, DDP와 유사합니다. 편리하게 Multi-process를 통한 distributed training을 지원하고, NCCL에 최적화하여 지원합니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 학습 스크립트 코딩하기\n",
    "\n",
    "<p>SageMaker에서 학습하는 것이 아니더라도 실제 모델 아키텍처와 학습을 위한 optimizer와 loss 함수 등을 정의하는 python 파일을 구성하게 됩니다. SageMaker에서 활용하는 python 파일도 동일한 python 파일을 사용하게 됩니다. 연계되는 다른 소스코드 파일이 있는 경우에도 별도 소스코드 수정 없이 학습이 가능하며, SageMaker에서 사용하기 위해서는 기존 python 파일에 SageMaker 학습에 사용할 수 있는 환경변수들만 추가하면 됩니다. 예를 들어, 환경변수 중 <code>SM_MODEL_DIR</code>은 컨테이너 환경에서는 <code>/opt/ml/model</code>를 의미합니다. 다양한 환경변수는 <strong><a href=\"https://github.com/aws/sagemaker-containers\" target=\"_blank\" class ='btn-default'>SageMaker Containers-IMPORTANT ENVIRONMENT VARIABLES</a></strong>를 참고하시기 바랍니다. </p><p>SageMaker 학습이 끝나면 자동은 컨테이너 환경은 삭제가 됩니다. 따라서, 학습이 완료된 모델 산출물과 다양한 output 파일은 S3로 저장해야 합니다. SageMaker는 자동으로 <code>SM_MODEL_DIR</code>에 저장된 최종 모델 파일을 학습이 끝난 다음 model.tar.gz로 압축하여 컨테이너 환경에서 S3의 특정 bucket에 저장하게 됩니다.</p><p> 별도 bucket을 설정하지 않으며, 기본적으로 생성되는 bucket에 저장됩니다. 이외 학습에 이용되는 python source code는 SageMaker 학습이 시작되면서 S3에 저장되며, 별도로 <code>SM_MODEL_DIR</code>에 checkpoint 또는 log 파일을 저장하게 되면 학습이 끝난 이후 자동으로 컨테이너 환경에서 S3로 저장된 파일들이 이동하게 됩니다. 이런 과정을 이해한다면 학습 시 저장되는 다양한 정보들을 저장한 다음 학습이 끝난 후 S3에서 download 받아 활용할 수 있습니다. </p>\n",
    "\n",
    "<p>아래는 시간 관계 상 미리 작성한 python 학습 스크립트 코드 입니다.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./src_dir/requirements.txt\n",
    "albumentations\n",
    "opencv-python\n",
    "pyarrow\n",
    "torchnet\n",
    "webdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%writefile ./src_dir/main_trainer.py\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "import cv2\n",
    "from typing import Callable, cast\n",
    "\n",
    "from albumentations import (\n",
    "    RandomResizedCrop, HorizontalFlip, ShiftScaleRotate, CLAHE,\n",
    "    RandomRotate90, Transpose, ShiftScaleRotate, Blur, OpticalDistortion,\n",
    "    GridDistortion, HueSaturationValue, GaussNoise,\n",
    "    MotionBlur, MedianBlur, RandomBrightnessContrast,\n",
    "    Sharpen, Emboss, Flip, OneOf, Compose, Resize, VerticalFlip,\n",
    "    HorizontalFlip, CenterCrop, Normalize)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchnet.dataset import SplitDataset\n",
    "# import webdataset as wds\n",
    "\n",
    "import dis_util\n",
    "import util\n",
    "\n",
    "# print(\"######### Start Training #########\")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "\n",
    "class AlbumentationImageDataset(Dataset):\n",
    "    def __init__(self, image_path, transform, args):\n",
    "        self.image_path = image_path\n",
    "        self.transform = transform\n",
    "        self.args = args\n",
    "        self.image_list = self._loader_file(self.image_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.image_list))\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "\n",
    "        image = cv2.imread(self.image_list[i][0])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Augment an image\n",
    "        transformed = self.transform(image=image)[\"image\"]\n",
    "        transformed_image = np.transpose(transformed,\n",
    "                                         (2, 0, 1)).astype(np.float32)\n",
    "        return torch.tensor(transformed_image,\n",
    "                            dtype=torch.float), self.image_list[i][1]\n",
    "\n",
    "    def _loader_file(self, image_path):\n",
    "        extensions = ('.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif',\n",
    "                      '.tiff', '.webp')\n",
    "\n",
    "        def is_valid_file(x: str) -> bool:\n",
    "            return x.lower().endswith(extensions)\n",
    "\n",
    "        is_valid_file = cast(Callable[[str], bool], is_valid_file)\n",
    "\n",
    "        self.classes = [d.name for d in os.scandir(image_path) if d.is_dir()]\n",
    "        self.classes.sort()\n",
    "        self.class_to_idx = {\n",
    "            cls_name: i\n",
    "            for i, cls_name in enumerate(self.classes)\n",
    "        }\n",
    "\n",
    "        instances = []\n",
    "        for target_class in sorted(self.class_to_idx.keys()):\n",
    "            class_index = self.class_to_idx[target_class]\n",
    "            target_dir = os.path.join(image_path, target_class)\n",
    "            if not os.path.isdir(target_dir):\n",
    "                continue\n",
    "            for root, _, fnames in sorted(os.walk(target_dir,\n",
    "                                                  followlinks=True)):\n",
    "                for fname in sorted(fnames):\n",
    "                    path = os.path.join(root, fname)\n",
    "\n",
    "                    if is_valid_file(path):\n",
    "                        item = path, class_index\n",
    "                        instances.append(item)\n",
    "        return instances\n",
    "\n",
    "\n",
    "def args_fn():\n",
    "    parser = argparse.ArgumentParser(description='PyTorch Resnet50 Example')\n",
    "\n",
    "    # Default Setting\n",
    "    parser.add_argument(\n",
    "        '--log-interval',\n",
    "        type=int,\n",
    "        default=5,\n",
    "        metavar='N',\n",
    "        help='how many batches to wait before logging training status')\n",
    "    parser.add_argument(\n",
    "        '--backend',\n",
    "        type=str,\n",
    "        default='nccl',\n",
    "        help=\n",
    "        'backend for distributed training (tcp, gloo on cpu and gloo, nccl on gpu)'\n",
    "    )\n",
    "    parser.add_argument('--channels-last', type=bool, default=True)\n",
    "    parser.add_argument('--seed',\n",
    "                        type=int,\n",
    "                        default=1,\n",
    "                        metavar='S',\n",
    "                        help='random seed (default: 1)')\n",
    "    parser.add_argument('-p',\n",
    "                        '--print-freq',\n",
    "                        default=10,\n",
    "                        type=int,\n",
    "                        metavar='N',\n",
    "                        help='print frequency (default: 10)')\n",
    "\n",
    "    # Hyperparameter Setting\n",
    "    parser.add_argument('--model_name', type=str, default='resnet50')\n",
    "    parser.add_argument('--height', type=int, default=224)\n",
    "    parser.add_argument('--width', type=int, default=224)\n",
    "    parser.add_argument('--lr', type=float, default=0.0001)\n",
    "    parser.add_argument('--num-classes', type=int, default=10)\n",
    "    parser.add_argument('--num-epochs', type=int, default=3)\n",
    "    parser.add_argument('--batch-size', type=int, default=64)\n",
    "    parser.add_argument('--test-batch-size',\n",
    "                        type=int,\n",
    "                        default=200,\n",
    "                        metavar='N',\n",
    "                        help='input batch size for testing (default: 200)')\n",
    "\n",
    "    # Setting for Distributed Training\n",
    "    parser.add_argument('--data_parallel', type=bool, default=False)\n",
    "    parser.add_argument('--model_parallel', type=bool, default=False)\n",
    "    parser.add_argument('--apex', type=bool, default=False)\n",
    "    parser.add_argument('--opt-level', type=str, default='O0')\n",
    "    parser.add_argument('--keep-batchnorm-fp32', type=str, default=None)\n",
    "    parser.add_argument('--loss-scale', type=str, default=None)\n",
    "    parser.add_argument('--sync_bn',\n",
    "                        action='store_true',\n",
    "                        help='enabling apex sync BN.')\n",
    "    parser.add_argument('--prof',\n",
    "                        default=-1,\n",
    "                        type=int,\n",
    "                        help='Only run 10 iterations for profiling.')\n",
    "\n",
    "    # Setting for Model Parallel\n",
    "    parser.add_argument(\"--horovod\", type=int, default=0)\n",
    "    parser.add_argument('--mp_parameters', type=str, default='')\n",
    "    parser.add_argument(\"--ddp\", type=int, default=0)\n",
    "    parser.add_argument(\"--amp\", type=int, default=0)\n",
    "    parser.add_argument(\"--save_full_model\", type=bool, default=True)\n",
    "    parser.add_argument(\"--pipeline\", type=str, default=\"interleaved\")\n",
    "    parser.add_argument(\"--assert-losses\", type=int, default=0)\n",
    "    parser.add_argument(\"--partial-checkpoint\",\n",
    "                        type=str,\n",
    "                        default=\"\",\n",
    "                        help=\"The checkpoint path to load\")\n",
    "    parser.add_argument(\"--full-checkpoint\",\n",
    "                        type=str,\n",
    "                        default=\"\",\n",
    "                        help=\"The checkpoint path to load\")\n",
    "    parser.add_argument(\"--save-full-model\",\n",
    "                        action=\"store_true\",\n",
    "                        default=False,\n",
    "                        help=\"For Saving the current Model\")\n",
    "    parser.add_argument(\n",
    "        \"--save-partial-model\",\n",
    "        action=\"store_true\",\n",
    "        default=False,\n",
    "        help=\"For Saving the current Model\",\n",
    "    )\n",
    "\n",
    "    # SageMaker Container environment\n",
    "    parser.add_argument('--hosts',\n",
    "                        type=list,\n",
    "                        default=json.loads(os.environ['SM_HOSTS']))\n",
    "    parser.add_argument('--current-host',\n",
    "                        type=str,\n",
    "                        default=os.environ['SM_CURRENT_HOST'])\n",
    "    parser.add_argument('--model-dir',\n",
    "                        type=str,\n",
    "                        default=os.environ['SM_MODEL_DIR'])\n",
    "    parser.add_argument('--data-dir',\n",
    "                        type=str,\n",
    "                        default=os.environ['SM_CHANNEL_TRAINING'])\n",
    "    parser.add_argument('--num-gpus',\n",
    "                        type=int,\n",
    "                        default=os.environ['SM_NUM_GPUS'])\n",
    "    parser.add_argument('--output_data_dir',\n",
    "                        type=str,\n",
    "                        default=os.environ['SM_OUTPUT_DATA_DIR'])\n",
    "    parser.add_argument('--rank', type=int, default=0)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "def _get_train_data_loader(args, **kwargs):\n",
    "\n",
    "    transform = Compose([\n",
    "        RandomResizedCrop(args.height, args.width),\n",
    "        GaussNoise(p=0.2),\n",
    "        VerticalFlip(p=0.5),\n",
    "        OneOf([\n",
    "            MotionBlur(p=.2),\n",
    "            MedianBlur(blur_limit=3, p=0.1),\n",
    "            Blur(blur_limit=3, p=0.1),\n",
    "        ],\n",
    "              p=0.2),\n",
    "        OneOf([\n",
    "            CLAHE(clip_limit=2),\n",
    "            Sharpen(),\n",
    "            Emboss(),\n",
    "            RandomBrightnessContrast(),\n",
    "        ],\n",
    "              p=0.3),\n",
    "        HueSaturationValue(p=0.3),\n",
    "        Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "        )\n",
    "    ],\n",
    "                        p=1.0)\n",
    "\n",
    "    train_sampler = None\n",
    "    train_dataloader = None\n",
    "\n",
    "    dataset = AlbumentationImageDataset(image_path=os.path.join(\n",
    "        args.data_dir, 'train'),\n",
    "                                        transform=transform,\n",
    "                                        args=args)\n",
    "\n",
    "    drop_last = args.model_parallel\n",
    "\n",
    "    train_sampler = data.distributed.DistributedSampler(\n",
    "        dataset, num_replicas=int(args.world_size), rank=int(\n",
    "            args.rank)) if args.multigpus_distributed else None\n",
    "    train_dataloader = data.DataLoader(dataset,\n",
    "                                       batch_size=args.batch_size,\n",
    "                                       shuffle=train_sampler is None,\n",
    "                                       sampler=train_sampler,\n",
    "                                       drop_last=drop_last,\n",
    "                                       **kwargs)\n",
    "    return train_dataloader, train_sampler\n",
    "\n",
    "\n",
    "def _get_test_data_loader(args, **kwargs):\n",
    "    logger.info(\"Get test data loader\")\n",
    "    transform = Compose([\n",
    "        Resize(args.height, args.width),\n",
    "        Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    image_path = os.path.join(args.data_dir, 'val')\n",
    "    dataset = AlbumentationImageDataset(image_path=image_path,\n",
    "                                        transform=transform,\n",
    "                                        args=args)\n",
    "\n",
    "    drop_last = args.model_parallel\n",
    "    print(\"test drop_last : {}\".format(drop_last))\n",
    "    test_sampler = data.distributed.DistributedSampler(\n",
    "        dataset, num_replicas=int(args.world_size), rank=int(\n",
    "            args.rank)) if args.multigpus_distributed else None\n",
    "\n",
    "    return data.DataLoader(dataset,\n",
    "                           batch_size=args.test_batch_size,\n",
    "                           shuffle=False,\n",
    "                           sampler=test_sampler,\n",
    "                           drop_last=drop_last)\n",
    "\n",
    "\n",
    "def train(local_rank, args):\n",
    "    best_acc1 = -1\n",
    "    model_history = {}\n",
    "    model_history = util.init_modelhistory(model_history)\n",
    "    train_start = time.time()\n",
    "\n",
    "    if local_rank is not None:\n",
    "        args.local_rank = local_rank\n",
    "\n",
    "    # distributed_setting\n",
    "    if args.multigpus_distributed:\n",
    "        args = dis_util.dist_setting(args)\n",
    "\n",
    "    # choose model from pytorch model_zoo\n",
    "    model = util.torch_model(\n",
    "        args.model_name,\n",
    "        num_classes=args.num_classes,\n",
    "        pretrained=True,\n",
    "        local_rank=args.local_rank,\n",
    "        model_parallel=args.model_parallel)  # 1000 resnext101_32x8d\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "    model, args = dis_util.dist_model(model, args)\n",
    "\n",
    "    # CuDNN library will benchmark several algorithms and pick that which it found to be fastest\n",
    "    cudnn.benchmark = False if args.seed else True\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "    if args.apex:\n",
    "        model, optimizer, args = dis_util.apex_init(model, optimizer, args)\n",
    "    elif args.model_parallel:\n",
    "        model, optimizer, args = dis_util.smp_init(model, optimizer, args)\n",
    "    elif args.data_parallel:\n",
    "        model, optimizer, args = dis_util.sdp_init(model, optimizer, args)\n",
    "\n",
    "    train_loader, train_sampler = _get_train_data_loader(args, **args.kwargs)\n",
    "\n",
    "    logger.info(\"Processes {}/{} ({:.0f}%) of train data\".format(\n",
    "        len(train_loader.sampler), len(train_loader.dataset),\n",
    "        100. * len(train_loader.sampler) / len(train_loader.dataset)))\n",
    "\n",
    "    test_loader = _get_test_data_loader(args, **args.kwargs)\n",
    "\n",
    "    #     if args.rank == 0:\n",
    "    logger.info(\"Processes {}/{} ({:.0f}%) of test data\".format(\n",
    "        len(test_loader.sampler), len(test_loader.dataset),\n",
    "        100. * len(test_loader.sampler) / len(test_loader.dataset)))\n",
    "\n",
    "    print(\" local_rank : {}, local_batch_size : {}\".format(\n",
    "        args.local_rank, args.batch_size))\n",
    "\n",
    "    for epoch in range(1, args.num_epochs + 1):\n",
    "        ##\n",
    "        batch_time = util.AverageMeter('Time', ':6.3f')\n",
    "        data_time = util.AverageMeter('Data', ':6.3f')\n",
    "        losses = util.AverageMeter('Loss', ':.4e')\n",
    "        top1 = util.AverageMeter('Acc@1', ':6.2f')\n",
    "        top5 = util.AverageMeter('Acc@5', ':6.2f')\n",
    "        progress = util.ProgressMeter(\n",
    "            len(train_loader), [batch_time, data_time, losses, top1, top5],\n",
    "            prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "        model.train()\n",
    "        end = time.time()\n",
    "\n",
    "        # Set epoch count for DistributedSampler\n",
    "        if args.multigpus_distributed and not args.model_parallel:\n",
    "            train_sampler.set_epoch(epoch)\n",
    "\n",
    "        for batch_idx, (input, target) in enumerate(train_loader):\n",
    "            input = input.to(args.device)\n",
    "            target = target.to(args.device)\n",
    "            batch_idx += 1\n",
    "\n",
    "            if args.model_parallel:\n",
    "                output, loss = dis_util.train_step(model, criterion, input,\n",
    "                                                   target, args.scaler, args)\n",
    "                # Rubik: Average the loss across microbatches.\n",
    "                loss = loss.reduce_mean()\n",
    "\n",
    "            else:\n",
    "                output = model(input)\n",
    "                loss = criterion(output, target)\n",
    "\n",
    "#             if not args.model_parallel:\n",
    "#                 # compute gradient and do SGD step\n",
    "#                 optimizer.zero_grad()\n",
    "\n",
    "            if args.apex:\n",
    "                dis_util.apex_loss(loss, optimizer)\n",
    "            elif not args.model_parallel:\n",
    "                loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            if args.model_parallel:\n",
    "                # compute gradient and do SGD step\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            if args.rank == 0:\n",
    "                #             if args.rank == 0 and batch_idx % args.log_interval == 1:\n",
    "                # Every print_freq iterations, check the loss, accuracy, and speed.\n",
    "                # For best performance, it doesn't make sense to print these metrics every\n",
    "                # iteration, since they incur an allreduce and some host<->device syncs.\n",
    "\n",
    "                if args.model_parallel:\n",
    "                    output = torch.cat(output.outputs)\n",
    "\n",
    "                # Measure accuracy\n",
    "                prec1, prec5 = util.accuracy(output, target, topk=(1, 5))\n",
    "\n",
    "                # to_python_float incurs a host<->device sync\n",
    "                losses.update(util.to_python_float(loss), input.size(0))\n",
    "                top1.update(util.to_python_float(prec1), input.size(0))\n",
    "                top5.update(util.to_python_float(prec5), input.size(0))\n",
    "\n",
    "                # Waiting until finishing operations on GPU (Pytorch default: async)\n",
    "                torch.cuda.synchronize()\n",
    "                batch_time.update((time.time() - end) / args.log_interval)\n",
    "                end = time.time()\n",
    "\n",
    "                #                 if args.rank == 0:\n",
    "                print(\n",
    "                    'Epoch: [{0}][{1}/{2}] '\n",
    "                    'Train_Time={batch_time.val:.3f}: avg-{batch_time.avg:.3f}, '\n",
    "                    'Train_Speed={3:.3f} ({4:.3f}), '\n",
    "                    'Train_Loss={loss.val:.10f}:({loss.avg:.4f}), '\n",
    "                    'Train_Prec@1={top1.val:.3f}:({top1.avg:.3f}), '\n",
    "                    'Train_Prec@5={top5.val:.3f}:({top5.avg:.3f})'.format(\n",
    "                        epoch,\n",
    "                        batch_idx,\n",
    "                        len(train_loader),\n",
    "                        args.world_size * args.batch_size / batch_time.val,\n",
    "                        args.world_size * args.batch_size / batch_time.avg,\n",
    "                        batch_time=batch_time,\n",
    "                        loss=losses,\n",
    "                        top1=top1,\n",
    "                        top5=top5))\n",
    "\n",
    "        acc1 = validate(test_loader, model, criterion, epoch, model_history,\n",
    "                        args)\n",
    "\n",
    "        is_best = False\n",
    "\n",
    "        if args.rank == 0:\n",
    "            is_best = acc1 > best_acc1\n",
    "            best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "        if not args.multigpus_distributed or (args.multigpus_distributed\n",
    "                                              and not args.model_parallel\n",
    "                                              and args.rank == 0):\n",
    "            model_history['epoch'].append(epoch)\n",
    "            model_history['batch_idx'].append(batch_idx)\n",
    "            model_history['batch_time'].append(batch_time.val)\n",
    "            model_history['losses'].append(losses.val)\n",
    "            model_history['top1'].append(top1.val)\n",
    "            model_history['top5'].append(top5.val)\n",
    "\n",
    "            util.save_history(\n",
    "                os.path.join(args.output_data_dir, 'model_history.p'),\n",
    "                model_history)\n",
    "            util.save_model(\n",
    "                {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'model_name': args.model_name,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'best_acc1': best_acc1,\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'class_to_idx': train_loader.dataset.class_to_idx,\n",
    "                }, is_best, args)\n",
    "        elif args.model_parallel:\n",
    "            if args.rank == 0:\n",
    "                util.save_history(\n",
    "                    os.path.join(args.output_data_dir, 'model_history.p'),\n",
    "                    model_history)\n",
    "            dis_util.smp_savemodel(model, optimizer, is_best, args)\n",
    "            \n",
    "    if args.model_parallel:\n",
    "        dis_util.smp_barrier()\n",
    "\n",
    "    if args.data_parallel:\n",
    "        dis_util.sdp_barrier(args)\n",
    "\n",
    "    return 1\n",
    "        \n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion, epoch, model_history, args):\n",
    "    batch_time = util.AverageMeter('Time', ':6.3f')\n",
    "    losses = util.AverageMeter('Loss', ':.4e')\n",
    "    top1 = util.AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = util.AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = util.ProgressMeter(len(val_loader),\n",
    "                                  [batch_time, losses, top1, top5],\n",
    "                                  prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    end = time.time()\n",
    "\n",
    "    #     print(\"**** validate *****\")\n",
    "    test_losses = []\n",
    "    for batch_idx, (input, target) in enumerate((val_loader)):\n",
    "        input = input.to(args.device)\n",
    "        target = target.to(args.device)\n",
    "\n",
    "        batch_idx += 1\n",
    "        # compute output\n",
    "        with torch.no_grad():\n",
    "            if args.model_parallel:\n",
    "                output, loss = dis_util.test_step(model, criterion, input,\n",
    "                                                  target)\n",
    "                loss = loss.reduce_mean()\n",
    "                test_losses.append(loss)\n",
    "            else:\n",
    "                output = model(input)\n",
    "                loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        if args.model_parallel:\n",
    "            output = torch.cat(output.outputs)\n",
    "\n",
    "        prec1, prec5 = util.accuracy(output, target, topk=(1, 5))\n",
    "\n",
    "        losses.update(util.to_python_float(loss), input.size(0))\n",
    "        top1.update(util.to_python_float(prec1), input.size(0))\n",
    "        top5.update(util.to_python_float(prec5), input.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        #         print(\"Validation args.rank : {}\".format(args.rank))\n",
    "        # TODO:  Change timings to mirror train().\n",
    "        if args.rank == 0:\n",
    "            print('Test: [{0}/{1}]  '\n",
    "                  'Test_Time={batch_time.val:.3f}:({batch_time.avg:.3f}), '\n",
    "                  'Test_Speed={2:.3f}:({3:.3f}), '\n",
    "                  'Test_Loss={loss.val:.4f}:({loss.avg:.4f}), '\n",
    "                  'Test_Prec@1={top1.val:.3f}:({top1.avg:.3f}), '\n",
    "                  'Test_Prec@5={top5.val:.3f}:({top5.avg:.3f})'.format(\n",
    "                      batch_idx,\n",
    "                      len(val_loader),\n",
    "                      args.world_size * args.batch_size / batch_time.val,\n",
    "                      args.world_size * args.batch_size / batch_time.avg,\n",
    "                      batch_time=batch_time,\n",
    "                      loss=losses,\n",
    "                      top1=top1,\n",
    "                      top5=top5))\n",
    "            model_history['val_epoch'].append(epoch)\n",
    "            model_history['val_batch_idx'].append(batch_idx)\n",
    "            model_history['val_batch_time'].append(batch_time.val)\n",
    "            model_history['val_losses'].append(losses.val)\n",
    "            model_history['val_top1'].append(top1.val)\n",
    "            model_history['val_top5'].append(top5.val)\n",
    "\n",
    "    model_history['val_avg_epoch'].append(epoch)\n",
    "    model_history['val_avg_batch_time'].append(batch_time.avg)\n",
    "    model_history['val_avg_losses'].append(losses.avg)\n",
    "    model_history['val_avg_top1'].append(top1.avg)\n",
    "    model_history['val_avg_top5'].append(top5.avg)\n",
    "\n",
    "    if args.model_parallel:\n",
    "        if args.assert_losses:\n",
    "            dis_util.smp_lossgather(losses.avg, args)\n",
    "        dis_util.smp_barrier()\n",
    "        \n",
    "    return top1.avg\n",
    "\n",
    "def main():\n",
    "    print(\"start main function\")\n",
    "    args = args_fn()\n",
    "    args.exp_cnt = 0\n",
    "    print(\n",
    "        \"args.data_parallel : {} , args.model_parallel : {}, args.apex : {} , args.num_gpus : {}, args.num_classes\"\n",
    "        .format(args.data_parallel, args.model_parallel, args.apex,\n",
    "                args.num_gpus, args.num_classes))\n",
    "\n",
    "    args.use_cuda = int(args.num_gpus) > 0\n",
    "    \n",
    "#     os.environ['PYTHONWARNINGS'] = 'ignore:semaphore_tracker:UserWarning'\n",
    "\n",
    "    args.kwargs = {\n",
    "        'num_workers': 16,\n",
    "        'pin_memory': True\n",
    "    } if args.use_cuda else {}\n",
    "    args.device = torch.device(\"cuda\" if args.use_cuda else \"cpu\")\n",
    "    if args.exp_cnt == 0:\n",
    "        args = dis_util.dist_init(train, args)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 분산/멀티 gpu에 필요한 code 작성\n",
    "\n",
    "apex사용과 분산을 위한 init 함수와 분산관련 다양한 함수를 제공합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./src_dir/dis_util.py\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import shutil\n",
    "import warnings\n",
    "import importlib\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data.distributed\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "import util\n",
    "\n",
    "try:\n",
    "    import smdistributed.modelparallel.torch as smp\n",
    "    \n",
    "except ImportError:\n",
    "    pass\n",
    "#     raise ImportError(\"Please install smdist.\")\n",
    "\n",
    "\n",
    "try:\n",
    "    from apex.parallel import DistributedDataParallel as apexDDP\n",
    "    import torch.distributed as apex\n",
    "    from apex.fp16_utils import *\n",
    "    from apex import amp, optimizers\n",
    "    from apex.multi_tensor_apply import multi_tensor_applier\n",
    "except ImportError:\n",
    "    raise ImportError(\n",
    "        \"Please install apex from https://www.github.com/nvidia/apex to run this example.\"\n",
    "    )\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "\n",
    "def _sdp_import(args):\n",
    "    # Remove the import of smdistributed.dataparallel as\n",
    "    # that causes the MPI init/shutdown error at exit time\n",
    "\n",
    "    try:\n",
    "        sdp = importlib.import_module(\"smdistributed.dataparallel.torch.distributed\")\n",
    "        DDP = importlib.import_module(\"smdistributed.dataparallel.torch.parallel.distributed\",\"DistributedDataParallel\")\n",
    "#         import smdistributed.dataparallel.torch.distributed as sdp\n",
    "#         from smdistributed.dataparallel.torch.parallel.distributed import DistributedDataParallel as DDP\n",
    "        return sdp, DDP\n",
    "\n",
    "    except ImportError:\n",
    "        pass\n",
    "    #     raise ImportError(\"Please install smdist.\")\n",
    "    \n",
    "    \n",
    "    \n",
    "def dist_init(fn, args):\n",
    "    \n",
    "    if args.seed is not None:\n",
    "        random.seed(args.seed)\n",
    "        torch.manual_seed(args.seed)\n",
    "        np.random.seed(args.seed)\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "        cudnn.deterministic = True\n",
    "\n",
    "        if cudnn.deterministic:\n",
    "            warnings.warn('You have chosen to seed training. '\n",
    "                          'This will turn on the CUDNN deterministic setting, '\n",
    "                          'which can slow down your training considerably! '\n",
    "                          'You may see unexpected behavior when restarting '\n",
    "                          'from checkpoints.')\n",
    "\n",
    "    args.is_distributed = len(args.hosts) > 1 and args.backend is not None\n",
    "    args.is_multigpus = args.num_gpus > 1\n",
    "    args.multigpus_distributed = (args.is_distributed or args.is_multigpus)\n",
    "\n",
    "    logger.debug(\"multigpus_distributed - {}\".format(\n",
    "        args.multigpus_distributed))\n",
    "    logger.debug(\"Number of gpus available - {}\".format(args.num_gpus))\n",
    "\n",
    "    if args.multigpus_distributed and args.exp_cnt == 0:\n",
    "        if args.apex:\n",
    "            # Initialize the distributed environment.\n",
    "            mp.spawn(fn, nprocs=args.num_gpus, args=(args, ))\n",
    "        else:\n",
    "            if args.data_parallel:\n",
    "                sdp, DDP = _sdp_import(args)\n",
    "                sdp.init_process_group() if not sdp.is_initialized() else None    \n",
    "            elif args.model_parallel:\n",
    "                smp.init()\n",
    "            args.exp_cnt = fn(None, args)\n",
    "            \n",
    "            \n",
    "    else:\n",
    "        args.exp_cnt = fn(0, args)\n",
    "    return args\n",
    "\n",
    "\n",
    "def dist_setting(args):\n",
    "    #     args.data_parallel = False\n",
    "    print(f\"args.data_parallel : {args.data_parallel}, args.model_parallel : {args.model_parallel}, args.apex : {args.apex}\")\n",
    "\n",
    "\n",
    "    args.world_size = 1\n",
    "    args.host_num = args.hosts.index(args.current_host)\n",
    "\n",
    "    if args.data_parallel:\n",
    "        sdp, DDP = _sdp_import(args)\n",
    "        \n",
    "        args.world_size = sdp.get_world_size()\n",
    "        args.rank = sdp.get_rank()  # total rank in all hosts\n",
    "        args.local_rank = sdp.get_local_rank()  # rank per host\n",
    "    elif args.model_parallel:\n",
    "        args.world_size = smp.size()\n",
    "        args.world_size = args.num_gpus * len(args.hosts)\n",
    "        args.local_rank = smp.local_rank()  # rank per host\n",
    "        args.rank = smp.rank()\n",
    "        args.dp_size = smp.dp_size()\n",
    "        args.dp_rank = smp.dp_rank()\n",
    "    else:\n",
    "        args.world_size = len(args.hosts) * args.num_gpus\n",
    "        if args.local_rank is not None:\n",
    "            args.rank = args.num_gpus * args.host_num + \\\n",
    "                args.local_rank  # total rank in all hosts\n",
    "\n",
    "        dist.init_process_group(backend=args.backend,\n",
    "                                rank=args.rank,\n",
    "                                world_size=args.world_size)\n",
    "        logger.info(\n",
    "            'Initialized the distributed environment: \\'{}\\' backend on {} nodes. '\n",
    "            .format(args.backend, dist.get_world_size()) +\n",
    "            'Current host rank is {}. Number of gpus: {}'.format(\n",
    "                dist.get_rank(), args.num_gpus))\n",
    "    \n",
    "#     if not args.model_parallel:\n",
    "    args.lr = args.lr * float(args.world_size)\n",
    "    args.batch_size //= args.world_size // args.num_gpus\n",
    "    args.batch_size = max(args.batch_size, 1)\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "def dist_model(model, args):\n",
    "    if args.multigpus_distributed:\n",
    "        #     if args.sync_bn:\n",
    "        # #         import apex\n",
    "        #         print(\"using apex synced BN\")\n",
    "        #         model = apex.parallel.convert_syncbn_model(model)\n",
    "\n",
    "        if args.local_rank is not None:\n",
    "            torch.cuda.set_device(args.local_rank)\n",
    "\n",
    "            if not (args.apex or args.data_parallel or args.model_parallel):\n",
    "                model.cuda(args.local_rank)\n",
    "                model = torch.nn.parallel.DistributedDataParallel(\n",
    "                    model, device_ids=[args.rank])\n",
    "        else:\n",
    "            if not (args.apex or args.data_parallel or args.model_parallel):\n",
    "                model.cuda()\n",
    "                model = torch.nn.parallel.DistributedDataParallel(model)\n",
    "    elif args.rank is not None:\n",
    "        torch.cuda.set_device(args.rank)\n",
    "        if not (args.apex or args.data_parallel or args.model_parallel):\n",
    "            model = model.cuda(args.rank)\n",
    "    else:\n",
    "        if not (args.apex or args.data_parallel or args.model_parallel):\n",
    "            model = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "    return model, args\n",
    "\n",
    "\n",
    "def apex_init(model, optimizer, args):    \n",
    "    model = model.cuda()\n",
    "    model, optimizer = amp.initialize(\n",
    "        model,\n",
    "        optimizer,\n",
    "        opt_level=args.opt_level,\n",
    "        keep_batchnorm_fp32=args.keep_batchnorm_fp32,\n",
    "        loss_scale=args.loss_scale)\n",
    "    if args.multigpus_distributed:\n",
    "        model = apexDDP(model, delay_allreduce=True)\n",
    "    return model, optimizer, args\n",
    "\n",
    "\n",
    "def sdp_init(model, optimizer, args):\n",
    "    sdp, DDP = _sdp_import(args)\n",
    "    \n",
    "    model = DDP.DistributedDataParallel(model.to(args.device), broadcast_buffers=False)\n",
    "    #     model = DDP(model, device_ids=[args.rank], broadcast_buffers=False)\n",
    "    model.cuda(args.local_rank)\n",
    "    return model, optimizer, args\n",
    "\n",
    "\n",
    "def smp_init(model, optimizer, args):\n",
    "    model = smp.DistributedModel(model)\n",
    "    args.scaler = smp.amp.GradScaler()\n",
    "    optimizer = smp.DistributedOptimizer(optimizer)\n",
    "    if args.partial_checkpoint:\n",
    "        args.checkpoint = smp.load(args.partial_checkpoint, partial=True)\n",
    "        model.load_state_dict(args.checkpoint[\"model_state_dict\"])\n",
    "        optimizer.load_state_dict(args.checkpoint[\"optimizer_state_dict\"])\n",
    "    elif args.full_checkpoint:\n",
    "        args.checkpoint = smp.load(args.full_checkpoint, partial=False)\n",
    "        model.load_state_dict(args.checkpoint[\"model_state_dict\"])\n",
    "        optimizer.load_state_dict(args.checkpoint[\"optimizer_state_dict\"])\n",
    "\n",
    "    return model, optimizer, args\n",
    "\n",
    "\n",
    "def apex_loss(loss, optimizer):\n",
    "    with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "        scaled_loss.backward()\n",
    "\n",
    "\n",
    "def reduce_tensor(tensor, args):\n",
    "    rt = tensor.clone()\n",
    "    print(\"rt : {}\".format(rt))\n",
    "    sdp.all_reduce(rt)\n",
    "    print(\"args.world_size : {}\".format(args.world_size))\n",
    "    rt /= args.world_size\n",
    "    return rt\n",
    "\n",
    "\n",
    "def smp_lossgather(loss, args):\n",
    "    if args.use_horovod or args.use_ddp:\n",
    "        # Rubik: If using data parallelism, gather all losses across different model\n",
    "        # replicas and check if losses match.\n",
    "\n",
    "        losses = smp.allgather(loss, smp.DP_GROUP)\n",
    "        for l in losses:\n",
    "            assert math.isclose(l, losses[0])\n",
    "\n",
    "        assert loss < 0.14\n",
    "    else:\n",
    "        assert loss < 0.08\n",
    "\n",
    "\n",
    "def smp_savemodel(model, optimizer, is_best, args):\n",
    "    filepath = '/opt/ml/local_checkpoints'\n",
    "    filename = os.path.join(filepath, 'smp_full_checkpoint.pt')\n",
    "\n",
    "    if args.rank == 0:\n",
    "        if os.path.exists(filepath):\n",
    "            print(\"-INFO- PATH DO EXIST\")\n",
    "        else:\n",
    "            os.makedirs(filepath)\n",
    "            print(\"-INFO- PATH DO NOT EXIST\")\n",
    "    smp.barrier()\n",
    "\n",
    "\n",
    "    if args.dp_rank == 0:\n",
    "        if args.save_full_model:\n",
    "            model_dict = model.state_dict()\n",
    "            opt_dict = optimizer.state_dict()\n",
    "            smp.save(\n",
    "                {\n",
    "                    \"model_state_dict\": model_dict,\n",
    "                    \"optimizer_state_dict\": opt_dict\n",
    "                },\n",
    "                filename,\n",
    "                partial=False,\n",
    "            )\n",
    "        else:\n",
    "            model_dict = model.local_state_dict()\n",
    "            opt_dict = optimizer.local_state_dict()\n",
    "            smp.save(\n",
    "                {\n",
    "                    \"model_state_dict\": model_dict,\n",
    "                    \"optimizer_state_dict\": opt_dict\n",
    "                },\n",
    "                filename,\n",
    "                partial=True,\n",
    "            )\n",
    "    smp.barrier()\n",
    "\n",
    "    if args.rank == 0:\n",
    "        print(\"Start syncing\")\n",
    "        base_s3_path = os.path.dirname(\n",
    "            os.path.dirname(os.getenv('SM_MODULE_DIR', '')))\n",
    "        curr_host = os.getenv('SM_CURRENT_HOST')\n",
    "        full_s3_path = f'{base_s3_path}/checkpoints/{curr_host}/'\n",
    "        util.sync_local_checkpoints_to_s3(local_path=filepath,\n",
    "                                          s3_path=full_s3_path)\n",
    "        print(\"Finished syncing\")\n",
    "\n",
    "        print(\"is_best : {}\".format(is_best))\n",
    "        if is_best:\n",
    "            shutil.copyfile(filename,\n",
    "                            os.path.join(args.model_dir, 'model_best.pth'))\n",
    "    smp.barrier()\n",
    "\n",
    "\n",
    "def smp_barrier():\n",
    "    smp.barrier()\n",
    "\n",
    "def sdp_barrier(args):\n",
    "    sdp, DDP = _sdp_import(args)\n",
    "    sdp.barrier()\n",
    "    \n",
    "try:\n",
    "    # Rubik: Define smp.step. Return any tensors needed outside.\n",
    "    @smp.step\n",
    "    def train_step(model, criterion, input, target, scaler, args):        \n",
    "        with autocast(1 > 0):\n",
    "            output = model(input)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "        loss = loss.mean()\n",
    "\n",
    "        # scaled_loss = scaler.scale(loss) if args.amp else loss\n",
    "        model.backward(loss)\n",
    "        return output, loss\n",
    "\n",
    "    # Rubik: Define smp.step for evaluation.\n",
    "    @smp.step\n",
    "    def test_step(model, criterion, input, target):\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "        loss = loss.mean()\n",
    "        return output, loss\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) 모델 학습에 공통적으로 사용할 수 있는 util 코드 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%writefile ./src_dir/util.py\n",
    "\n",
    "import codecs\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data.distributed\n",
    "from torchvision import models\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "try:\n",
    "    import dis_util\n",
    "except ImportError:\n",
    "    pass\n",
    "# import sagemaker_containers\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "\n",
    "def torch_model(model_name,\n",
    "                num_classes=0,\n",
    "                pretrained=True,\n",
    "                local_rank=0,\n",
    "                model_parallel=False):\n",
    "    #     model_names = sorted(name for name in models.__dict__\n",
    "    #                          if name.islower() and not name.startswith(\"__\")\n",
    "    #                          and callable(models.__dict__[name]))\n",
    "\n",
    "    if (model_name == \"inception_v3\"):\n",
    "        raise RuntimeError(\n",
    "            \"Currently, inception_v3 is not supported by this example.\")\n",
    "\n",
    "    # create model\n",
    "    if pretrained:\n",
    "        print(\"=> using pre-trained model '{}'\".format(model_name))\n",
    "        if model_parallel:\n",
    "            if local_rank == 0:\n",
    "                model = models.__dict__[model_name](pretrained=True)\n",
    "            dis_util.smp_barrier()\n",
    "        model = models.__dict__[model_name](pretrained=True)\n",
    "    else:\n",
    "        print(\"=> creating model '{}'\".format(model_name))\n",
    "        model = models.__dict__[model_name]()\n",
    "\n",
    "    if num_classes > 0:\n",
    "        n_inputs = model.fc.in_features\n",
    "\n",
    "        # add more layers as required\n",
    "        classifier = nn.Sequential(\n",
    "            OrderedDict([('fc_output', nn.Linear(n_inputs, num_classes))]))\n",
    "\n",
    "        model.fc = classifier\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1, )):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred)).contiguous()\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n",
    "\n",
    "\n",
    "def save_model(state, is_best, args):\n",
    "    logger.info(\"Saving the model.\")\n",
    "    filename = os.path.join(args.model_dir, 'checkpoint.pth')\n",
    "    # recommended way from http://pytorch.org/docs/master/notes/serialization.html\n",
    "    torch.save(state, filename, _use_new_zipfile_serialization=False)\n",
    "\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, os.path.join(args.model_dir,\n",
    "                                               'model_best.pth'))\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, step, len_epoch, args):\n",
    "    factor = epoch // 30\n",
    "\n",
    "    if epoch >= 80:\n",
    "        factor = factor + 1\n",
    "\n",
    "    lr = args.lr * (0.1**factor)\n",
    "    \n",
    "    # Warmup\n",
    "    if epoch < 5:\n",
    "        lr = lr * float(1 + step + epoch * len_epoch) / (5. * len_epoch)\n",
    "\n",
    "    if args.rank == 0:\n",
    "        print(\"epoch = {}, step = {}, lr = {}\".format(epoch, step, lr))\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def save_history(path, history):\n",
    "\n",
    "    history_for_json = {}\n",
    "    # transform float values that aren't json-serializable\n",
    "    for key in history.keys():\n",
    "        history_for_json[key] = list(map(float, history[key]))\n",
    "\n",
    "    with codecs.open(path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(history_for_json,\n",
    "                  f,\n",
    "                  separators=(',', ':'),\n",
    "                  sort_keys=True,\n",
    "                  indent=4)\n",
    "\n",
    "\n",
    "def to_python_float(t):\n",
    "    if hasattr(t, 'item'):\n",
    "        return t.item()\n",
    "    elif hasattr(t, 'index'):\n",
    "        return t[0]\n",
    "    else:\n",
    "        return t\n",
    "\n",
    "\n",
    "def init_modelhistory(model_history):\n",
    "    model_history['epoch'] = []\n",
    "    model_history['batch_idx'] = []\n",
    "    model_history['batch_time'] = []\n",
    "    model_history['losses'] = []\n",
    "    model_history['top1'] = []\n",
    "    model_history['top5'] = []\n",
    "    model_history['val_epoch'] = []\n",
    "    model_history['val_batch_idx'] = []\n",
    "    model_history['val_batch_time'] = []\n",
    "    model_history['val_losses'] = []\n",
    "    model_history['val_top1'] = []\n",
    "    model_history['val_top5'] = []\n",
    "    model_history['val_avg_epoch'] = []\n",
    "    model_history['val_avg_batch_time'] = []\n",
    "    model_history['val_avg_losses'] = []\n",
    "    model_history['val_avg_top1'] = []\n",
    "    model_history['val_avg_top5'] = []\n",
    "    return model_history\n",
    "\n",
    "\n",
    "def aws_s3_sync(source, destination):\n",
    "    \"\"\"aws s3 sync in quiet mode and time profile\"\"\"\n",
    "    import time, subprocess\n",
    "    cmd = [\"aws\", \"s3\", \"sync\", \"--quiet\", source, destination]\n",
    "    print(f\"Syncing files from {source} to {destination}\")\n",
    "    start_time = time.time()\n",
    "    p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    p.wait()\n",
    "    end_time = time.time()\n",
    "    print(\"Time Taken to Sync: \", (end_time - start_time))\n",
    "    return\n",
    "\n",
    "\n",
    "def sync_local_checkpoints_to_s3(\n",
    "    local_path=\"/opt/ml/checkpoints\",\n",
    "    s3_path=os.path.dirname(os.path.dirname(os.getenv('SM_MODULE_DIR', ''))) +\n",
    "    '/checkpoints'):\n",
    "    \"\"\" sample function to sync checkpoints from local path to s3 \"\"\"\n",
    "\n",
    "    import boto3, botocore\n",
    "    #check if local path exists\n",
    "    if not os.path.exists(local_path):\n",
    "        raise RuntimeError(\n",
    "            \"Provided local path {local_path} does not exist. Please check\")\n",
    "\n",
    "    #check if s3 bucket exists\n",
    "    s3 = boto3.resource('s3')\n",
    "    if 's3://' not in s3_path:\n",
    "        raise ValueError(\n",
    "            \"Provided s3 path {s3_path} is not valid. Please check\")\n",
    "\n",
    "    s3_bucket = s3_path.replace('s3://', '').split('/')[0]\n",
    "    print(f\"S3 Bucket: {s3_bucket}\")\n",
    "    try:\n",
    "        s3.meta.client.head_bucket(Bucket=s3_bucket)\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        error_code = e.response['Error']['Code']\n",
    "        if error_code == '404':\n",
    "            raise RuntimeError('S3 bucket does not exist. Please check')\n",
    "    aws_s3_sync(local_path, s3_path)\n",
    "    return\n",
    "\n",
    "\n",
    "def sync_s3_checkpoints_to_local(\n",
    "    local_path=\"/opt/ml/checkpoints\",\n",
    "    s3_path=os.path.dirname(os.path.dirname(os.getenv('SM_MODULE_DIR', ''))) +\n",
    "    '/checkpoints'):\n",
    "    \"\"\" sample function to sync checkpoints from s3 to local path \"\"\"\n",
    "\n",
    "    import boto3, botocore\n",
    "    #creat if local path does not exists\n",
    "    if not os.path.exists(local_path):\n",
    "        print(f\"Provided local path {local_path} does not exist. Creating...\")\n",
    "        try:\n",
    "            os.makedirs(local_path)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"failed to create {local_path}\")\n",
    "\n",
    "    #check if s3 bucket exists\n",
    "    s3 = boto3.resource('s3')\n",
    "    if 's3://' not in s3_path:\n",
    "        raise ValueError(\n",
    "            \"Provided s3 path {s3_path} is not valid. Please check\")\n",
    "\n",
    "    s3_bucket = s3_path.replace('s3://', '').split('/')[0]\n",
    "    print(f\"S3 Bucket: {s3_bucket}\")\n",
    "    try:\n",
    "        s3.meta.client.head_bucket(Bucket=s3_bucket)\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        error_code = e.response['Error']['Code']\n",
    "        if error_code == '404':\n",
    "            raise RuntimeError('S3 bucket does not exist. Please check')\n",
    "    aws_s3_sync(s3_path, local_path)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model 성능 추적용 Metrics 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions=[\n",
    "     {'Name': 'train:Time', 'Regex': 'Train_Time=(.*?):'},\n",
    "     {'Name': 'train:Loss', 'Regex': 'Train_Loss=(.*?):'},\n",
    "     {'Name': 'train:Prec@1', 'Regex': 'Train_Prec@1=(.*?):'},\n",
    "     {'Name': 'train:Prec@5', 'Regex': 'Train_Prec@5=(.*?):'},\n",
    "     {'Name': 'test:Time', 'Regex': 'Test_Time=(.*?):'},\n",
    "     {'Name': 'test:Loss', 'Regex': 'Test_Loss=(.*?):'},\n",
    "     {'Name': 'test:Prec@1', 'Regex': 'Test_Prec@1=(.*?):'},\n",
    "     {'Name': 'test:Prec@5', 'Regex': 'Test_Prec@5=(.*?):'}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Debugger 설정\n",
    "\n",
    "### 7.1 Rule 설정\n",
    "\n",
    "Debugger를 위해 다음과 같은 rules를 설정해야 합니다.\n",
    "\n",
    "- loss_not_decreasing : loss가 감소하고 있는지 확인하고, 지난 몇 번의 iterations에서 loss가 특정 % 만큼 감소하지 않은 경우 트리거를 합니다.\n",
    "- overfit : training loss와 validation loss를 비교하여 모델이 training 데이터에 overfit인지를 감지합니다.\n",
    "- stalled_training_rule : training job이 진행되지 않는지 감지하여 해당 규칙이 실행되면 학습 작업을 중지합니다.\n",
    "- LowGPUUtilization : GPU 활용도가 낮은지 확인합니다.\n",
    "- ProfilerReport : 전체 성능 관련 rules 들에 대해 실행하고, insights 와 추천을 포함하여 최종 ouput report를 생성합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.debugger import Rule, ProfilerRule, rule_configs\n",
    "\n",
    "rules=[ \n",
    "    Rule.sagemaker(rule_configs.loss_not_decreasing()),\n",
    "    Rule.sagemaker(rule_configs.overfit()),\n",
    "    Rule.sagemaker(rule_configs.stalled_training_rule()),\n",
    "    ProfilerRule.sagemaker(rule_configs.LowGPUUtilization()),\n",
    "    ProfilerRule.sagemaker(rule_configs.ProfilerReport()),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Profiler 설정 \n",
    "\n",
    "profiling을 실행하기 위해서는 ProfilerConfig object를 생성한 후 이 값을 Estimator의 Parameter인 profiler_config 값으로 전달합니다.\n",
    "\n",
    "아래 설정에서는 system metrics를 0.1 (100), 0.2 (200), 0.5 (500), 1 (1000), 5 (5000), 60 (60000) 초 (1 second = 1000 milliseconds) 중 하나를 선택할 수 있으며, default로는 0.5 초 입니다. system metrics에는 CPU/GPU 당 utilization, CPU/GPU 당 memory utilization, I/O, Network 등을 포함하고 있습니다.\n",
    "\n",
    "Debugger는 step 5부터 step 7까지의 상세한 profiling 정보를 수집합니다. 이 정보에는 CPU와 GPU에서 동작되는 Horovod metrics, dataloading, preprocessing, operators 등을 포함합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.debugger import CollectionConfig, DebuggerHookConfig\n",
    "\n",
    "debugger_hook_config = DebuggerHookConfig(\n",
    "    hook_parameters={\n",
    "        \"save_interval\": \"40\"\n",
    "    },\n",
    "    collection_configs=[\n",
    "        CollectionConfig(\"weights\"),\n",
    "        CollectionConfig(\"biases\"),\n",
    "        CollectionConfig(\"gradients\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.Hyperparameter 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "        'model_name' : 'resnext101_32x8d',\n",
    "        'num-classes' : 37,\n",
    "        'height' : 128,\n",
    "        'width' : 128,\n",
    "        'num-epochs': 5,\n",
    "        'batch-size' : 80, # 80 128 136\n",
    "        'test-batch-size' : 200, \n",
    "        'lr': 0.00001,\n",
    "        'data_parallel' : True,\n",
    "#         'model_parallel' : True,\n",
    "#         'apex' : True,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instance_type = 'ml.p3.16xlarge'  # 'ml.p3.16xlarge', 'ml.p3dn.24xlarge', 'ml.p4d.24xlarge'\n",
    "train_instance_count = 2\n",
    "image_uri = None\n",
    "distribution = None\n",
    "train_job_name = 'single'\n",
    "\n",
    "if hyperparameters.get('data_parallel'):\n",
    "    train_job_name = 'sdp-dist'\n",
    "    \n",
    "    distribution = {\"smdistributed\": {\n",
    "                        \"dataparallel\": {\n",
    "                                \"enabled\": True\n",
    "                        }\n",
    "                   }\n",
    "                 }\n",
    "elif hyperparameters.get('model_parallel'):\n",
    "    train_job_name = 'smp-dist'\n",
    "    \n",
    "    mpioptions = \"-verbose -x orte_base_help_aggregate=0 \"\n",
    "    distribution = {\"smdistributed\": {\n",
    "                      \"modelparallel\": {\n",
    "                          \"enabled\":True,\n",
    "                          \"parameters\": {\n",
    "                              \"microbatches\": 4,\n",
    "                              \"placement_strategy\": \"spread\",\n",
    "                              \"pipeline\": \"interleaved\",\n",
    "                              \"optimize\": \"speed\",\n",
    "                              \"partitions\": 2,\n",
    "                              \"ddp\": True,\n",
    "                          }\n",
    "                      }\n",
    "                  },\n",
    "                  \"mpi\": {\n",
    "                        \"enabled\": True,\n",
    "                        \"processes_per_host\": 2, # Pick your processes_per_host\n",
    "                        \"custom_mpi_options\": mpioptions\n",
    "                  },\n",
    "              }\n",
    "    \n",
    "    profiler_config = None  # smdebug doesnt support detailed profiling with sagemaker model parallel\n",
    "elif hyperparameters.get('apex'):\n",
    "    train_job_name = 'apex-dist'\n",
    "    \n",
    "else:\n",
    "    train_instance_type = 'ml.p3.2xlarge'\n",
    "\n",
    "\n",
    "print(\"train_job_name : {} \\ntrain_instance_type : {} \\ntrain_instance_count : {} \\nimage_uri : {} \\ndistribution : {}\".format(train_job_name, train_instance_type, train_instance_count, image_uri, distribution))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. `Pytorch` estimator를 이용한 training job 생성하기\n",
    "\n",
    "\n",
    "<p><strong><code>sagemaker.pytorch.PyTorch</code></strong> estimator는 처음 실행하는 스크립트 위치와 다양한 연계 코드들이 위치한 디렉토리 정보를 찾아서 스크립트를 S3에 upload하고 SageMaker의 training job을 수행하게 됩니다. training job은 학습을 수행한 단위입니다. 학습을 1번 돌리면 training job이 1개 생성됩니다. 몇 가지 중요 파라미터를 아래와 같이 설명드립니다. </p>\n",
    "\n",
    "- **entry_point** : 학습을 처음 실행하는 Python 소스 파일의 절대 또는 상대 경로이며, source_dir이 지정된 경우 entry_point는 source_dir 내 파일이 됩니다.\n",
    "- **source_dir** : 학습에 연계되는 다양한 소스코드 파일이 들어 있는 디렉토리 위치이며, 절대, 상대 경로 또는 S3 URI가 모두 가능하며,source_dir이 S3 URI 인 경우 tar.gz 파일이 됩니다.\n",
    "- **role** : Amazon SageMaker가 사용자를 대신해 작업(예: S3 버킷에서 모델 결과물이라고 하는 훈련 결과 읽기 및 Amazon S3에 훈련 결과 쓰기)을 수행하는 AWS Identity and Access Management(IAM) 역할입니다.\n",
    "- **train_instance_count** : 학습을 수행하는 instance 개수를 정의할 수 있습니다.\n",
    "- **train_instance_type** : 학습을 수행하는 instance 타입을 정의할 수 있습니다.\n",
    "- **train_volume_size** : 학습 인스턴스에 연결할 Amazon Elastic Block Store(Amazon EBS) 스토리지 볼륨의 크기(GB)입니다. File 모드를 사용할 경우 이 값이 훈련 데이터를 충분히 저장할 수 있는 크기여야 합니다(File 모드가 기본값)\n",
    "- **train_use_spot_instances** : 학습에서 SageMaker Managed Spot 인스턴스를 사용할지 여부를 지정합니다. 활성화되면 train_max_wait도 설정해야 합니다.\n",
    "- **train_max_run** : 최대 학습 시간을 설정할 수 있으며, 이 시간이 지나면 Amazon SageMaker는 현재 상태에 관계없이 작업을 종료합니다. (기본값 : 24 * 60 * 60)\n",
    "- **train_max_wait** : SageMaker Managed Spot 인스턴스를 기다리는 초 단위의 시간을 의미하는 것으로, 이 시간이 지나면 Amazon SageMaker는 스팟 인스턴스가 사용 가능해지기를 기다리는 것을 중지하며 결과는 fail이 됩니다.\n",
    "- **framework_version** : 학습에 사용될 특정 Pytorch 버전을 정의할 수 있습니다.\n",
    "- **py_version** : 컨테이너 환경이 python3일 경우 py3, python2일 경우 py2로 설정하면 됩니다. python2는 지원이 중단되었지만 기존 python2로 구성된 파일들을 지원하기 위해 현재 계속 사용할 수 있습니다. 없을 경우에는 기본적으로 py3 입니다.\n",
    "- **hyperparameters** : 학습에 사용할 하이퍼 파라미터를 정의할 수 있으며, 정의된 하이퍼 파라미터 값들은 모두 학습 컨테이너로 전송이 됩니다.\n",
    "- **distribution** : 분산과 관련된 값들을 학습 컨테이너로 전송합니다.\n",
    "- **profiler_config / rules** : Debugger에서 앞서 설정한 profiler와 rule을 학습 컨테이너로 전송합니다.\n",
    "\n",
    "<p> 추가적으로 분산/ 멀티 GPU 학습도 가능합니다. SageMaker는 <strong><a href=\"https://github.com/horovod/horovod\" target=\"_blank\" class ='btn-default'>Horovod</a></strong>에 최적화된 환경을 제공하고 있으며, Pytorch의 경우 1.5.0부터 기본 docker에서 apex를 지원합니다.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# all input configurations, parameters, and metrics specified in estimator \n",
    "# definition are automatically tracked\n",
    "estimator = PyTorch(\n",
    "    entry_point='./main_trainer.py',\n",
    "    source_dir='./src_dir',\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    framework_version='1.8.1',\n",
    "    py_version='py36',\n",
    "    instance_count=train_instance_count,\n",
    "    instance_type=train_instance_type,\n",
    "    volume_size=400,\n",
    "    hyperparameters=hyperparameters,\n",
    "    distribution=distribution,\n",
    "#     disable_profiler=True,\n",
    "    metric_definitions=metric_definitions,\n",
    "    rules=rules,\n",
    "    debugger_hook_config=debugger_hook_config,\n",
    "    max_run=12*60*60,\n",
    "#     use_spot_instances=True,  # spot instance 활용\n",
    "#     max_wait=12*60*60,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Fit 함수로 학습 시작하기 \n",
    "\n",
    "<p>학습을 시작하는 것은 <strong><code>estimator.fit (training_data_uri)</code></strong>이 호출되는 경우입니다. 여기에서 실제 데이터가 있는 S3의 위치가 입력으로 사용됩니다. <code>fit</code>에서는 <code>training</code>라는 기본 채널을 생성하며, 이 위치의 데이터는 S3에서 실제 컨테이너 환경에서는 <code>SM_CHANNEL_TRAINING</code> 위치로 복사되어 학습에 활용이 가능합니다. <code>fit</code>은 몇 가지 다른 유형의 입력도 허용하는데 자세한 내용은 <strong><a href=\"https://sagemaker.readthedocs.io/en/stable/estimators.html#sagemaker.estimator.EstimatorBase.fit\" target=\"_blank\" class ='btn-default'>API 문서</a></strong>를 참고하실 수 있습니다.</p>\n",
    "<p> 학습이 시작되면 Tensorflow 컨테이너에서는 <code>image_classifier.py</code>를 실행되며, <code>Estimator</code>에서 <code>hyperparameters</code> 와 <code>model_dir</code>을 스크립트의 파라미터로 전달합니다. <code>model_dir</code>을 별도로 전달하지 않으며, 기본값은<strong>s3://[DEFAULT_BUCKET]/[TRAINING_JOB_NAME] </strong>이 되며 실제 스크립트 실행은 다음과 같습니다. </p>\n",
    "    \n",
    "```bash\n",
    "python image_classifier.py --model_dir s3://[DEFAULT_BUCKET]/[TRAINING_JOB_NAME]\n",
    "```\n",
    "<p>학습이 완료되면 training job은 Tensorflow serving을 위해 saved model을 S3에 upload합니다.</p>\n",
    "<p><code>fit</code>에서 <strong>wait=True</strong>로 설정할 경우 <strong>Synchronous</strong> 방식으로 동직하게 되며, <strong>wait=False</strong>일 경우 <strong>Aynchronous</strong> 방식으로 동작되어 여러 개의 Training job을 동시에 실행할 수 있습니다. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = \"{}-training-job-{}\".format(train_job_name, int(time.time()))\n",
    "\n",
    "\n",
    "# Now associate the estimator with the Experiment and Trial\n",
    "estimator.fit(\n",
    "    inputs={'training': s3_data_path}, \n",
    "    job_name=job_name,\n",
    "    wait=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name=estimator.latest_training_job.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong>Aynchronous</strong>로 진행된 Training job은 아래와 같은 방법으로 진행상황을 실시간으로 확인할 수 있습니다.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session.logs_for_job(job_name=job_name, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Debugger Rules 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.latest_training_job.rule_job_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_debugger_artifacts_path = estimator.latest_job_debugger_artifacts_path()\n",
    "print(training_job_debugger_artifacts_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Tensors 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분석을 수행하기 전에 분석에 도움이 되는 Debugger의 개념을 아래 설명합니다.\n",
    "\n",
    "* **Trial** - Tensor에 액세스 할 때 Debugger API의 핵심 요소이며, training job의 단일 실행을 나타내는 high-level 추상화 객체입니다. Training job에서 도출된 모든 Tensor와 연계됩니다.\n",
    "* **Step** - 다음 추상화 수준의 객체이며, Debugger에서 step은 Training job의 단일 배치를 나타냅니다. 각 Trial은 여러 단계가 있으며, 각 Tensor는 여러 단계와 연계되고, 각 단계에서 특정 값을 가지게 됩니다.\n",
    "* **Tensor** - Training job 동안 저장되는 실제 Tensor를 나타내는 객체이며, tensor는 1-D scalar도 가능합니다.(loss는 scalar로 저장됩니다.)\n",
    "\n",
    "Debugger API에 대한 상세 내용은 [Amazon SageMaker Debugger github](https://github.com/awslabs/sagemaker-debugger)를 참조하십시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smdebug.trials import create_trial\n",
    "\n",
    "# this is where we create a Trial object that allows access to saved tensors\n",
    "trial = create_trial(training_job_debugger_artifacts_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_data(trial, tensor_name, batch_index, steps_range, mode):\n",
    "    tensor = trial.tensor(tensor_name)\n",
    "    vals = []\n",
    "    for step_num in steps_range:\n",
    "        val = tensor.value(step_num=step_num, mode=mode)[batch_index]\n",
    "        vals.append(val)\n",
    "    return pd.DataFrame(columns=['steps', tensor_name], data=list(zip(steps_range, vals)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smdebug import modes\n",
    "import time\n",
    "\n",
    "# Below we select the very first tensor from every batch.\n",
    "# Feel free to modify this and select another tensor from the batch.\n",
    "batch_index = 0\n",
    "\n",
    "# This is a name of a tensor to analyze.\n",
    "tensor_name = 'DistributedDataParallel_module.conv1.weight'\n",
    "\n",
    "steps = 0\n",
    "while steps == 0:\n",
    "    # trial.steps return all steps that have been downloaded by Debugger to date.\n",
    "    # It doesn't represent all steps that are to be available once training job is complete -\n",
    "    # it is a snapshot of a current state of the training job. If you call it after training job is done\n",
    "    # you will get all tensors available at once.\n",
    "    steps = trial.steps()\n",
    "    print('Waiting for tensors to become available...')\n",
    "    time.sleep(3)\n",
    "print('\\nDone')\n",
    "\n",
    "print('Getting tensors...')\n",
    "rendered_steps = []\n",
    "\n",
    "# trial.loaded_all_steps is a way to keep monitoring for a state of a training job as seen by Debugger.\n",
    "# When SageMaker completes training job Debugger, and trial, becomes aware of it.\n",
    "\n",
    "loaded_all_steps = False\n",
    "while not loaded_all_steps:\n",
    "    loaded_all_steps = trial.loaded_all_steps\n",
    "    steps = trial.steps()\n",
    "    # show diff between lists\n",
    "    steps_to_render = list(set(steps).symmetric_difference(set(rendered_steps)))\n",
    "    \n",
    "    data = get_data(trial=trial, \n",
    "                    tensor_name=tensor_name, \n",
    "                    batch_index=0, \n",
    "                    steps_range=steps_to_render, \n",
    "                    mode=modes.GLOBAL)\n",
    "    print(data)\n",
    "#     data.sort_values('steps', inplace=True)\n",
    "#     data.plot(x='steps', y=tensor_name)\n",
    "    \n",
    "    rendered_steps.extend(steps_to_render)\n",
    "    time.sleep(5)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Local Directory 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = './model'\n",
    "output_dir = './output'\n",
    "\n",
    "!rm -rf $model_dir\n",
    "!rm -rf $output_dir\n",
    "\n",
    "import json , os\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_output = output_dir+'/ProfilerReport'\n",
    "\n",
    "if not os.path.exists(profile_output):\n",
    "    os.makedirs(profile_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Profiling Data 분석\n",
    "\n",
    "Training이 진행되는 동안에도 성능 데이터를 visualization할 수 있습니다. Debugger는 system metrics를 timeline 차트 또는 heatmaps의 형태로 plot하기 위한 유틸리티를 제공합니다. 상세한 정보를 위해 노트북 [profiling_interactive_analysis.ipynb](analysis_tools/profiling_interactive_analysis.ipynb)을 생성해서 제공합니다. 아래 셀을 실행하여 시계열 차트로서 전체 CPU와 GPU utilization을 plot합니다. I/O, Memory, network 와 같은 다른 metrics을 visualization하기 위해서는 단순히 `select_dimension` `select_events` 전달되는 list만 확장하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smdebug.profiler.analysis.notebook_utils.training_job import TrainingJob\n",
    "tj = TrainingJob(job_name)\n",
    "tj.wait_for_sys_profiling_data_to_be_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.1 Utilization histograms\n",
    "\n",
    "MetricHistogram은 GPU와 CPU의 utilization에 대한 히스토그램을 계산합니다. Bin은 0에서 100 사이이며, 분포의 중심이 80에서 90 사이에 있으면 좋은 system utilization를 의미합니다.\n",
    "\n",
    "히스토그램의 dimension은 CPUUtilization, GPUUtilization, GPUMemoryUtilization, IOPS (IO per second) 등이 가능합니다. 별도 event를 설정하지 않으면 각 단일 코어에 대한 CPU utilization과 전체 CPU 사용량에 대한 히스토그램이 표시됩니다. GPU의 경우 각 GPU utilization과 memory를 시각화하며, IOPS의 경우에는 CPU 당 IO 대기 시간을 표시합니다.\n",
    "\n",
    "select_events를 지정하면 select_metrics의 이름과 일치하는 메트릭만 표시하며, select_dimensions와 select_events를 모두 지정하지 않으면 사용 가능한 모든 측정 항목을 시각화합니다.\n",
    "\n",
    "아래 2번째 CPU/GPU utilization은 마지막 1000 datapoints에 대해 timeline 차트로 코어/GPU 당 utilization을 보여줍니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tj.wait_for_framework_profiling_data_to_be_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smdebug.profiler.analysis.notebook_utils.metrics_histogram import MetricsHistogram\n",
    "from smdebug.profiler.analysis.notebook_utils.timeline_charts import TimelineCharts\n",
    "\n",
    "\n",
    "system_metrics_reader=tj.get_systems_metrics_reader()\n",
    "system_metrics_reader.refresh_event_file_list()\n",
    "\n",
    "framework_metrics_reader=tj.get_framework_metrics_reader()\n",
    "framework_metrics_reader.refresh_event_file_list()\n",
    "\n",
    "metrics_histogram=MetricsHistogram(system_metrics_reader)\n",
    "metrics_histogram.plot(starttime=0, \n",
    "                       endtime=system_metrics_reader.get_timestamp_of_latest_available_file(), \n",
    "                       select_dimensions=[\"CPU\", \"GPU\"],\n",
    "                       select_events=[\"total\"]\n",
    "                      )\n",
    "\n",
    "view_timeline_charts =TimelineCharts(system_metrics_reader, \n",
    "                                       framework_metrics_reader=framework_metrics_reader,\n",
    "                                       select_dimensions=[\"CPU\", \"GPU\"],\n",
    "                                       select_events=[\"total\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "target range를 선택하여 drill-down하기 위해서는 두번째 plot에서 선택하여 정확한 time range를 얻은 후, 이는 correlated framework metrics의 출력값에서 얻을 수 있습니다.\n",
    "\n",
    "<img src=./imgs/select_range_drilldown_framework_metrics.gif/>\n",
    "\n",
    "#### 1. 모든 framework operation의 time annotation을 찾습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_range=[535,541]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Note change index range below with selected index range from above cell\n",
    "view_timeline_charts.find_time_annotations(time_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 선택된 time range에 대해 framework metrics의 timeline 차트를 plot합니다. out of memory의 이슈를 피하기 위해 단지 처음 1000 datapoints만 plot 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Note change index range below with selected index range from above cell\n",
    "view_timeline_charts.plot_detailed_profiler_data(time_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2 CPU 병목 식별하기\n",
    "\n",
    "heatmap은 각 행이 하나의 metric (CPU core 와 GPU utilization)에 해당하고, x 축이 training job의 duration 입니다. GPU의 utilization이 낮고, 1개 이상 cores의 utilization이 높은 경우 CPU 병목을 쉽게 확인할 수 있습니다.\n",
    "\n",
    "아래 heatmap에서, Yellow 는 maximum utilization이며, Purple은 utilization이 0을 의미합니다. GPU는 utilization이 0으로 떨어지면서 동시에 CPU core의 utilization이 최대가 되면서 자주 지연된 주기가 발생하며, GPU가 데이터를 기다리는 CPU 병목현상을 나타내게 됩니다. 예를 들어 이런 병목현상은 컴퓨팅이 많이 필요한 preprocessing에서 발생할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smdebug.profiler.analysis.notebook_utils.heatmap import Heatmap\n",
    "\n",
    "system_metrics_reader.refresh_event_file_list()\n",
    "view_heatmap=Heatmap(system_metrics_reader, plot_height=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from smdebug.profiler.analysis.utils.merge_timelines import MergedTimeline, MergeUnit\n",
    "\n",
    "start_step, end_step=1, 10\n",
    "combined_timeline=MergedTimeline(tj.profiler_s3_output_path, output_directory=profile_output)\n",
    "combined_timeline.merge_timeline(start_step, end_step, unit=MergeUnit.STEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>학습이 모두 완료된 다음에 S3에서 모델 산출물을 SageMaker Notebook 환경으로 내려받습니다.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_dir = estimator.model_data.replace('model.tar.gz', '')\n",
    "print(artifacts_dir)\n",
    "!aws s3 ls --human-readable {artifacts_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp {artifacts_dir}model.tar.gz {model_dir}/model.tar.gz\n",
    "!tar -xzf {model_dir}/model.tar.gz -C {model_dir}\n",
    "!aws s3 cp {artifacts_dir}output.tar.gz {output_dir}/output.tar.gz\n",
    "!tar -xzf {output_dir}/output.tar.gz -C {output_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json , os\n",
    "\n",
    "with open(os.path.join(output_dir, 'model_history.p'), \"r\") as f:\n",
    "    model_history = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_curves(history): \n",
    "    \n",
    "    fig, axes = plt.subplots(1, 4, figsize=(18, 4), sharex=True)\n",
    "    \n",
    "    ax = axes[0]\n",
    "    ax.plot(history['epoch'], history['losses'], label='train')\n",
    "    ax.plot(history['val_avg_epoch'], history['val_avg_losses'], label='validation')\n",
    "    ax.set(\n",
    "        title='model loss',\n",
    "        ylabel='loss',\n",
    "        xlabel='epoch')\n",
    "    ax.legend()\n",
    "    \n",
    "    ax = axes[1]\n",
    "    ax.plot(history['epoch'], history['batch_time'], label='train')\n",
    "    ax.plot(history['val_avg_epoch'], history['val_avg_batch_time'], label='validation')\n",
    "    ax.set(\n",
    "        title='model batch_time',\n",
    "        ylabel='batch_time',\n",
    "        xlabel='epoch')\n",
    "    ax.legend()\n",
    "    \n",
    "    \n",
    "    ax = axes[2]\n",
    "    ax.plot(history['epoch'], history['top1'], label='train')\n",
    "    ax.plot(history['val_avg_epoch'], history['val_avg_top1'], label='validation')\n",
    "    ax.set(\n",
    "        title='top1 accuracy',\n",
    "        ylabel='accuracy',\n",
    "        xlabel='epoch')\n",
    "    ax.legend()\n",
    "    \n",
    "    ax = axes[3]\n",
    "    ax.plot(history['epoch'], history['top5'], label='train')\n",
    "    ax.plot(history['val_avg_epoch'], history['val_avg_top5'], label='validation')\n",
    "    ax.set(\n",
    "        title='top5 accuracy',\n",
    "        ylabel='accuracy',\n",
    "        xlabel='epoch')\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    \n",
    "plot_training_curves(model_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Debugger Profiling Report 다운로드 받기\n",
    "Profiling report rule은 html report `profiler-report.html` 생성합니다. 이 Report에는 built-in rules 과 다음 단계에 대한 recommenadation에 대한 요약을 포함하고 있습니다. Report는 S3 bucket에 있으며 아래 cell을 실행하여 노트북으로 다운로드를 받습니다. 자세한 사항은 [SageMaker Debugger Profiling Report](https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-profiling-report.html) 에서 확인이 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_output_path = estimator.output_path + estimator.latest_training_job.job_name + \"/rule-output\"\n",
    "print(f\"You will find the profiler report in {rule_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls {rule_output_path}/ProfilerReport/profiler-output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp {rule_output_path}/ProfilerReport/profiler-output/ {output_dir}/ProfilerReport/ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>ProfilerReport : <a href=\"{}profiler-report.html\">Profiler Report</a></b>'.format(output_dir+\"/ProfilerReport/\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%store hyperparameters model_dir output_dir artifacts_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>\n",
    "<p>Amazon SageMaker에서 모든 학습을 완료하였습니다. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.c5.large",
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
